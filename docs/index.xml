<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Hongsup Shin</title>
<link>https://hongsupshin.github.io/</link>
<atom:link href="https://hongsupshin.github.io/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.8.26</generator>
<lastBuildDate>Sun, 22 Feb 2026 06:00:00 GMT</lastBuildDate>
<item>
  <title>The Corpus-Provenance Gap in RAG Evaluation</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2026-02-22-rag_data_provenance/</link>
  <description><![CDATA[ 





<p>A widespread pattern in RAG evaluation is to generate QA pairs from the same or overlapping documents that populate the retrieval corpus. The evaluation scores often look encouraging, but after deployment, users report hallucinations and confidently wrong answers at a rate the evaluation did not predict. The root cause is often that every eval question has a matching document in the store by construction, so the evaluation never tests partial-match scenarios, out-of-distribution queries, or questions where the appropriate response is “I don’t have enough information.” This <strong>corpus-eval contamination</strong> is well-understood in supervised ML as train/test contamination. In RAG evaluation, the same principle applies but the tooling does not surface it.</p>
<p>This post proposes a lightweight content hashing pattern that gives teams corpus-level awareness: the ability to know what was in the vector store when an evaluation ran, detect overlap between eval QA sources and the retrieval corpus, and construct out-of-distribution tests deliberately. This is not a new idea; it is a transfer of train/test discipline from supervised ML, and several recent papers address overlapping concerns. The sections that follow first review the relevant literature and the current evaluation tooling landscape, then describe practical mitigations at three levels of effort.</p>
<p>A careful reader might object that the analogy is imperfect: training data shapes model parameters through gradient updates, while a retrieval corpus is merely looked up at inference time. The mechanism differs, but the function is the same. In both cases, the data source is the knowledge base the system draws on to produce answers, and in both cases, overlap between that knowledge base and the evaluation set inflates scores by guaranteeing that relevant information is always available. The risk is identical because you are measuring retrieval under conditions that will not hold in production even though the pathway from data to answer is different.</p>
<section id="the-analogy-to-traintest-contamination" class="level2">
<h2 class="anchored" data-anchor-id="the-analogy-to-traintest-contamination">The Analogy to Train/Test Contamination</h2>
<p>In supervised ML, the train/test split is foundational, and contamination between the two is among the first pitfalls any practitioner learns to avoid. Temporal splits, group-aware splits, and distribution shift testing all exist to handle subtler versions of this problem.</p>
<p>In RAG, the retrieval corpus plays a role analogous to training data, and the evaluation QA set serves as the test set. When there’s an overlap between the two, the split is effectively contaminated. The system will retrieve plausible content for every eval question, inflating faithfulness and context recall scores. Effectively, we are measuring the system’s ability to look up answers that are guaranteed to exist.</p>
<section id="related-work" class="level3">
<h3 class="anchored" data-anchor-id="related-work">Related Work</h3>
<p>Several 2025 papers address RAG contamination, primarily from the <strong>memorization angle</strong> such as whether the LLM already knows the answer from pretraining and does not actually need retrieval. <a href="https://arxiv.org/abs/2506.15513">RePCS</a> proposes a retrieval-path contamination score. <a href="https://arxiv.org/abs/2602.10210">HybridRAG-Bench</a> uses time-framed corpora to reduce pretraining overlap. <a href="https://arxiv.org/abs/2507.05713">DRAGOn</a> addresses non-reproducibility by proposing dynamic benchmarks on periodically refreshed corpora, with versioned dataset snapshots uploaded to Hugging Face.</p>
<p>These papers address overlapping concerns. DRAGOn in particular tackles the question of how to maintain evaluation validity when the underlying corpus changes between benchmark runs. HybridRAG-Bench’s use of time-framed corpus snapshots is also a form of corpus-level control for evaluation validity. <a href="https://arxiv.org/abs/2506.03401">RAGOps paper</a> supports the framing here, noting that current LLMOps tools focus on model and prompt management while offering limited support for data-related aspects of RAG systems.</p>
</section>
</section>
<section id="a-landscape-review-what-gets-versioned-and-what-does-not" class="level2">
<h2 class="anchored" data-anchor-id="a-landscape-review-what-gets-versioned-and-what-does-not">A Landscape Review: What Gets Versioned and What Does Not</h2>
<p>There appears to be a structural gap at the boundary between two tooling categories: evaluation platforms and vector stores, each of which addresses part of the problem.</p>
<section id="evaluation-platforms" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-platforms">Evaluation Platforms</h3>
<p>Modern evaluation platforms are capable experiment management tools. They version <strong>prompts, scores, model configurations, and evaluation datasets</strong>.</p>
<p><a href="https://www.braintrust.dev/">Braintrust</a> tracks full lineage per experiment: dataset version, prompt version, model configuration, and judge settings. <a href="https://www.langchain.com/langsmith">LangSmith</a> provides per-query trace-level visibility into which documents were retrieved, along with dataset versioning for test cases. <a href="https://langfuse.com/">Langfuse</a> shipped dataset item versioning in late 2025, automatically tying experiments to the exact dataset state at run time. <a href="https://wandb.ai/site/weave">W&amp;B Weave</a> versions code via <code>@weave.op()</code> decorators alongside model parameters, datasets, and scorers. <a href="https://phoenix.arize.com/">Arize Phoenix</a> offers corpus embedding extraction and visualization — the closest any evaluation tool comes to corpus awareness, though as post-hoc analysis rather than provenance. These tools address the problems they were designed for, and they do so effectively.</p>
<section id="what-remains-unversioned" class="level4">
<h4 class="anchored" data-anchor-id="what-remains-unversioned">What Remains Unversioned</h4>
<p>The retrieval corpus state at evaluation time. In reviewing seven tools (<a href="https://www.braintrust.dev/">Braintrust</a>, <a href="https://www.langchain.com/langsmith">LangSmith</a>, <a href="https://langfuse.com/">Langfuse</a>, <a href="https://wandb.ai/site/weave">W&amp;B Weave</a>, <a href="https://phoenix.arize.com/">Arize Phoenix</a>, <a href="https://www.promptfoo.dev/">Promptfoo</a>, and <a href="https://www.getmaxim.ai/">Maxim</a>), I could not find one that can answer <strong>“What documents were in the vector store when this evaluation ran?”</strong></p>
<p>The concept of a <strong>unified evaluation environment fingerprint</strong> (a single hash capturing vector store contents, embedding model version, chunking parameters, and retrieval configuration) does not appear in any of these tools’ documentation as of this writing (Feb 2026). Prompts, models, eval datasets, and scoring criteria can all be versioned. The data the system retrieves from cannot.</p>
</section>
</section>
<section id="data-versioning-tools" class="level3">
<h3 class="anchored" data-anchor-id="data-versioning-tools">Data Versioning Tools</h3>
<p><a href="https://lakefs.io/">lakeFS</a> provides git-like branching and commits for data lakes. As of early 2026, it has shipped a LanceDB integration, built a LangChain document loader, and acquired DVC in late 2025. It can version data effectively. However, connecting a lakeFS commit ID to an evaluation run in Braintrust or Langfuse requires custom engineering. I have not found a documented standard pattern for this integration.</p>
<p><a href="https://www.activeloop.ai/">Deep Lake</a> (Activeloop) offers built-in version control at the storage format level with time-travel capabilities. It has expanded its RAG support with Deep Memory, Deep Lake 4.0, and a PostgreSQL integration. It can version corpus data, but similarly lacks integration with evaluation frameworks to bind corpus versions to evaluation runs.</p>
<p>The gap seems to exist because versioning tools can version data, evaluation tools can version experiments, but <strong>the connection between the two for RAG evaluation is not yet standardized</strong>. The problem is not on either side alone. To my knowledge, no existing system currently provides automatic corpus fingerprinting at evaluation time, immutable eval-corpus binding, diff-aware re-evaluation triggered by corpus changes, corpus-version comparison dashboards, or CI/CD gates on corpus quality regressions. These would be straightforward extensions of what evaluation tools already do. They have simply not been built yet, likely because the corpus has been treated as outside the evaluation tool’s scope.</p>
</section>
</section>
<section id="practical-mitigations" class="level2">
<h2 class="anchored" data-anchor-id="practical-mitigations">Practical Mitigations</h2>
<p>Rather than jumping to an infrastructure solution, I think the most useful starting point is a diagnostic. In my experience, teams are more motivated to build systematic tooling after discovering that their current evaluation has a concrete problem.</p>
<section id="level-1-diagnostics-zero-infrastructure" class="level3">
<h3 class="anchored" data-anchor-id="level-1-diagnostics-zero-infrastructure">Level 1: Diagnostics (Zero Infrastructure)</h3>
<p>Three questions to ask about a current evaluation setup:</p>
<section id="source-overlap-check" class="level4">
<h4 class="anchored" data-anchor-id="source-overlap-check">Source Overlap Check</h4>
<p>Were the eval QA pairs generated from documents that are currently in the retrieval corpus? If so, what percentage of the eval set has a source document in the store? This is a manual audit: pull the eval dataset, trace where the questions originated, and check whether those source documents are present in the store. In my experience, many teams have not done this. Among the teams I have worked with or consulted, the overlap was often 100%.</p>
</section>
<section id="the-abstention-i-dont-know-test" class="level4">
<h4 class="anchored" data-anchor-id="the-abstention-i-dont-know-test">The Abstention (“I Don’t Know”) Test</h4>
<p>What percentage of eval questions are genuinely unanswerable from the current corpus? If the answer is zero, the evaluation only measures the happy path. Running 10–20 questions that are known not to be covered by the documents can reveal whether the system hallucinates, hedges, or correctly abstains. To be honest, this is not common practice even among teams with mature evaluation workflows. I had the infrastructure to support this test in a system I built, and it was still never exercised in practice. The gap between recognizing its value and actually doing it is real.</p>
</section>
<section id="the-silent-drift-check" class="level4">
<h4 class="anchored" data-anchor-id="the-silent-drift-check">The Silent Drift Check</h4>
<p>Has the corpus changed since the last evaluation? If new documents have been ingested, old ones deleted, or existing content re-chunked, the previous eval scores describe a system configuration that no longer exists.</p>
</section>
</section>
<section id="level-2-lightweight-instrumentation" class="level3">
<h3 class="anchored" data-anchor-id="level-2-lightweight-instrumentation">Level 2: Lightweight Instrumentation</h3>
<p>For teams that want to address this without adopting new infrastructure:</p>
<section id="tag-eval-qa-pairs-with-source-document-identifiers" class="level4">
<h4 class="anchored" data-anchor-id="tag-eval-qa-pairs-with-source-document-identifiers">Tag Eval QA Pairs with Source Document Identifiers</h4>
<p>Even filenames suffice. When running an evaluation, log which source documents the QA pairs came from. This enables a minimum viable contamination check: if a QA pair’s source document is also in the retrieval corpus, flag it.</p>
</section>
<section id="hash-the-corpus-at-evaluation-time" class="level4">
<h4 class="anchored" data-anchor-id="hash-the-corpus-at-evaluation-time">Hash the Corpus at Evaluation Time</h4>
<p>Before each eval run, compute a single aggregate hash over the store’s contents, even a sorted list of document filenames hashed together. Log it alongside the eval scores. When comparing two evaluation runs, this at least indicates whether the corpus was identical. This is approximate, but substantially better than having no record at all.</p>
</section>
<section id="split-the-eval-set-deliberately" class="level4">
<h4 class="anchored" data-anchor-id="split-the-eval-set-deliberately">Split the Eval Set Deliberately</h4>
<p>Remove a certain portion (e.g., 20%) of source documents from the store and generate eval questions only from those excluded documents. These serve as out-of-distribution questions. If the system’s faithfulness score drops meaningfully on this subset, the magnitude of contamination-driven score inflation becomes quantifiable.</p>
<p><strong>A practical note.</strong> The ease of implementation varies by vector store architecture. Self-hosted stores where documents can be enumerated make this straightforward. Managed APIs (such as OpenAI’s Assistants API) where file IDs can be listed but content cannot be efficiently hashed require additional workarounds.</p>
</section>
</section>
<section id="level-3-the-full-pattern" class="level3">
<h3 class="anchored" data-anchor-id="level-3-the-full-pattern">Level 3: The Full Pattern</h3>
<p>For teams building evaluation infrastructure, the systematic version of Level 2 can be designed for durability.</p>
<p>A brief note on what vector stores do and do not provide, since this motivates the pattern. Most major vector databases (Pinecone, Qdrant, Chroma, pgvector) offer ID-based upsert: upserting with the same ID produces an update, not a duplicate. But the common RAG ingestion pattern uses auto-generated IDs, so the same document uploaded twice creates two records. More importantly, ID-based upsert tells you nothing about what content is in the store. <a href="https://docs.weaviate.io/weaviate/manage-objects/create#generate-deterministic-ids">Weaviate’s <code>generate_uuid5()</code></a> is an exception because it produces deterministic UUIDs from object content. But it is opt-in and operates at the document level, not as a corpus-level feature. This landscape moves quickly, and I would encourage readers to verify against current documentation.</p>
<section id="the-content-hashing-pattern" class="level4">
<h4 class="anchored" data-anchor-id="the-content-hashing-pattern">The Content Hashing Pattern</h4>
<p>SHA-256 hash each document’s content at ingestion time and maintain a manifest mapping file paths to content hashes and upload timestamps.</p>
<p>It is worth being explicit about two levels of hashing here, since the post uses both. <em>Document-level hashing</em> (one hash per file) is the foundation. It enables deduplication and answers the question “is this specific document in the store?” <em>Corpus-level fingerprinting</em> is derived from the document hashes, and it represents an aggregate hash or manifest snapshot over all documents currently in the store. It answers a different question: “has the overall state of the store changed since the last evaluation run?”</p>
<p>The contamination detection use case depends on <em>document-level awareness</em>; the “did my corpus drift between eval runs?” check depends on corpus-level fingerprinting. Document-level hashing is, I believe, the appropriate abstraction for the contamination question. The relevant question is “is the source information present in the store when this eval ran?” not “how is it chunked?” A document chunked into 256-token or 1024-token pieces contains the same source information; an eval QA pair generated from that document is answerable in either case. This pattern provides three capabilities:</p>
<p><strong>Corpus fingerprinting.</strong> A single aggregate hash or manifest snapshot representing what was in the store at evaluation time. Binding this to each evaluation run alongside prompt version and model configuration gives every result a data provenance record.</p>
<p><strong>Contamination detection.</strong> Comparing the source documents for eval QA pairs against the corpus manifest. Any document used to generate QA and also present in the retrieval corpus at evaluation time can be flagged as potential contamination. This is a mechanical check.</p>
<p><strong>Out-of-distribution evaluation construction.</strong> Deliberately excluding a subset of documents from the store, generating questions from those excluded documents, and verifying the system declines gracefully rather than hallucinating. Without a manifest, this is difficult to do reliably.</p>
</section>
</section>
</section>
<section id="what-i-learned-building-this" class="level2">
<h2 class="anchored" data-anchor-id="what-i-learned-building-this">What I Learned Building This</h2>
<p>I built a system along these lines while working on an internal RAG SDK at work. The content hashing manifest was originally motivated by deduplication and rollback safety, but it turned out to also serve as the foundation for evaluation provenance. The three capabilities above emerged from infrastructure that already existed for ingestion integrity. This is perhaps the most useful insight from that experience: if corpus awareness is built into the ingestion layer, evaluation provenance comes at relatively low additional cost.</p>
<p>These pieces, combined with structured execution logs, form what I think of as a reproducibility layer. The content hashing manifest provides data provenance because it’s a record of what is in the store at any point. An evaluation environment snapshot (combining configuration, content, and prompt hashes) provides environment tracking, making any result traceable to its full configuration. Structured execution logs such as recording the query, retrieved documents, assembled prompt, and generated answer for each request, provide execution provenance. Together, these three components cover the dimensions needed to reproduce a past evaluation. They are not typically connected into an automated workflow, but the artifacts are inexpensive to produce if considered at ingestion time rather than retrofitted later.</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p>Content hashing is lightweight and effective for the contamination problem, but it has real boundaries that are worth stating clearly.</p>
<p>The aggregate fingerprint is O(n) at evaluation time. Computing a corpus-level hash requires reading every entry in the manifest. At hundreds or low thousands of documents, this is trivial. At hundreds of thousands, <strong>incremental computation</strong> (e.g., a Merkle tree updated on each ingestion) becomes necessary. This is solvable but represents a different class of engineering effort.</p>
<p>A single-file manifest does not support <strong>distributed writers</strong>. Atomic temp-file-then-rename writes work for a single machine with a single ingestion process. Multiple services writing to the same vector store require a database-backed manifest or distributed coordination.</p>
<p><strong>Near-duplicates</strong> are invisible to content hashing. SHA-256 catches exact matches only. The same document with a different header, trailing whitespace, or encoding produces a different hash. Addressing semantic near-duplicates would require embedding-level similarity at ingestion time, a fundamentally different cost profile. The manifest tracks identical content, not semantically redundant content.</p>
<p><strong>Chunking strategy changes are invisible at the document level.</strong> The content hashing pattern described here operates on source documents, not on the chunks derived from them. This is a deliberate choice because the contamination question is about whether the source information is present, not how it is segmented. However, different chunking strategies can change whether a question is actually answerable: a question that requires context spanning paragraphs 3 and 4 may succeed with 1024-token chunks but fail with 256-token chunks that split those paragraphs across chunk boundaries. The document-level hash will show no change even though the system’s effective retrieval capability has shifted. This is why the earlier discussion of an evaluation environment fingerprint includes chunking parameters alongside the corpus hash because the two are complementary, not redundant.</p>
<p>For teams that work with hundreds to low-thousands of documents, running evaluations periodically, with a single ingestion pipeline, the pattern should work within these boundaries. Teams at larger scale should treat it as a starting point rather than a complete solution.</p>
</section>
<section id="suggestions-for-the-ecosystem" class="level2">
<h2 class="anchored" data-anchor-id="suggestions-for-the-ecosystem">Suggestions for the Ecosystem</h2>
<p>I want to be careful about positioning here. This is intended as a suggestion to existing tool builders, not a claim to have solved the problem comprehensively. Score tracking, dashboards, annotation workflows, prompt versioning, and experiment comparison are mature capabilities in tools like Braintrust, Langfuse, and LangSmith. These should not be rebuilt.</p>
<p>What appears to be missing is a metadata interface. Evaluation tools could accept a corpus-state fingerprint alongside prompt version and model configuration. The ingestion pipeline or SDK would emit this metadata; the evaluation tool would record and surface it.</p>
<p>The minimum viable version might be a <code>corpus_hash</code> field on evaluation runs, displayed in experiment comparison views. When two experiments have different corpus hashes, the tool could flag that the underlying data differed. Langfuse, for example, already versions dataset items and ties experiments to the exact dataset state at run time. Extending that pattern to accept a corpus fingerprint, emitted by the ingestion pipeline and logged alongside the eval dataset version, would be a natural next step, and the schema change would be minimal. Even this single field, if surfaced in experiment comparison views, could meaningfully change how teams interpret their evaluation results.</p>
<p>A more complete vision might include corpus-version comparison dashboards, CI/CD gates on corpus quality regressions, and diff-aware re-evaluation triggered by corpus changes. These are natural extensions of experiment management into the data dimension, and I suspect they are not prohibitively expensive to build for teams that already have the experiment infrastructure in place.</p>
<p>The underlying observation is straightforward: evaluation tools already version most aspects of the evaluation environment except the data the system retrieves from. Closing that gap does not require a paradigm shift and I believe it requires one additional metadata field and the discipline to populate it.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>The idea in this post is not novel. It is a transfer of a well-established mental model (train/test contamination) from supervised ML to RAG evaluation. And from my understanding, the RAG ecosystem has not yet inherited the tooling to detect and prevent this kind of contamination at the corpus level. The gap seems to be real, but it is also addressable with relatively modest engineering effort.</p>
<p>If this post is useful, it will be for the Level 1 diagnostic. Running a source overlap check, testing out-of-distribution questions, and verifying that the corpus has not drifted since the last evaluation are all things that can be done immediately and at no cost. Most teams, in my experience, find the results informative.</p>
<p>Content hashing is not exotic infrastructure. Logging a corpus fingerprint alongside evaluation scores is a small amount of work. Whether the ecosystem will converge on treating the retrieval corpus with the same discipline applied to training data remains to be seen, but the technical barriers are low.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li>Xu, X. et al.&nbsp;(2025). “RAGOps: Operating and Managing Retrieval-Augmented Generation Pipelines.” arXiv:2506.03401. CSIRO, KU Leuven.</li>
<li>RePCS (2025). “Retrieval-Path Contamination Scoring.” arXiv:2506.15513.</li>
<li>HybridRAG-Bench (2025). “Benchmarking RAG with Time-Framed Corpora.” arXiv:2602.10210.</li>
<li>DRAGOn (2025). “Non-Reproducibility with Evolving Corpora in RAG.” arXiv:2507.05713.</li>
</ul>
<hr>
<p><em>If you found this post useful, you can cite it as:</em></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bibtex code-with-copy"><code class="sourceCode bibtex"><span id="cb1-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">@article</span>{</span>
<span id="cb1-2">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">hongsupshin</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">2026</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">rag</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">corpus</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">provenance</span>,</span>
<span id="cb1-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">author</span> = {Hongsup Shin},</span>
<span id="cb1-4">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">title</span> = {The Corpus-Provenance Gap in RAG Evaluation},</span>
<span id="cb1-5">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">year</span> = {2026},</span>
<span id="cb1-6">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span> = {2},</span>
<span id="cb1-7">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">day</span> = {22},</span>
<span id="cb1-8">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">howpublished</span> = {<span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\url</span>{https://hongsupshin.github.io}},</span>
<span id="cb1-9">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">journal</span> = {Hongsup Shin's Blog},</span>
<span id="cb1-10">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">url</span> = {https://hongsupshin.github.io/posts/2026-02-22-rag_data_provenance/},</span>
<span id="cb1-11">}</span></code></pre></div></div>


</section>

 ]]></description>
  <category>RAG</category>
  <category>evaluation</category>
  <category>LLMOps</category>
  <category>data-provenance</category>
  <guid>https://hongsupshin.github.io/posts/2026-02-22-rag_data_provenance/</guid>
  <pubDate>Sun, 22 Feb 2026 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2026-02-22-rag_data_provenance/fig.png" medium="image" type="image/png" height="150" width="144"/>
</item>
<item>
  <title>The AI SDK Adoption Problem: When Conway’s Law Meets AI Engineering</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2026-01-24-conway-law/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://www.comicagile.net/comic/conways-law/"><img src="https://hongsupshin.github.io/posts/2026-01-24-conway-law/fig.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></a></p>
</figure>
</div>
<figcaption>Comic Agile #85: Conway’s Law</figcaption>
</figure>
</div>
<p>Two teams exist in many organizations building AI capabilities: the SDK team builds client libraries and developer tools, and the solutions team builds applications. Both teams want the same thing: successful AI products. But there’s a tension.</p>
<p>The SDK team asks the solutions team to adopt their tools. The solutions team resists: “Too immature, slows us down. We’ll just use the API directly.” The SDK team can’t mature the tools without production use cases. Meanwhile, internal users/engineers, who are eager to build things quickly, just bypass both teams entirely and use OpenAI or Anthropic APIs directly, sometimes with nothing more than a prompt file and a Python script.</p>
<p>Both sides are frustrated, and both sides have valid concerns. The SDK team genuinely wants to help because they’re trying to prevent chaos and technical debt. The solutions team isn’t being difficult because they face demands from users and they’re trying to ship products under real deadlines.</p>
<p>This post examines why internal SDK teams struggle with adoption, even when building technically sound tools, and what actually works based on my experience building and using AI SDKs.</p>
<section id="conways-law-building-in-isolation" class="level2">
<h2 class="anchored" data-anchor-id="conways-law-building-in-isolation">Conway’s Law: Building in Isolation</h2>
<p>The typical model looks like this. An SDK team operates separately from solution teams, building an SDK based on what “users should (or would) want” based on some hypotheses. They push adoption without proving that it solves real problems. Features get built speculatively, before patterns emerge from actual use cases, which naturally creates user alienation and resistance. This isn’t malice—it’s an organizational structure problem. The reasoning seems sound: “We need reusable tooling before use cases proliferate. If we don’t build this now, we’ll have chaos later.”</p>
<p>But the consequences are predictable. With no production use cases driving requirements, the SDK team keeps building features based on hypotheticals, leading to over-engineering or feature mismatch. Adoption stays low because for solution engineers, this just feels like another unnecessary layer. The cycle repeats.</p>
<p>The issue isn’t technical capability. The teams are structurally set up to not collaborate effectively. Whether the motivation for an SDK is vendor independence, cost governance, or developer experience, the adoption problem remains the same: you can’t build a good SDK for a problem space you haven’t explored through real applications. One would say we can still build an SDK for general features, but then why would we need this additional layer in the first place?</p>
<p><a href="https://en.wikipedia.org/wiki/Conway%27s_law">Conway’s Law</a> is at work here. Team boundaries create tool boundaries. When SDK engineers operate in isolation, they build isolated tools.</p>
</section>
<section id="paved-roads-rather-than-golden-paths" class="level2">
<h2 class="anchored" data-anchor-id="paved-roads-rather-than-golden-paths">“Paved Roads” Rather Than “Golden Paths”</h2>
<p>The alternative approach requires <strong>SDK engineers to embed with solution teams and build 2-3 real applications themselves first</strong>. SDK engineers can extract common patterns into an SDK after they see repetition across use cases. Then, they bring their SDK to maturity by continuing to apply and validate it with new and existing use cases. This embedding approach creates an <strong>immediate feedback loop</strong>. SDK engineers experience user pain firsthand, not through filtered feature requests. When they’ve used their own tools in production, credibility and adoption come naturally. The solutions team sees them as peers who understand their constraints, not outsiders pushing tools.</p>
<p>This connects to an important engineering concept: <a href="https://mia-platform.eu/blog/paved-roads-golden-paths-guardrails-railroads/">“paved road” vs.&nbsp;“golden path.”</a></p>
<ul>
<li><strong>Golden path</strong> provides one blessed way. High opinions, low flexibility. The SDK makes strong assumptions about your workflow and enforces them.</li>
<li><strong>Paved road</strong> makes the right thing easy but doesn’t prevent alternatives. Lower opinions, high flexibility. The SDK helps you do common things quickly but doesn’t lock you in.</li>
</ul>
<p>Both have pros and cons, but <strong>for AI development, paved roads are the better choice</strong>, at least initially. LLM APIs, frameworks, and best practices shift rapidly, and the whole process requires experimentation: trying different retrieval strategies, testing model combinations, iterating on evaluation approaches. Golden paths lock in workflows before understanding their true utilities. In large organizations, they often become bureaucratic blockers that slow down the very innovation they’re meant to enable.</p>
<p>But paved roads alone can invite chaos. This is where <strong>guardrails</strong> come in: automated safety nets that constrain consequences without constraining methods. For instance, cost controls like budget alerts and rate limiting prevent runaway spending. Security and compliance measures like audit trails and PII detection prevent data leaks. Observability provides visibility into what’s happening across applications. These guardrails don’t dictate <em>how</em> engineers build. Rather, they protect against what can go wrong.</p>
<p>Golden paths would make sense later once patterns have stabilized and standardization provides clear value. Organizations fail when they try to build mature-stage SDKs at early-stage maturity. If you have fewer than five clear production use cases with high utility, you might not need a comprehensive SDK with golden paths. You need to focus on building applications that work, and pay attention to what hurts.</p>
</section>
<section id="but-we-need-to-scale-fast" class="level2">
<h2 class="anchored" data-anchor-id="but-we-need-to-scale-fast">“But We Need to Scale Fast”</h2>
<p>This advice sounds reasonable for small teams. But what about organizations that need to scale AI adoption quickly?</p>
<p>Let’s be real: the pressure is on. Many companies want to ramp up AI across their organizations quickly. They have dozens of ML engineers or data scientists, who need to transition to AI engineering. Every team wants AI work, and leadership is expecting 10x returns on their LLM investments. The tempting response is to build the SDK first so everyone has something to standardize around. But it actually makes things worse because you’re locking in abstractions before understanding the problem space.</p>
<p>The key is to <strong>deploy AI engineers to highest-priority use cases immediately without waiting for the SDK</strong>. Let them document pain points as they build. After 2-3 apps ship, they will see real patterns, and can extract those specific things. They can then start building focused utilities that address observed pain. Starting with the smallest thing that provides value always works.</p>
<p>I would also suggest not to create a separate SDK team. It is much better to have <strong>engineer rotation between app and SDK work</strong>, which builds organic collaboration, robust team knowledge, and empathy, all at once. For instance, engineers spend a month building an app, then spend the next month extracting patterns into shared tooling, then back to a new app. This rotation keeps SDK work grounded in reality. Engineers understand both perspectives because they’ve lived both.</p>
<p>But more importantly, management must understand that <strong>project selection requires ruthlessness.</strong> Not all “high priority” projects are actually good candidates for early AI work. Good candidates have clear, bounded scope, not wishlist-type scope creep. They have easily measurable results and eval setup that can be iterated fast. Most importantly, they need engaged domain experts who collaborate actively, not senior stakeholders who over-promise and then disappear. And these criteria should create healthy competition across teams. Teams that can’t provide clear scopes aren’t suitable for ML/AI adoption. It’s better to learn this early than to commit engineers to projects destined to fail. Organizations that try to skip this learning phase end up rebuilding their SDKs after real applications expose the mismatches.</p>
</section>
<section id="what-to-focus-sdk-efforts-on" class="level2">
<h2 class="anchored" data-anchor-id="what-to-focus-sdk-efforts-on">What to Focus SDK Efforts On</h2>
<p>This doesn’t mean all early SDK work is bad. The <strong>guardrails</strong> discussed earlier are exactly what SDK teams should focus on first; automated safety nets that protect without constraining how engineers build. In my experience, some areas provide high value with low controversy:</p>
<p><strong>Observability and telemetry are good starting points.</strong> They address a universal need non-intrusively: cost tracking per query/user/project, performance monitoring for latency/token usage/error rates, and so on. You can add these via decorators without refactoring user code. For example, OpenTelemetry-based instrumentation that wraps any module gives teams visibility without forcing them to change their application logic.</p>
<p><strong>Governance and compliance become critical as applications mature.</strong> Audit trails for all LLM interactions, data sanitization and PII detection against potential leaks, budget alerts and spend tracking to prevent cost spirals, and access control and rate limiting against abuse. These protections make everyone’s life easier and guarantee compliance.</p>
<p><strong>Developer experience (DX) improvements should focus on reducing friction.</strong> Config templates encode best practices so engineers don’t start from scratch. Better error messages with actionable guidance instead of cryptic stack traces. Idempotency checks prevent duplicate operations. None of these are glamorous, but they’re what engineers actually thank you for.</p>
<p>But I’d recommend NOT abstracting:</p>
<p><strong>LLM provider APIs</strong> are too volatile because they change weekly. Let <a href="https://docs.litellm.ai/docs/">LiteLLM</a> or <a href="https://openrouter.ai/">OpenRouter</a> or similar tools handle this. Your abstraction will lag behind updates and become a bottleneck.</p>
<p><strong>Vector database query languages</strong> are evolving rapidly. Whatever abstraction you build will be outdated within months. Give users direct access.</p>
<p><strong>Framework-specific patterns</strong> like LangChain or LlamaIndex are moving targets. Don’t wrap them. If users choose those frameworks, they’ve already accepted that dependency.</p>
<p>The principle I’ve found helpful: abstract stable interfaces (authentication, observability, governance) from volatile ones (LLM APIs, retrieval strategies). The SDK should make the boring stuff invisible and stay out of the way for the interesting stuff.</p>
</section>
<section id="concrete-example-what-made-rag-wrapper-work" class="level2">
<h2 class="anchored" data-anchor-id="concrete-example-what-made-rag-wrapper-work">Concrete Example: What Made RAG Wrapper Work</h2>
<p>In my experience building AI SDKs, I developed a RAG wrapper library that got organic adoption from engineers despite broader SDK adoption challenges in the organization. When I joined the solutions team after my SDK work, I experienced the resistance to the broader adoption firsthand. Engineers saw it as “yet another layer to learn” with unclear benefits. The SDK team had skipped the teaching phase entirely (releasing docs and expecting adoption without demonstrating value or dogfooding their own tools).</p>
<p>Fortunately, before building the wrapper, I worked with teams building RAG applications. After helping build several different pipelines, patterns emerged. Teams spent hours on boilerplate setup, copying similar code between projects. Every team needed custom preprocessing, but in slightly different ways depending on their document types. This experience helped me build these features:</p>
<p><strong>Config-based quick start</strong> emerged from watching teams copy-paste the same 50 lines of setup code. Engineers could get a working RAG pipeline in minutes with YAML config instead of learning a new API. Lower barrier meant more people would try it.</p>
<p><strong>Extensibility via custom preprocessors</strong> came after the third team asked “can I customize just the chunking logic?” Inspired by sklearn’s pipeline pattern (familiar to ML engineers and data scientists), users could build their own preprocessing pipeline through the config while keeping the rest of the workflow standard.</p>
<p><strong>Idempotency and duplicate detection</strong> came from debugging a team’s duplicate content issue that caused retrieval quality and eval data contamination problems. Content hashing at ingestion time prevented duplicate uploads and flagged potential training/validation data leakage, turning this into a safety net.</p>
<p><strong>Product mindset for internal tools</strong> meant treating it like a real product. As a firm believer of good communication, I provided detailed documentation with live step-by-step demos, structured feature requests, and 1:1 support conversations to understand needs before and after building.</p>
<p>The value proposition was straightforward because it had <strong>lower activation energy</strong> than learning LangChain or LlamaIndex from scratch, but <strong>more structure than raw API calls</strong>. Engineers could start with a standard pipeline in minutes, then customize specific components (embeddings, chunking, retrieval strategy) without learning an entire framework. For teams that needed RAG but didn’t want to become LangChain experts, this was the middle path.</p>
<p>Adoption happened organically. A few engineers experimented, found it useful, and told others. The features that got the most use were ones I have built to solve friction I have experienced myself. The library wasn’t comprehensive but it did address real pain points users hit repeatedly.</p>
</section>
<section id="closing-remarks" class="level2">
<h2 class="anchored" data-anchor-id="closing-remarks">Closing Remarks</h2>
<p>The most common mistake organizations make with AI SDKs is treating them as technical problems when they’re actually organizational design problems. You can hire the best engineers, give them all the resources, and still fail if the team structure doesn’t support collaboration between builders and users.</p>
<p>The uncomfortable truth is that most organizations aren’t ready for comprehensive AI SDKs yet. If you have only a couple of production applications with clear scope and utility (and chances are you don’t even have an application that meets the criteria), you don’t need golden-path abstraction layers. You need engineers building things that actually work and documenting the learning. The SDK comes later, extracted from observed patterns rather than hypothetical needs.</p>
<p>This requires patience that conflicts with institutional pressure to “scale AI fast.” Leadership wants standardization now. But premature standardization is worse than no standardization at all because it locks in the wrong patterns leading to technical debt, and creates friction that slows down the innovation.</p>
<p>The question to ask isn’t “Is this SDK technically sound?” but “Have we proven this solves a real problem for actual users?” If you can’t point to specific engineers who asked for specific features based on specific pain points, you’re probably building in isolation. And isolation, however well-intentioned, leads to tools that gather dust.</p>
<hr>
<p><em>If you found this post useful, you can cite it as:</em></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bibtex code-with-copy"><code class="sourceCode bibtex"><span id="cb1-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">@article</span>{</span>
<span id="cb1-2">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">hongsupshin</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">2026</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">ai</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">sdk</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">adoption</span>,</span>
<span id="cb1-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">author</span> = {Hongsup Shin},</span>
<span id="cb1-4">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">title</span> = {The AI SDK Adoption Problem: When Conway's Law Meets AI Engineering},</span>
<span id="cb1-5">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">year</span> = {2026},</span>
<span id="cb1-6">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span> = {1},</span>
<span id="cb1-7">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">day</span> = {24},</span>
<span id="cb1-8">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">howpublished</span> = {<span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\url</span>{https://hongsupshin.github.io}},</span>
<span id="cb1-9">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">journal</span> = {Hongsup Shin's Blog},</span>
<span id="cb1-10">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">url</span> = {https://hongsupshin.github.io/posts/2026-01-24-conway-law/},</span>
<span id="cb1-11">}</span></code></pre></div></div>


</section>

 ]]></description>
  <category>AI</category>
  <category>SDK-design</category>
  <category>engineering-leadership</category>
  <category>AIOps</category>
  <guid>https://hongsupshin.github.io/posts/2026-01-24-conway-law/</guid>
  <pubDate>Sat, 24 Jan 2026 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2026-01-24-conway-law/fig.png" medium="image" type="image/png" height="128" width="144"/>
</item>
<item>
  <title>LangGraph Error Handling Patterns in Production</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2026-01-12/</link>
  <description><![CDATA[ 





<p>Everyone says you can build an agent in several lines of code. Making it work in production is a different story. APIs timeout, LLMs hallucinate recovery strategies, users provide incomplete data, and the workflow needs to handle all of it gracefully without cascading failures.</p>
<p>In traditional software, you catch exceptions, log them, and maybe retry. In agent systems, this approach does not work efficiently because <strong>the right recovery strategy depends on error semantics, not just error types</strong>. For instance, a timeout should retry automatically, but an “email format invalid” error needs semantic understanding to fix. Besides, for a problem that requires human intervention, the system needs to pause and seek out human input. This differs depending on whether you need information from users or need developers to debug the system.</p>
<p>Agent workflows are multi-step and autonomous. An error in an intermediate step shouldn’t just bubble up. It might need retry logic, LLM reasoning to adapt, or user clarification to continue. Treating all errors the same leads to cascading failures or stuck workflows. This post covers four error handling patterns for LangGraph agent systems, each mapping to a fundamentally different recovery mechanism:</p>
<ol type="1">
<li><strong>Retry with Backoff</strong> (Time-based): wait and try again (no decision needed)</li>
<li><strong>LLM-Guided Recovery</strong> (Semantic): LLM reasons about context and chooses action</li>
<li><strong>Human-in-the-Loop</strong> (External information): only humans can provide what’s needed</li>
<li><strong>Unexpected Failures</strong> (Unrecoverable): surface to developers immediately</li>
</ol>
<p>This post is inspired by a <a href="https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph">LangGraph tutorial</a>. The tutorial covers basic concepts of the errors but not the full practical implementations. In this post, we will discuss a more detailed walkthrough of each error type such as when to use each pattern, code examples for different workflows, and architecture for testing error scenarios.</p>
<p>We’ll use the familiar and simple email support agent (the same one from the above-mentioned tutorial) as an example throughout. This way, we can focus on error handling patterns rather than understanding complex business logic.</p>
<p>All code is available <a href="https://github.com/hongsupshin/hongsupshin.github.io/tree/main/posts/2026-01-12/code">here</a>. The figure below shows the workflow overview of the email support agent system.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2026-01-12/workflow_diagram.png" class="quarto-figure quarto-figure-center figure-img" height="500"></p>
</figure>
</div>
<section id="langgraph-quick-start" class="level2">
<h2 class="anchored" data-anchor-id="langgraph-quick-start">LangGraph Quick Start</h2>
<section id="core-concepts" class="level3">
<h3 class="anchored" data-anchor-id="core-concepts">Core Concepts</h3>
<p>Let’s quickly review the key concepts of LangGraph.</p>
<p><strong>1. State = Workflow Memory (Data)</strong></p>
<p>State is a typed object (Pydantic model or TypedDict) that flows through your workflow; I prefer <strong>Pydantic</strong> over TypedDict for runtime validation and better error messages. Think of a state as a comprehensive list of data fields in your agent system. You should be able to fully design the system first before defining a state. Every node reads it and returns updates:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> EmailState(BaseModel):</span>
<span id="cb1-4">    email_content: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-5">    sender_email: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb1-6">    classification: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb1-7">    draft_response: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb1-8">    reply_sent: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span></code></pre></div></div>
<p><strong>2. Nodes = Processing Functions</strong></p>
<p>Nodes transform state and return updates. Each node reads the current state, performs a specific task (like calling an API or running an LLM), and returns updates to merge back into state:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> classify_email(state: EmailState) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>:</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Returns dict; updates merged into state."""</span></span>
<span id="cb2-3">    classification <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.invoke(state.email_content)</span>
<span id="cb2-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classification"</span>: classification}</span></code></pre></div></div>
<p><strong>3. Command = State Update + Routing</strong></p>
<p>The <code>Command</code> lets nodes do two things at once: update the state AND decide where to go next. Without <code>Command</code>, nodes only return state updates and go to <em>pre-defined</em> edges. With <code>Command</code>, a node can make routing decisions dynamically based on what it just processed. This is useful when the next step depends on the results of the current node:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.types <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Command</span>
<span id="cb3-2"></span>
<span id="cb3-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> classify_email(state: EmailState) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Command[Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"search_docs"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bug_tracker"</span>]]:</span>
<span id="cb3-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Returns Command; updates state AND decides next node."""</span></span>
<span id="cb3-5">    classification <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.invoke(state.email_content)</span>
<span id="cb3-6">    next_node <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"search_docs"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> classification.intent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bug_tracker"</span></span>
<span id="cb3-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Command(</span>
<span id="cb3-8">        update<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classification"</span>: classification},</span>
<span id="cb3-9">        goto<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>next_node  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Dynamic routing</span></span>
<span id="cb3-10">    )</span></code></pre></div></div>
<p><strong>4. Workflows = The Big Picture</strong></p>
<p>Workflows connect all your nodes together into an execution graph. Using <code>StateGraph</code>, you define which nodes exist, how they connect to each other, and the order of execution. Think of it as drawing a flowchart; you specify the starting point, the processing steps (nodes), and the paths between them (edges). Once you compile the workflow, you have a complete agent system ready to execute:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StateGraph, START, END</span>
<span id="cb4-2"></span>
<span id="cb4-3">workflow <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(EmailState)</span>
<span id="cb4-4">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classify"</span>, classify_email)</span>
<span id="cb4-5">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"search_docs"</span>, search_documentation)</span>
<span id="cb4-6">workflow.add_edge(START, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classify"</span>)</span>
<span id="cb4-7">workflow.add_conditional_edges(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classify"</span>, [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"search_docs"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bug_tracker"</span>])</span>
<span id="cb4-8">workflow.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"search_docs"</span>, END)</span>
<span id="cb4-9"></span>
<span id="cb4-10">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> workflow.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span></code></pre></div></div>
<p>You can visualize workflows in several ways. For command-line scripts, <code>print(workflow.get_graph().draw_ascii())</code> outputs an ASCII diagram directly to the terminal. For richer visualizations, <code>workflow.get_graph().draw_mermaid()</code> generates Mermaid diagram code you can paste into mermaid.live. For Jupyter notebooks, compiled workflows’ diagram can be rendered in output cells (i.e., simply return <code>app</code> in a cell).</p>
<p><strong>5. Execution</strong></p>
<p>Once you’ve compiled your workflow, call <code>invoke()</code> with your initial state and the workflow runs through the graph. This executes nodes and follows edges until it reaches the <code>END</code>. You get back the final state with all updates from every node that ran:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> app.invoke({</span>
<span id="cb5-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"email_content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"I forgot my password"</span>,</span>
<span id="cb5-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sender_email"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user@example.com"</span></span>
<span id="cb5-4">})</span>
<span id="cb5-5"></span>
<span id="cb5-6"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(result[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"draft_response"</span>])</span></code></pre></div></div>
<p>Note that LangGraph workflows are <strong>compiled</strong>. Once you call <code>.compile()</code>, node functions are locked in. To test different behaviors (like error simulation), you must rebuild the workflow with different node implementations. This is why modular architecture matters.</p>
</section>
<section id="testing-pattern-workflow-builders" class="level3">
<h3 class="anchored" data-anchor-id="testing-pattern-workflow-builders">Testing Pattern: Workflow Builders</h3>
<p>Since workflows are compiled and immutable, testing different behaviors requires rebuilding with node overrides. The <code>build_workflow()</code> helper function constructs and compiles a <code>StateGraph</code> while allowing you to swap in different node implementations for testing:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Production version</span></span>
<span id="cb6-2">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> build_workflow()</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Test version with simulated error</span></span>
<span id="cb6-5">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> build_workflow(</span>
<span id="cb6-6">    nodes_override<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"search_docs"</span>: search_with_error}</span>
<span id="cb6-7">)</span></code></pre></div></div>
<p>This pattern keeps production code clean while enabling deterministic error testing. Examples throughout use this approach. Full code structure available in the [GitHub repo].</p>
</section>
<section id="observability-tools" class="level3">
<h3 class="anchored" data-anchor-id="observability-tools">Observability Tools</h3>
<p>LangGraph workflows benefit from observability tools that trace execution, inspect state at each step, and visualize error scenarios. <a href="https://docs.langchain.com/langsmith/studio">LangSmith Studio</a> is the primary tool for this. It provides real-time execution traces, state snapshots at each node, and visual debugging of workflow paths. To enable tracing, set your LangSmith API key and configure tracing before building your workflow. Once enabled, every workflow invocation automatically logs to LangSmith, where you can inspect the full execution graph, timing data, and state transitions:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb7-2">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LANGCHAIN_TRACING_V2"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"true"</span></span>
<span id="cb7-3">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LANGCHAIN_API_KEY"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"your-api-key"</span></span>
<span id="cb7-4">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"LANGCHAIN_PROJECT"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"error-handling-demo"</span></span>
<span id="cb7-5"></span>
<span id="cb7-6">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> build_workflow()</span>
<span id="cb7-7">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> app.invoke(initial_state)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Automatically traced to LangSmith</span></span></code></pre></div></div>
<p>Note that this tracing is available for notebook code cells.</p>
</section>
</section>
<section id="error-handling-and-recovery-patterns" class="level2">
<h2 class="anchored" data-anchor-id="error-handling-and-recovery-patterns">Error Handling and Recovery Patterns</h2>
<section id="overview-the-decision-framework" class="level3">
<h3 class="anchored" data-anchor-id="overview-the-decision-framework">Overview: The Decision Framework</h3>
<p>Here’s a quick reference for matching error types to recovery patterns:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 15%">
<col style="width: 21%">
<col style="width: 31%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Pattern</th>
<th>When to Use</th>
<th>LangGraph Feature</th>
<th>Recovery Strategy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Retry with Backoff</strong></td>
<td>Network failures, rate limits, temporary outages</td>
<td><code>RetryPolicy</code></td>
<td>Automatic retry with exponential backoff</td>
</tr>
<tr class="even">
<td><strong>LLM-Guided Recovery</strong></td>
<td>Errors with semantic context LLM can understand and fix</td>
<td>Circular routing</td>
<td>LLM decides recovery action</td>
</tr>
<tr class="odd">
<td><strong>Human-in-the-Loop</strong></td>
<td>Missing data only user can provide, high-stakes decisions</td>
<td><code>interrupt()</code></td>
<td>Pause and request human input</td>
</tr>
<tr class="even">
<td><strong>Unexpected Failures</strong></td>
<td>Unknown errors, bugs, critical infrastructure failures</td>
<td>Exception bubbling</td>
<td>Log context, bubble up to developers</td>
</tr>
</tbody>
</table>
</section>
<section id="pattern-1-retry-with-backoff" class="level3">
<h3 class="anchored" data-anchor-id="pattern-1-retry-with-backoff">Pattern 1: Retry with Backoff</h3>
<p>This pattern uses automatic retry with exponential backoff to handle transient failures like network timeouts, rate limits (429), and temporary service outages (503).</p>
<p>The key is to <strong>use <code>RetryPolicy</code> when adding a node to a workflow</strong>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.types <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RetryPolicy</span>
<span id="cb8-2"></span>
<span id="cb8-3">workflow.add_node(</span>
<span id="cb8-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"search_documentation"</span>,</span>
<span id="cb8-5">    search_documentation,</span>
<span id="cb8-6">    retry_policy<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>RetryPolicy(max_attempts<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, backoff_base<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb8-7">)</span></code></pre></div></div>
<p>The <code>backoff_base</code> parameter controls exponential backoff timing: <code>backoff_base=2</code> means wait times follow 2^0=1s, 2^1=2s, 2^2=4s, etc.</p>
<p>The workflow attempts the failing node 3 times with exponential backoff. Attempt 1 raises <code>SearchAPIError</code> and retries in 1 second. Attempt 2 raises the same error and retries in 2 seconds. Attempt 3 succeeds and the workflow continues normally. (In LangSmith Studio, you’ll see 3 separate executions of the node with exponential backoff timing.)</p>
<p>This pattern is unsuitable for errors that won’t resolve with retry (like bad API keys or malformed requests), errors that need user input, or errors requiring semantic understanding to fix.</p>
<hr>
</section>
<section id="pattern-2-llm-guided-recovery" class="level3">
<h3 class="anchored" data-anchor-id="pattern-2-llm-guided-recovery">Pattern 2: LLM-Guided Recovery</h3>
<p>This pattern stores errors in state and routes to an LLM agent that decides the recovery action. Use it for errors with semantic information an LLM can understand and fix.</p>
<p>We handle this by <strong>creating an agent node that uses <code>Command</code> with <code>goto</code> to route dynamically based on state</strong>. Instead of raising exceptions, nodes store errors in state and return to the agent:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.types <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Command</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> agent(state: EmailState) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Command[Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"get_customer_history"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"normalize_email"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"draft_response"</span>]]:</span>
<span id="cb9-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Agent examines state and decides next action."""</span></span>
<span id="cb9-5">    decision <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.invoke(state)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># LLM decides based on state</span></span>
<span id="cb9-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Command(goto<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>decision.next_action)</span>
<span id="cb9-7"></span>
<span id="cb9-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_customer_history(state):</span>
<span id="cb9-9">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Node stores errors instead of raising."""</span></span>
<span id="cb9-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> has_error:</span>
<span id="cb9-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"customer_history"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"error"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"..."</span>}}  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Store error</span></span>
<span id="cb9-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"customer_history"</span>: {...}}  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Store result</span></span>
<span id="cb9-13"></span>
<span id="cb9-14">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"agent"</span>, agent)</span>
<span id="cb9-15">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"get_customer_history"</span>, get_customer_history)</span>
<span id="cb9-16">workflow.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"get_customer_history"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"agent"</span>)  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Always route back to agent</span></span></code></pre></div></div>
<p>The recovery flow cycles through the agent node multiple times:</p>
<ol type="1">
<li>First, <code>get_customer_history</code> fails due to mixed-case email, stores the error, and routes to <code>agent</code>.</li>
<li>The LLM agent sees the error and decides to call <code>normalize_email</code>.</li>
<li>After normalizing the email, it routes back to <code>agent</code>, which decides to retry <code>get_customer_history</code>. This time it succeeds and routes to <code>agent</code> again.</li>
<li>The agent sees valid data and decides to proceed with <code>draft_response</code>.</li>
</ol>
<p>In LangSmith Studio, we can watch the circular path through the agent node and see LLM reasoning for each decision.</p>
<p>Note that the agent’s return type <code>Command[Literal["get_customer_history", "normalize_email", "draft_response"]]</code> explicitly lists all possible routing destinations. This provides type safety and serves as documentation showing the full decision space. If you add new recovery paths, update this type hint.</p>
<p>Use this pattern when error messages contain semantic information LLMs can parse, when multiple potential recovery strategies exist, or when the best action depends on contextual understanding. Avoid it for simple errors with deterministic recovery (use conditional edges instead), errors that need human judgment, or when high-latency is a concern (each agent call requires one LLM inference).</p>
<section id="preventing-infinite-loops" class="level4">
<h4 class="anchored" data-anchor-id="preventing-infinite-loops">Preventing infinite loops</h4>
<p>Since this pattern creates circular routing, add safeguards to prevent infinite loops (e.g., <code>MaxIterationsError</code>):</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> EmailState(BaseModel):</span>
<span id="cb10-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ... other fields ...</span></span>
<span id="cb10-3">    iteration_count: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb10-4">    max_iterations: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb10-5"></span>
<span id="cb10-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> agent(state: EmailState) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Command[...]:</span>
<span id="cb10-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Check iteration limit</span></span>
<span id="cb10-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> state.iteration_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> state.max_iterations:</span>
<span id="cb10-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> MaxIterationsError(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Agent exceeded </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>state<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>max_iterations<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> iterations"</span>)</span>
<span id="cb10-10"></span>
<span id="cb10-11">    decision <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.invoke(state)</span>
<span id="cb10-12"></span>
<span id="cb10-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Command(</span>
<span id="cb10-14">        update<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"iteration_count"</span>: state.iteration_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>},</span>
<span id="cb10-15">        goto<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>decision.next_action</span>
<span id="cb10-16">    )</span></code></pre></div></div>
<p>Alternatively, you can also track specific error types or visited actions to detect stuck states.</p>
<hr>
</section>
</section>
<section id="pattern-3-human-in-the-loop" class="level3">
<h3 class="anchored" data-anchor-id="pattern-3-human-in-the-loop">Pattern 3: Human-in-the-Loop</h3>
<p>This pattern uses <code>interrupt()</code> to pause workflow execution and request human input. Use it when missing data only users can provide, handling ambiguous requests, or making high-stakes decisions.</p>
<p>The key is to <strong>use <code>interrupt()</code> inside a node to pause execution and compile the workflow with a checkpointer.</strong> Resume by invoking with <code>Command(resume=...)</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.types <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> interrupt, Command</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.checkpoint.memory <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MemorySaver</span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> node_with_interrupt(state):</span>
<span id="cb11-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> needs_user_input:</span>
<span id="cb11-6">        user_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> interrupt({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"request"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Please provide X"</span>})</span>
<span id="cb11-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Command(</span>
<span id="cb11-8">            update<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"field"</span>: user_data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"field"</span>]},</span>
<span id="cb11-9">            goto<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"node_with_interrupt"</span>  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Recursive until condition met</span></span>
<span id="cb11-10">        )</span>
<span id="cb11-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Continue normally</span></span>
<span id="cb11-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"result"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"..."</span>}</span>
<span id="cb11-13"></span>
<span id="cb11-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compile with checkpointer (required for interrupt/resume)</span></span>
<span id="cb11-15">checkpointer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MemorySaver()</span>
<span id="cb11-16">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> workflow.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>(checkpointer<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>checkpointer)</span>
<span id="cb11-17"></span>
<span id="cb11-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Part 1: Trigger interrupt</span></span>
<span id="cb11-19">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> app.invoke(initial_state, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configurable"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"thread_id"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1"</span>}})</span>
<span id="cb11-20"></span>
<span id="cb11-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Part 2: Resume with user input</span></span>
<span id="cb11-22">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> app.invoke(</span>
<span id="cb11-23">    Command(resume<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"field"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user_value"</span>}),</span>
<span id="cb11-24">    config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configurable"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"thread_id"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1"</span>}}</span>
<span id="cb11-25">)</span></code></pre></div></div>
<p>The node detects missing <code>customer_id</code>, calls <code>interrupt()</code> with a request payload, and the workflow pauses and returns the payload to the caller. After the human provides the <code>customer_id</code>, the workflow resumes from the same node with updated state. The node sees that <code>customer_id</code> now exists and continues normally. Note the recursive pattern: the node calls <code>goto="search_docs"</code> (itself) after getting user input, creating a loop until the condition is satisfied. (In LangSmith Studio, you’ll see the workflow paused at the node with the interrupt payload, then the resumed continuation.)</p>
<p>Use this pattern when you need required data only users have (account IDs, preferences, clarifications), high-risk actions needing approval (delete data, financial transactions), or ambiguous requests needing clarification. Critical requirement: <strong>you must use a checkpointer to maintain memory</strong> of workflow state between invocations.</p>
<hr>
</section>
<section id="pattern-4-unexpected-failures" class="level3">
<h3 class="anchored" data-anchor-id="pattern-4-unexpected-failures">Pattern 4: Unexpected Failures</h3>
<p>This pattern logs context then re-raises the exception—don’t catch what you can’t handle. Use it for bugs, edge cases, and critical infrastructure failures. In this case, we <strong>log state context for debugging, then re-raise the exception without attempting recovery</strong>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> node_with_unexpected_errors(state):</span>
<span id="cb12-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb12-3">        result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> risky_operation()</span>
<span id="cb12-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"result"</span>: result}</span>
<span id="cb12-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> UnexpectedError <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> e:</span>
<span id="cb12-6">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Log context</span></span>
<span id="cb12-7">        logger.error(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Error: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>e<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, State: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>state<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>()<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb12-8">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Re-raise - don't recover</span></span>
<span id="cb12-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span></span></code></pre></div></div>
<p>When the node encounters an unexpected error, it logs state context for debugging, re-raises the exception without attempting recovery, and the workflow fails immediately. LangSmith captures the full state at the failure point. (In LangSmith Studio, you’ll see a red error icon on the failed node with the stack trace and state snapshot.)</p>
<p>Use this pattern for infrastructure failures (database down, API 500 errors), programming bugs (unexpected data types, null references), security violations, or any error where “continuing anyway” would be worse than stopping. Don’t catch exceptions you can’t meaningfully handle—let them bubble up to your monitoring system where they trigger alerts with full context. In production, connect to error monitoring tools like Sentry or Datadog for alerting. LangSmith Studio provides tracing and debugging visibility but isn’t designed for incident response.</p>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>We’ve covered four distinct error handling patterns, each designed for different failure modes. The decision framework boils down to one question: how should the system recover? Transient failures need time, semantic errors need reasoning, missing data needs human input, and unexpected failures need developer attention. Here’s a quick reference mapping common scenarios to their appropriate patterns:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 30%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th>Scenario</th>
<th>Pattern</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>API timeout</td>
<td><span style="color: #0066CC;"><strong>Retry with Backoff</strong></span></td>
<td>Transient - likely succeeds on retry</td>
</tr>
<tr class="even">
<td>Rate limit (429)</td>
<td><span style="color: #0066CC;"><strong>Retry with Backoff</strong></span></td>
<td>Temporary - retry after backoff</td>
</tr>
<tr class="odd">
<td>Database query timeout</td>
<td><span style="color: #0066CC;"><strong>Retry with Backoff</strong></span></td>
<td>Connection issue - often resolves quickly</td>
</tr>
<tr class="even">
<td>Third-party service unavailable (503)</td>
<td><span style="color: #0066CC;"><strong>Retry with Backoff</strong></span></td>
<td>Service may recover within seconds</td>
</tr>
<tr class="odd">
<td>CRM (Customer Relationship Management) returns error message</td>
<td><span style="color: #00AA00;"><strong>LLM-Guided Recovery</strong></span></td>
<td>LLM can adapt response to missing data</td>
</tr>
<tr class="even">
<td>Invalid email format</td>
<td><span style="color: #00AA00;"><strong>LLM-Guided Recovery</strong></span></td>
<td>LLM can normalize and retry</td>
</tr>
<tr class="odd">
<td>Malformed JSON in API response</td>
<td><span style="color: #00AA00;"><strong>LLM-Guided Recovery</strong></span></td>
<td>LLM can extract data despite formatting issues</td>
</tr>
<tr class="even">
<td>Ambiguous user query</td>
<td><span style="color: #00AA00;"><strong>LLM-Guided Recovery</strong></span></td>
<td>LLM can reformulate or add context</td>
</tr>
<tr class="odd">
<td>Missing user preference</td>
<td><span style="color: #FF8800;"><strong>Human-in-the-Loop</strong></span></td>
<td>Only user knows their preference</td>
</tr>
<tr class="even">
<td>Delete confirmation</td>
<td><span style="color: #FF8800;"><strong>Human-in-the-Loop</strong></span></td>
<td>High-stakes action needs approval</td>
</tr>
<tr class="odd">
<td>Payment amount approval</td>
<td><span style="color: #FF8800;"><strong>Human-in-the-Loop</strong></span></td>
<td>Financial decision requires human judgment</td>
</tr>
<tr class="even">
<td>Account ID for lookup</td>
<td><span style="color: #FF8800;"><strong>Human-in-the-Loop</strong></span></td>
<td>User-specific data only they can provide</td>
</tr>
<tr class="odd">
<td>Database connection lost</td>
<td><span style="color: #CC0000;"><strong>Unexpected Failures</strong></span></td>
<td>Infrastructure issue - can’t recover</td>
</tr>
<tr class="even">
<td>Null reference error</td>
<td><span style="color: #CC0000;"><strong>Unexpected Failures</strong></span></td>
<td>Programming bug - needs investigation</td>
</tr>
<tr class="odd">
<td>Authentication service down</td>
<td><span style="color: #CC0000;"><strong>Unexpected Failures</strong></span></td>
<td>Critical dependency failure</td>
</tr>
<tr class="even">
<td>Permission denied on resource</td>
<td><span style="color: #CC0000;"><strong>Unexpected Failures</strong></span></td>
<td>Security/configuration issue needs fixing</td>
</tr>
</tbody>
</table>
<p>This guide covered four distinct error handling patterns, each designed for different failure modes. <strong>Retry with Backoff</strong> handles transient failures that resolve automatically with time. <strong>LLM-Guided Recovery</strong> uses the LLM to decide recovery actions for semantic errors that require reasoning. <strong>Human-in-the-Loop</strong> pauses workflow execution when missing data or decisions require human input. <strong>Unexpected Failures</strong> log context and bubble up to developers when the system can’t meaningfully recover.</p>
<p>LangGraph workflows are compiled, meaning node functions lock in after calling <code>.compile()</code>. To test different behaviors, you must rebuild the workflow with <code>nodes_override</code> to swap in alternative node implementations. This design choice is why modular architecture matters—it enables deterministic testing without polluting production code. Test utilities provide controlled error simulation, making it easy to validate recovery behavior from notebooks or CLI.</p>
<p>Use LangSmith Studio to observe workflow execution in real-time. It provides execution traces, state inspection at each step, and full context for debugging errors. For production monitoring and alerting, integrate with dedicated tools like Sentry or Datadog—Studio is excellent for development visibility but not designed for incident response.</p>
<p>Error handling in agent systems is more complex because we have semantic errors that require different recovery patterns than typical software engineering. The key is matching the recovery pattern to error characteristics.</p>
<hr>
<p><em>If you found this post useful, you can cite it as:</em></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode bibtex code-with-copy"><code class="sourceCode bibtex"><span id="cb13-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">@article</span>{</span>
<span id="cb13-2">    <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">hongsupshin</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">2026</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">langgraph</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">error</span>-<span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">handling</span>,</span>
<span id="cb13-3">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">author</span> = {Hongsup Shin},</span>
<span id="cb13-4">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">title</span> = {LangGraph Error Handling Patterns in Production},</span>
<span id="cb13-5">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">year</span> = {2026},</span>
<span id="cb13-6">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">month</span> = {1},</span>
<span id="cb13-7">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">day</span> = {12},</span>
<span id="cb13-8">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">howpublished</span> = {<span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\url</span>{https://hongsupshin.github.io}},</span>
<span id="cb13-9">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">journal</span> = {Hongsup Shin's Blog},</span>
<span id="cb13-10">    <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">url</span> = {https://hongsupshin.github.io/posts/2026-01-12/},</span>
<span id="cb13-11">}</span></code></pre></div></div>


</section>

 ]]></description>
  <category>LangGraph</category>
  <category>AI Agents</category>
  <category>LLM</category>
  <category>Production</category>
  <category>Debugging</category>
  <guid>https://hongsupshin.github.io/posts/2026-01-12/</guid>
  <pubDate>Mon, 12 Jan 2026 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2026-01-12/fig.png" medium="image" type="image/png" height="111" width="144"/>
</item>
<item>
  <title>Essential qualities of ML tech leads</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2025-02-23/</link>
  <description><![CDATA[ 





<p>Over my near-decade career in ML, I’ve witnessed firsthand how technical leadership can make or break a team’s success. As both a tech lead and someone who has worked with various tech leads, I’ve learned that typical engineering management is not enough to handle unique challenges of ML projects. The ML field moves at a fast pace, and projects require orchestrating multiple stakeholders with diverse expertise. Teams must constantly balance research with production while assessing the inherent uncertainty in ML systems. In addition, it is necessary to nurture collaboration between highly skilled individuals who bring their own innovative perspectives. Without effective technical leadership, even the most promising ML projects can unravel, leading to missed opportunities and team burnout.</p>
<p>I’ve learned (sometimes the hard way) that great ML tech leadership requires a unique blend of technical vision, people skills, and operational excellence. While no one perfectly embodies all of these, I think understanding them is crucial for developing good tech leads in ML community, myself included.</p>
<section id="drive-technical-vision-and-stay-at-the-forefront" class="level2">
<h2 class="anchored" data-anchor-id="drive-technical-vision-and-stay-at-the-forefront">Drive technical vision and stay at the forefront</h2>
<p>ML tech leads must stay informed about recent developments in the ML field. Even when an ML system runs like a well-oiled machine, there always is room for increased efficiency and innovation. Staying informed does not mean buying all the hypes from recent developments. It is crucial to distinguish true opportunities from background noise, and then translate them into business values because “cool” does not always mean “useful.” Once the connection between technology and business values is established, tech leads need to set clear technical directions with a roadmap. This not only includes clarifying short-term scopes, but also charting out a vision for long-term objectives, so the team and stakeholders are aware of where the team is headed.</p>
</section>
<section id="embrace-the-shift-from-coding-to-leading" class="level2">
<h2 class="anchored" data-anchor-id="embrace-the-shift-from-coding-to-leading">Embrace the shift from coding to leading</h2>
<p>Tech leads often start their careers as individual contributors (ICs) and inevitably face the challenge of transitioning from technical to managerial responsibilities. While it’s understandable to feel frustrated about not being able to maintain deep and focused technical work, tech leads need to remind themselves of their primary responsibility and recognize the importance of delegation. Besides, it is possible to maintain technical credibility while transitioning to leadership. For instance, tech leads can participate in code reviews rather than development itself, engage in short-term innovative projects, or create opportunities for team members to present their work and learn together more efficiently. Moreover, tech leads will also start developing a different set of technical skills focused at a higher level, which they might find equally enjoyable and rewarding.</p>
</section>
<section id="build-strong-development-infrastructures" class="level2">
<h2 class="anchored" data-anchor-id="build-strong-development-infrastructures">Build strong development infrastructures</h2>
<p>ML projects require iterative processes. Lack of proper scalable and frictionless development infrastructure leads to slow and unstable development, and causes constant fatigue in the team. While it is challenging to balance technical debts with delivery pressure, tech leads might have to convince the upper management to make initial investments on infrastructure before continuing development and delivery. Without the solid infrastructure, the ML product will be like a house of cards. However, tech leads should be aware of the trade-offs between building perfect and practical solutions. This naturally requires following changes in ML infrastructure space as well.</p>
</section>
<section id="exercise-sharp-technical-judgment" class="level2">
<h2 class="anchored" data-anchor-id="exercise-sharp-technical-judgment">Exercise sharp technical judgment</h2>
<p>With the fast moving pace of the ML field, it is important to quickly identify promising ideas in the team that are worth pursuing. Tech leads should help them cut through bureaucracy to speed up the innovation. At the same time, tech leads should help establish evaluation standards at the team level so that every idea is properly vetted. If unproductive approaches are found, it is important to recognize when to pivot. This also means the team should be able to quickly iterate through multiple ideas, and thus tech leads should help create a space for this. Finally, when making decisions and judgments, make sure document the reasoning and process for fairness, transparency, and accountability.</p>
</section>
<section id="embrace-change-and-combat-complacency" class="level2">
<h2 class="anchored" data-anchor-id="embrace-change-and-combat-complacency">Embrace change and combat complacency</h2>
<p>As ML tools and technology advance daily, maintaining a “business as usual” approach is likely to make the team less competitive. While changes can feel uncomfortable, ML is a unique domain characterized by rapid evolution across tools, frameworks, and methodologies. What works today might not be optimal tomorrow.</p>
<p>Moreover, ML practitioners are naturally drawn to innovation and eager to experiment with new approaches. Tech leads should harness this enthusiasm by leading through example such as actively discussing emerging technologies relevant to the team’s work and creating regular forums for team members to introduce new ideas. To make this sustainable, tech leads should establish structured processes for testing and validating new approaches without disrupting production systems. This balance between innovation and stability ensures the team stays current while maintaining reliable service.</p>
</section>
<section id="champion-team-growth-and-development" class="level2">
<h2 class="anchored" data-anchor-id="champion-team-growth-and-development">Champion team growth and development</h2>
<p>To go through different ideas and innovations, it is crucial to invest in team’s growth. Tech leads should create opportunities of learning and development, and also be able to identify each team member’s career aspirations. While nurturing unique strengths of individual members, tech leads should provide opportunities where team members can share their skills so that the whole team is more synced in technical capabilities and grow together. Team leads should be able to ask leadership for necessary resources for attending conferences and workshops while pursuing opportunities for publication and demo showcase.</p>
</section>
<section id="build-a-culture-of-trust-and-innovation" class="level2">
<h2 class="anchored" data-anchor-id="build-a-culture-of-trust-and-innovation">Build a culture of trust and innovation</h2>
<p>Teams cannot grow without reviewing and critiquing their work together. That’s why it is essential for tech leads to create a safe space for constant experimentation and failure. I recommend that tech leads should become a role model in this case and practice vulnerability by admitting their own mistakes while providing honest feedback with empathy in a group discussion. There is a fine balance to be struck here because teams should maintain high standards while supporting learning and open dialogue.</p>
<p>Since ML teams often consist of highly technical individual with diverse skills, it is possible that the teams’ functionality stays fragmented and team building may become overlooked. But I think it is important to nurture a strong sense of belonging and shared purpose. This can be simply done by celebrating wins together, and creating opportunities for knowledge sharing and teaching. Strengthening bonds among the team members leads to better quality of work and lower turnover. Furthermore, this will help building a brand for the team, which increases recognition in the company and community.</p>
</section>
<section id="advocate-for-your-team-and-shield-from-disruption" class="level2">
<h2 class="anchored" data-anchor-id="advocate-for-your-team-and-shield-from-disruption">Advocate for your team and shield from disruption</h2>
<p>Team leads should champion achievements from their team to leadership by highlighting individual members who contributed. When communicating with stakeholders and leadership, tech leads should set realistic expectations of the product and negotiate deadlines and resources without overpromising. I have seen many tech leads who were too eager to say yes to every stakeholder demand, unfortunately often because of the lack of technical understanding of their own product capabilities, which drove their team members to exhaustion. Although internal politics and unnecessary disruptions may not always be avoidable, tech leads should do their best to shield the team from them.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Yes, good ML tech leadership is undoubtedly challenging. While these qualities might seem daunting taken all at once, remember that great tech leadership develops over time through experience, reflection, and genuine care for both the technical craft and the people we work with. As our field continues to evolve and diversify, the need grows for exceptional ML tech leads who can balance technical excellence with human understanding, drive both innovation and value, and help their teams navigate the complex landscape of modern ML development.</p>


</section>

 ]]></description>
  <category>ML</category>
  <category>leadership</category>
  <guid>https://hongsupshin.github.io/posts/2025-02-23/</guid>
  <pubDate>Sun, 23 Feb 2025 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2025-02-23/fig.png" medium="image" type="image/png" height="126" width="144"/>
</item>
<item>
  <title>Ranking metrics: pitfalls and best practices</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2025-02-08/</link>
  <description><![CDATA[ 





<div id="cell-1" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-3"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>matplotlib inline</span>
<span id="cb1-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>config InlineBackend.figure_format<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'retina'</span></span>
<span id="cb1-5">plt.style.use(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ggplot'</span>)</span></code></pre></div></div>
</details>
</div>
<p>Ranking is everywhere. When you search for products online or scroll through your social media feed, you’re interacting with ranking systems. Unlike classification where we simply predict a category, ranking requires ordering items by their relevance or importance. This fundamental difference requires specific metrics so-called information retrieval (IR) metrics that capture nuanced aspects of ranking quality. Choosing the right ranking metric requires good understanding of reward, discount, and normalization of ranking metrics. In this post, we will discuss mathematical properties of various ranking metrics, focusing on common pitfalls in practice and how to address them. Let’s start with some basics.</p>
<section id="why-ranking-is-different" class="level2">
<h2 class="anchored" data-anchor-id="why-ranking-is-different">Why ranking is different</h2>
<p>A good way to understand ranking is to compare it against classification. Let’s say we have a dataset with three relevance grades: excellent, good, and mediocre. We can train a multi-class classifier to predict the probability of a sample belonging to each grade. In learning-to-rank (LTR) framework, this is called point-wise ranking approach. However, at the core, ranking is about understanding relative relationship among different samples, and thus, more preferred LTR models take pair-wise or list-wise approach.</p>
<p>This consideration of multi-sample comparison is related to how LTR is used in practice. When retrieving relevant documents or optimizing search query, we work with multiple queries. This means, we want to generalize the model to learn the relative importance of samples across multiple datasets. This is why a typical LTR dataset contains a group variable that indicates group or query membership. This also means that in some groups, we might not always have all relevance labels. For instance, in the three-grade example, we might have a query group where we only have samples that belong to “excellent” and “mediocre”, without the “good” grade. A classifier will complain about this but LTR optimization loss can naturally handle this.</p>
<p>Finally and most importantly, ranking deals with positional bias. We can train a model that optimizes the ranking of <em>all</em> items in a dataset, but in practice, we normally care about the small minority at the top (i.e., top K). This leads to more complex use cases and metrics such as whether only the top first item matters or top 10 items, or how we penalize model when it makes errors. Related to this, compared to classification, partial correctness exists in ranking systems. Even when model prediction does not result in a perfect ranking, loss can be computed by considering how far it is from the ideal ranking.</p>
</section>
<section id="mean-reciprocal-rank-mrr" class="level2">
<h2 class="anchored" data-anchor-id="mean-reciprocal-rank-mrr">Mean reciprocal rank (MRR)</h2>
<p>Ranking metrics are naturally designed to digest the positional information (ranks) of relevant items retrieved. Mean reciprocal rank (MRR) is a good example where the metric is solely computed by ranks. Mathematically, MRR is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?%20%5Ctext%7BMRR%7D%20=%20%5Cfrac%7B1%7D%7B%7CQ%7C%7D%20%5Csum_%7Bi=1%7D%5E%7B%7CQ%7C%7D%20%5Cfrac%7B1%7D%7B%5Ctext%7Brank%7D_i%7D%20"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Brank%7D_i"> refers to the rank of the <strong>first</strong> relevant item of <img src="https://latex.codecogs.com/png.latex?i">th query from a set of queries, <img src="https://latex.codecogs.com/png.latex?Q">. In other words, MRR is the <em>inverse</em> of the harmonic mean of ranks of the first relevant items. This also indicates that MRR’s focus is a single item, not the overall quality of ranking of an array.</p>
<section id="hyperbolic-discount-of-reward" class="level3">
<h3 class="anchored" data-anchor-id="hyperbolic-discount-of-reward">Hyperbolic discount of reward</h3>
<p>Since we use reciprocal rank (RR), <img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B%5Ctext%7Brank%7D_i%7D">, individual RR scores shows <em>hyperbolic</em> decay:</p>
<div id="cell-fig-1" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>))</span>
<span id="cb2-2">ax.plot(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>))</span>
<span id="cb2-3">ax.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(xlabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Rank of the first relevant item"</span>, ylabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"RR score"</span>)</span>
<span id="cb2-4">fig.tight_layout()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://hongsupshin.github.io/posts/2025-02-08/index_files/figure-html/fig-1-output-1.png" class="quarto-figure quarto-figure-center figure-img" width="391" height="241">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Hyperbolic decay of reciprocal rank (RR)
</figcaption>
</figure>
</div>
</div>
</div>
<p>This hyperbolic decay means the RR score difference between <strong><img src="https://latex.codecogs.com/png.latex?i">th and <img src="https://latex.codecogs.com/png.latex?i+k">th item is much larger when <img src="https://latex.codecogs.com/png.latex?i"> is small</strong>. For instance, the difference between getting the relevant item in the first vs.&nbsp;second place is much larger than getting the relevant item in the 100th vs.&nbsp;the 101st places.</p>
<p>This positional reward discount in RR is a core characteristic of most ranking metrics. In ranking systems, we put more emphasis on low ranking values. When ranking quality is poor (higher ranking values), discerning the ranking performance in this region is less meaningful than in the lower-ranking region.</p>
</section>
<section id="harmonic-nature-of-mrr" class="level3">
<h3 class="anchored" data-anchor-id="harmonic-nature-of-mrr">Harmonic nature of MRR</h3>
<p>This positional discount is why we use harmonic mean of ranks in MRR. When we compute the average of RR scores across queries, we do not want to equally treat a query with RR score of 1 (i.e., getting the relevant item in the 1st place) and a query with RR score of 0.2 (i.e., 1/5, getting the item in the 5th place).</p>
<p>On one hand, this means MRR is less sensitive to outliers: MRR does not change dramatically with occasional bad ranking performance because its contribution is small. But on the other, this implies that a small number queries with low rank values (high RR scores) can significantly outweigh multiple queries with higher rank values.</p>
<p>Assume that we have 4 queries, and system A returns the first relevant item at ranks 2, 3, 2 and 3, respectively, while system B returns the relevant items at ranks 1, 10, 1 and 15:</p>
<div id="cell-7" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> MRR(ranks):</span>
<span id="cb3-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">round</span>((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> ranks).mean(), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span>
<span id="cb3-3"></span>
<span id="cb3-4"></span>
<span id="cb3-5">first_relevant_ranks_A <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>])</span>
<span id="cb3-6">first_relevant_ranks_B <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>])</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"MRR(A):</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MRR(first_relevant_ranks_A)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb3-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"MRR(B):</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MRR(first_relevant_ranks_B)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>MRR(A):0.4167
MRR(B):0.5417</code></pre>
</div>
</div>
<p>In this example, MRR score is higher in system B but the overall ranking quality is more consistent in system A, which is likely to be preferable in practice. This suggests MRR alone is not enough, and it is useful to understand the distribution of individual RR scores.</p>
</section>
</section>
<section id="normalized-discounted-cumulative-gain-ndcg" class="level2">
<h2 class="anchored" data-anchor-id="normalized-discounted-cumulative-gain-ndcg">Normalized discounted cumulative gain (NDCG)</h2>
<p>NDCG is perhaps the most widely used ranking metric. Compared to MRR, NDCG has two distinctive features:</p>
<ul>
<li>It evaluates overall quality of ranking, not just the location of the first relevant item.</li>
<li>It can incorporate <em>graded</em> relevance levels where item relevance grades are more granular than binary.</li>
</ul>
<p>NDCG is a normalized form of DCG. DCG is defined as:</p>
<p><img src="https://latex.codecogs.com/png.latex?DCG_K%20=%20%5Csum_%7Bi=1%7D%5EK%20%5Cfrac%7B2%5E%7Brel_i%7D%20-%201%7D%7B%5Clog_2(i%20+%201)%7D"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?rel_i"> represents the relevance of the <img src="https://latex.codecogs.com/png.latex?i">th item and <img src="https://latex.codecogs.com/png.latex?K"> is the size of top-ranked items we consider (i.e., K in top K). NDCG is a normalized form of DCG: we divide DCG by ideal DCG (IDCG), which can be only computed when we have full knowledge of the ranking labels so we know what the ideal order of all items is:</p>
<p><img src="https://latex.codecogs.com/png.latex?NDCG_K%20=%20%5Cfrac%7BDCG_K%7D%7BIDCG_K%7D"></p>
<section id="linear-vs.-exponential-gain" class="level3">
<h3 class="anchored" data-anchor-id="linear-vs.-exponential-gain">Linear vs.&nbsp;exponential gain</h3>
<p>There are actually <a href="https://en.wikipedia.org/wiki/Discounted_cumulative_gain">two versions of DCG implementation</a>. The one above is more commonly used in industry and research, and it uses exponential gain on the numerator. The original DCG formula on the other hand, uses linear gain:</p>
<p><img src="https://latex.codecogs.com/png.latex?DCG_K%20=%20%5Csum_%7Bi=1%7D%5EK%20%5Cfrac%7Brel_i%7D%7B%5Clog_2(i%20+%201)%7D"></p>
<p>As of now (Feb 2025), the scikit-learn (ver. 1.6) uses the linear gain in NDCG calculation. So if we want to compute NDCG scores using sklearn, it’s important to know that its linear calculation of the score is going to be often different from the exponential version, which modern ML model packages use. For instance, in LightGBM, the loss objective <code>xe_ndcg</code> (or <code>rank_xendcg</code>) based on <a href="https://arxiv.org/abs/1911.09798">Bruch 2021</a> uses the exponential gain.</p>
<div id="cell-13" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> sklearn</span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ndcg_score</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"sklearn version:</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>sklearn<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>__version__<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb5-5"></span>
<span id="cb5-6"></span>
<span id="cb5-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> dcg(relevance_labels, scores, gain_type):</span>
<span id="cb5-8">    ranking <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.argsort(scores)[::<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb5-9">    relevance_labels_ranked <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> relevance_labels[ranking]</span>
<span id="cb5-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> gain_type <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"linear"</span>:</span>
<span id="cb5-11">        gains <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> relevance_labels_ranked</span>
<span id="cb5-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> gain_type <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"exponential"</span>:</span>
<span id="cb5-13">        gains <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>relevance_labels_ranked <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb5-14">    discounts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.log2(np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(scores) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb5-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(gains <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> discounts)</span>
<span id="cb5-16"></span>
<span id="cb5-17"></span>
<span id="cb5-18">y_true <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>])</span>
<span id="cb5-19">scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span>])</span>
<span id="cb5-20">ndcg_sklearn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ndcg_score(y_true.reshape((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)), scores.reshape((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)))</span>
<span id="cb5-21">ndcg_lin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dcg(y_true, scores, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"linear"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> dcg(y_true, y_true, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"linear"</span>)</span>
<span id="cb5-22">ndcg_exp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dcg(y_true, scores, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"exponential"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> dcg(y_true, y_true, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"exponential"</span>)</span>
<span id="cb5-23"></span>
<span id="cb5-24"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"NDCG with scikit-learn    : </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ndcg_sklearn<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb5-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"NDCG with linear gain     : </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ndcg_lin<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb5-26"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"NDCG with exponential gain: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ndcg_exp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:.4f}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>sklearn version:1.6.0
NDCG with scikit-learn    : 0.6957
NDCG with linear gain     : 0.6957
NDCG with exponential gain: 0.4097</code></pre>
</div>
</div>
<p>In the exponential version, higher relevance scores are emphasized much more strongly than the linear one. This is certainly better for applications where finding highly relevant items is critically important. This explains the difference in NDCG scores between linear and exponential in the above example. In our example, the relevance scores <code>[10, 0, 0, 1, 5]</code> range from 0 to 10 and exponential gains of 10 and 5 are massive. Therefore, any suboptimal ordering, which the example provides, is heavily penalized.</p>
</section>
<section id="ndcg-comparison-the-importance-of-fixed-k" class="level3">
<h3 class="anchored" data-anchor-id="ndcg-comparison-the-importance-of-fixed-k">NDCG comparison: The importance of fixed K</h3>
<p>One common mistake when comparing NDCG scores of top K items (NDCG@K) is to compare the scores across different Ks. For instance, one might want to compare NDCG@5 vs.&nbsp;NDCG@10. This should be avoided.</p>
<p>NDCG with different Ks are two fundamentally different cases. For a smaller K, the score calculation ignores candidates with ranks larger than K, which will be considered when computing NDCG with a larger K. Also, the discounting effect from <img src="https://latex.codecogs.com/png.latex?%5Clog_2(i+1)"> in the denominator causes errors at different positions have different impacts. Since later positions have less impact on the final score, NDCG score at a larger K can sometimes be higher even with mistakes in the tail region. Finally, since NDCG is a normalized metric, when K differs, the normalization term also changes. This means NDCG comparison with different K ignors the scaling difference.</p>
<p>Thus, when we evaluate different ranking systems and models, we should always compare NDCG scores at the same K value. However, since NDCG with a fixed K provides a single snapshot of the ranking quality at a given K, it is recommended to report NDCG at multiple K values to understand the model behavior in depth. Using other metrics such as MRR or mean average precision together is even better.</p>
</section>
</section>
<section id="why-small-k" class="level2">
<h2 class="anchored" data-anchor-id="why-small-k">Why small K</h2>
<p>When choosing K, the main consideration should be the use case of the system. For search query or video recommendation, K should be small because users only care about top 1-5 items. But for a use case like song playlist generation, K can be a bit larger than that. This means we need to consider how users interact with the system.</p>
<p>There are computational and modeling aspects that discourage having a larger K as well. First, as MRR and NDCG show, ranking metrics come with positional discount. Later positions have minimal impact and ranking error in this region may not provide much signal for models to learn. It’s even possible that models might focus on minor improvements in deep positions instead of focusing on top positions, which eventually can lead to slower convergence. In addition, as we saw in the examples above, as K becomes larger, there are more subtle nuances that occur, which evaluation metrics or losses might not be able to fully capture. This makes evaluation at larger K values less reliable. And of course, a larger K requires more compute resources.</p>
<p>So it is often more sensible to keep the size of K small. If we have a use case where K is large, we need to think about whether ranking is the best approach here. Alternatively, we can propose a solution where K can be kept small. For instance, instead of suggesting top 100 videos to a user group at once, we can recommend top 5 videos per user.</p>
</section>
<section id="granularity-in-relevance-levels" class="level2">
<h2 class="anchored" data-anchor-id="granularity-in-relevance-levels">Granularity in relevance levels</h2>
<p>When defining relevance of items, the number of relevance grades should also be small. First, having too much granularity in relevance level is not practical because data annotation can become easily unreliable and inconsistent (e.g., relevant:irrelevant vs.&nbsp;relevance Lv.36:relevance Lv.47). Relevance can also often be just naturally clustered even when defined with fine granularity.</p>
<p>Having too many levels is also not useful for model training. With the exponential NDCG, having too many levels can create extreme difference in relevance. This can make model training very unstable because the model will be overly incentivized to learn higher relevance items while essentially ignoring the distinction between low relevance items. This means training can be dominated by high-relevant items, making the fine granularity less useful. Model evaluation become even more challenging because it becomes extremely difficult to interpret ranking results and training process.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>This post explores common pitfalls and practical considerations when working with ranking metrics. Compared to classification, ranking has the distinctive positional-discount feature, which results in many interesting metric definitions and important considerations around it. One of the main challenges with ranking evaluation is that metrics often do not capture the full picture of ranking because it almost always requires holistic understanding of item arrays. Given that there are many metrics to choose from and many parameters to tweak, understanding how the choice impacts use case and model training should help us make better decisions when designing and evaluating ranking systems.</p>


</section>

 ]]></description>
  <category>ML</category>
  <category>Learning-to-rank</category>
  <guid>https://hongsupshin.github.io/posts/2025-02-08/</guid>
  <pubDate>Sat, 08 Feb 2025 06:00:00 GMT</pubDate>
</item>
<item>
  <title>Learning-to-rank for hardware bug discovery</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2025-02-01/</link>
  <description><![CDATA[ 





<section id="ml-for-efficient-hardware-verification" class="level2">
<h2 class="anchored" data-anchor-id="ml-for-efficient-hardware-verification">ML for efficient hardware verification</h2>
<p>One of the main challenges of hardware verification is finding bugs efficiently in a design. Since verification is resource-intensive in hardware engineering, ML for hardware verification is an active area of research. The mainstream idea in research is using reinforcement learning (RL) even though it is challenging to productionize RL.</p>
<p>Instead, my team at Arm developed an ML application based on a simpler approach: supervised learning with recommendation (Figure&nbsp;1). The model uses binary fail/pass labels during training, and predicts the probability of a test candidate being a bug. In production, the application makes batch prediction of a set of candidates and ranks the prediction scores so that engineers run only a subset (top-K) while discovering similar number of bugs.</p>
<div id="fig-1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://hongsupshin.github.io/posts/2025-02-01/Fig1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="450">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Schematics of the default constraint random verification (CRV) flow (left) and the ML application (right) that recommends test candidates based on model prediction.
</figcaption>
</figure>
</div>
</section>
<section id="objectives" class="level2">
<h2 class="anchored" data-anchor-id="objectives">Objectives</h2>
<p>Since verification is an exploration problem, its success is measured by the number of <em>novel</em> bugs discovered. Each verification test returns a binary label: fail or pass. When a test fails, it returns a failure signature (often called a <em>unique fail signature</em>, or <strong>UFS</strong>), which summarizes the cause of the failure. The business objective of bug discovery can be expressed mathematically as maximizing cardinality of the fail signature set <img src="https://latex.codecogs.com/png.latex?%5C%7Bs_i%5C%7D"> from <img src="https://latex.codecogs.com/png.latex?K"> test candidates:</p>
<p><span id="eq-ufs"><img src="https://latex.codecogs.com/png.latex?%0A%5Cleft%7C%5Cbigcup_%7Bi=1%7D%5E%7BK%7D%20%5C%7Bs_i%5C%7D%5Cright%7C%0A%5Ctag%7B1%7D"></span></p>
<p>So far we have been addressing this in a binary classification framework where we use the fail (1) and pass (0) labels. This is based on empirical findings which suggest positive correlation between the number of failures and the number of UFS. In other words, in the binary classifier, we aim to maximize the number of failures given <img src="https://latex.codecogs.com/png.latex?K"> test candidates:</p>
<p><span id="eq-fail"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5E%7BK%7D%20%5Cmathbb%7B1%7D_%7By_i%20=%201%7D%0A%5Ctag%7B2%7D"></span></p>
</section>
<section id="shortcomings-of-binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="shortcomings-of-binary-classification">Shortcomings of binary classification</h2>
<p>Once we deployed the classifier, we unfortunately started observing frequent fluctuations in model performance, often with suboptimal outcomes. After model inspection, we learned that the training process was often dominated by frequently-occurring failures. It turns out the fail signature frequency distribution has a long tail, indicating that only a small number of fail signatures dominate the failure-label space. Therefore, the model learned patterns from a small number of failure signatures.</p>
<p>From business perspective, this is problematic because frequently-occurring failures are already well known to verification engineers. These bugs are also not caused by design but other factors such as testing infrastructures. In other words, when the model focuses on these failures, our application delivers low value and may even risk misclassifying rare (more valuable) failures as passes, failing to prioritize them.</p>
</section>
<section id="learning-to-rank-bugs-by-their-rarity" class="level2">
<h2 class="anchored" data-anchor-id="learning-to-rank-bugs-by-their-rarity">Learning to rank bugs by their rarity</h2>
<p>When I was looking into ways to fix this model behavior and have it focus on rare failures (bugs), I learned about <strong>learning-to-rank (LTR)</strong> algorithms, a family of supervised learning algorithms that learn to generalize the ranking of samples. In a typical LTR dataset, labels are often integers that represent relative relevance of samples in a dataset. Their loss function usually focuses on the top-K elements, and tries to optimize an information retrieval (IR) metric. One of the most widely used IR metric is normalized discounted cumulative gain (NDCG), the normalized version of DCG, which is defined as:</p>
<p><span id="eq-dcg"><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BDCG%7D_K%20=%20%5Csum_%7Bi=1%7D%5E%7BK%7D%20%5Cfrac%7B2%5E%7Brel_i%7D%20-%201%7D%7B%5Clog_2(i%20+%201)%7D%0A%5Ctag%7B3%7D"></span></p>
<p>where <img src="https://latex.codecogs.com/png.latex?rel_i"> represents the relevance label of the <img src="https://latex.codecogs.com/png.latex?i">th sample.</p>
<p>Inspired by this, I formulated our objective as a ranking problem. I created a new labeling function that returns integer relevance labels by thresholding fail signature frequency. Failed tests whose signature frequency is less than <img src="https://latex.codecogs.com/png.latex?M"> times were considered <strong>rare</strong>. Other failed tests were considered <strong>common</strong> failures, and passing tests <strong>irrelevant</strong>. The LTR model learns to rank samples based on these relevance labels. It prioritizes rare fail signatures first, then common failures, and lastly passing tests. An <em>important modeling assumption</em> here is that there might be a learnable pattern among rare failures.</p>
<p>I soon realized that the gap between optimization metric (model loss) and target metric (Equation&nbsp;1) is reduced with the LTR model compared to the binary classifier (Table&nbsp;1). In addition to not incorporating failure signatures, the binary classifier neither learns ranking directly nor only focuses on top-K during training. The LTR model address both and can return higher cardinality by prioritizing rare signatures.</p>
<div id="tbl-comparison" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Loss comparison between the classification and the LTR regarding the target metric (KPI).
</figcaption>
<div aria-describedby="tbl-comparison-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Target metric key characteristics</th>
<th style="text-align: left;">Target metric addressed by classifier loss?</th>
<th style="text-align: left;">Target metric addressed by LTR loss?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Cardinality</td>
<td style="text-align: left;"><strong>No</strong></td>
<td style="text-align: left;"><strong>Partially Yes</strong>: Rarity prioritization leads to higher cardinality</td>
</tr>
<tr class="even">
<td style="text-align: left;">Fail signatures</td>
<td style="text-align: left;"><strong>No</strong>: Uses binary labels</td>
<td style="text-align: left;"><strong>Yes</strong></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Ranking</td>
<td style="text-align: left;"><strong>No</strong></td>
<td style="text-align: left;"><strong>Yes</strong></td>
</tr>
<tr class="even">
<td style="text-align: left;">Top-K</td>
<td style="text-align: left;"><strong>No</strong>: Uses all samples</td>
<td style="text-align: left;"><strong>Yes</strong></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
</section>
<section id="data-augmentation-with-simulated-ltr-groups" class="level2">
<h2 class="anchored" data-anchor-id="data-augmentation-with-simulated-ltr-groups">Data augmentation with simulated LTR groups</h2>
<p>A typical LTR dataset has a <strong>group</strong> (or query) variable that indicates the group membership of a given sample row. During LTR model training, the loss is calculated per group, and its aggregate is used for model updates. It’s like we want to teach a search query model to prioritize similar types of items across multiple different queries. It is technically possible to create a single group that contains the entire training dataset. However, this is much more challenging in terms of both loss optimization and compute. Besides, sometimes it’s not supported by model libraries. For instance, the <a href="https://github.com/microsoft/LightGBM/blob/master/src/metric/dcg_calculator.cpp#L17">lightgbm</a> package limits the group size to 10k.</p>
<p>In the verification training data, there are a few candidate features to group the samples. However, I decided to adopt a simpler approach: bootstrapping. I created an augmented training dataset with <img src="https://latex.codecogs.com/png.latex?m"> groups where each group contains <strong>ALL rare failures, a subset of common failures, and a subset of passes</strong> where the subsets are bootstrapped independently across all groups. I chose this particular method of guaranteeing every group to have all rare failures because the model should learn to prioritize these over the rest. The details of this process is shown below:</p>
<section id="input" class="level4">
<h4 class="anchored" data-anchor-id="input">Input</h4>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Baligned%7D%0A&amp;%20D_%7Btrain%7D:%20%5Ctext%7BOriginal%20training%20dataset%7D%20%5C%5C%0A&amp;%20F_%7Brare%7D%20%5Csubset%20D_%7Btrain%7D:%20%5Ctext%7BSet%20of%20rare%20failures%7D%20%5C%5C%0A&amp;%20F_%7Bcommon%7D%20%5Csubset%20D_%7Btrain%7D:%20%5Ctext%7BSet%20of%20common%20failures%7D%20%5C%5C%0A&amp;%20P%20%5Csubset%20D_%7Btrain%7D:%20%5Ctext%7BSet%20of%20passes%7D%20%5C%5C%0A&amp;%20k_%7Bcommon%7D:%20%5Ctext%7BSampling%20size%20of%20common%20failures%7D%20%5C%5C%0A&amp;%20k_%7Bpass%7D:%20%5Ctext%7BSampling%20size%20of%20passes%7D%20%5C%5C%0A&amp;%20m:%20%5Ctext%7BNumber%20of%20groups%7D%20%5C%5C%0A&amp;%20s:%20%5Ctext%7BFixed%20size%20for%20each%20group%20where%20%7D%20s%20=%20F_%7Brare%7D%20+%20k_%7Bcommon%7D%20+%20k_%7Bpass%7D%0A%5Cend%7Baligned%7D%0A"></p>
</section>
<section id="output" class="level4">
<h4 class="anchored" data-anchor-id="output">Output</h4>
<p><img src="https://latex.codecogs.com/png.latex?D_%7Baug%7D">: Augmented training dataset</p>
</section>
<section id="procedure" class="level4">
<h4 class="anchored" data-anchor-id="procedure">Procedure</h4>
<ol type="1">
<li>Initialize <img src="https://latex.codecogs.com/png.latex?D_%7Baug%7D%20%5Cgets%20%5Cemptyset"> with size <img src="https://latex.codecogs.com/png.latex?s"></li>
<li>For <img src="https://latex.codecogs.com/png.latex?i%20=%201"> to <img src="https://latex.codecogs.com/png.latex?m">:
<ul>
<li><img src="https://latex.codecogs.com/png.latex?D_%7Baug%7D%20%5Cgets%20F_%7Brare%7D"> (Include all rare failures)</li>
<li><img src="https://latex.codecogs.com/png.latex?D_%7Baug%7D%20%5Cgets%20D_%7Baug%7D%20%5Ccup%20%5Ctext%7BRandomSample%7D(F_%7Bcommon%7D,%20k_%7Bcommon%7D)"></li>
<li><img src="https://latex.codecogs.com/png.latex?D_%7Baug%7D%20%5Cgets%20D_%7Baug%7D%20%5Ccup%20%5Ctext%7BRandomSample%7D(P,%20k_%7Bpass%7D)"></li>
</ul></li>
<li>Return <img src="https://latex.codecogs.com/png.latex?D_%7Baug%7D"></li>
</ol>
<p>This bootstrapping process naturally results in <strong>bagging (bootstrap aggregation) effect</strong>. The training dataset now has synthetic bootstrapped groups, and the LTR model has to learn to prioritize rare failures over different combinations of common failures and passes.</p>
</section>
</section>
<section id="benchmarking-with-production-datasets" class="level2">
<h2 class="anchored" data-anchor-id="benchmarking-with-production-datasets">Benchmarking with production datasets</h2>
<p>With this new LTR model, I conducted a benchmarking experiment to compare the model performance of the existing binary classifier and the new model. I used about 40 production datasets from a CPU project from last year. For a thorough model comparison, I used the following four metrics:</p>
<ol type="1">
<li>Number of failures (Equation&nbsp;2): Binary fail/pass</li>
<li>Number of <strong>rare</strong> failures: failures whose relevance label is the largest <span id="eq-rare"><img src="https://latex.codecogs.com/png.latex?%0A%5Csum_%7Bi=1%7D%5E%7BK%7D%20%5Cmathbb%7B1%7D_%7By_i%20=%20%5Cmax(rel)%7D%0A%5Ctag%7B4%7D"></span></li>
<li>Number of unique fail signatures (Equation&nbsp;1): Measure of signature set cardinality</li>
<li>Number of <strong>never-seen</strong> fail signatures: Number of signatures that are newly discovered in the test set but NOT observed in the train set, <img src="https://latex.codecogs.com/png.latex?S_%7Btrain%7D"> <span id="eq-neverseen"><img src="https://latex.codecogs.com/png.latex?%0A%5Cleft%7C%5Cbigcup_%7Bi=1%7D%5E%7BK%7D%20%5C%7Bs_i%5C%7D%20-%20S_%7Btrain%7D%5Cright%7C%0A%5Ctag%7B5%7D"></span></li>
</ol>
<p>These metrics allow us to understand different aspects of model behavior. The number of rare failures (Equation&nbsp;4) addresses ranking quality most directly. The number of unique fail signatures is our KPI. The number of <strong>never-seen</strong> fail signatures indicates model generalizability.</p>
</section>
<section id="ranking-performance-comparison" class="level2">
<h2 class="anchored" data-anchor-id="ranking-performance-comparison">Ranking performance comparison</h2>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://hongsupshin.github.io/posts/2025-02-01/Fig2.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="800">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Mean test-set ranking performance of the binary classification (“Clf-Fail”) and the LTR (“Rank-FS”) models. Scores are calculated from the top-1000 samples.
</figcaption>
</figure>
</div>
<p>The average performance of the four metrics of the two models shows an interesting pattern (Figure&nbsp;2). Although the classifier is much better at capturing failures than the LTR model (leftmost), when it comes to metrics that consider fail signatures, it was worse than the LTR model. This supports the idea of the large metric gap of the classifier’s model loss and the target metric (KPI) (Table&nbsp;1).</p>
<div id="fig-3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://hongsupshin.github.io/posts/2025-02-01/Fig3.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="800">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Mean test-set ranking performance of the binary classification (“Clf-Fail”) and the LTR (“Rank-FS”) models across different Ks.
</figcaption>
</figure>
</div>
<p>This performance pattern remained consistent when I varied K (Figure&nbsp;3). By comparing different Ks, it’s possible to measure efficiency improvement by the LTR model. In the “UFS” and “Never-seen fail signatures” plots, the LTR performance at <img src="https://latex.codecogs.com/png.latex?K=250"> is similar to the classifier performance at <img src="https://latex.codecogs.com/png.latex?K=1000">. This suggests that the LTR model may require <strong>75% fewer tests</strong> to produce the same results.</p>
</section>
<section id="measuring-the-bagging-effect" class="level2">
<h2 class="anchored" data-anchor-id="measuring-the-bagging-effect">Measuring the bagging effect</h2>
<div id="fig-4" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://hongsupshin.github.io/posts/2025-02-01/Fig4.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="800">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-4-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Mean effect of the number of bootstrapped groups (<img src="https://latex.codecogs.com/png.latex?m">) during data augmentation on model performance (top-1000).
</figcaption>
</figure>
</div>
<p>In the default LTR model version I tried, I created a training dataset with 30 bootstrapped groups. When I varied the number of groups, I observed the impact of bagging on model performance (Figure&nbsp;4). As I increased the number of groups, the performance generally improved but it had diminishing return after a certain point.</p>
</section>
<section id="extended-model-comparison" class="level2">
<h2 class="anchored" data-anchor-id="extended-model-comparison">Extended model comparison</h2>
<p>To further understand the model behavior, I created several model variants and measured their performance using the same metrics and benchmark datasets.</p>
<section id="separating-the-impact-of-label-change-and-algorithm-change" class="level3">
<h3 class="anchored" data-anchor-id="separating-the-impact-of-label-change-and-algorithm-change">Separating the impact of label change and algorithm change</h3>
<p>In the LTR model, I made two changes. I created a different labeling system using failure signature frequency, and I changed the algorithm from classification to LTR as well. To separate the impact of these changes, I created two model variants:</p>
<ul>
<li>Multi-class classification with relevance labels (“Clf-FS”)</li>
<li>LTR with binary labels (“Rank-Fail”)</li>
</ul>
</section>
<section id="classification-with-frequency-based-label-encoding" class="level3">
<h3 class="anchored" data-anchor-id="classification-with-frequency-based-label-encoding">Classification with frequency-based label encoding</h3>
<p>To further explore the idea of the impact of the new labeling system I used for LTR, I tried the following two classifier variants:</p>
<ul>
<li>Binary classification without “common” failures (“Clf-FS (No 1s)”)</li>
<li>Binary classification by treating “common” failures as passes (“Clf-FS (1&gt;&gt;0)”)</li>
</ul>
<p>I also played with different signature-frequency thresholds to create binary labels. For instance, if the threshold is 50, all failures whose signature frequency is less than 50 are labeled as 1, the rest (failures whose signature frequency is larger than 50 and all passes) are labeled as 0:</p>
<ul>
<li>Binary classification with varying signature-frequency thresholds (“Clf-FS (Bin, &lt;<img src="https://latex.codecogs.com/png.latex?N">)” where different Ns are chosen based on varying quantile values)</li>
</ul>
</section>
<section id="classification-with-bootstrapping" class="level3">
<h3 class="anchored" data-anchor-id="classification-with-bootstrapping">Classification with bootstrapping</h3>
<p>To investigate whether bootstrapping can improve classification performance, I created the following variants as well:</p>
<ul>
<li>Multi-class classification with relevance labels and bootstrapped training data (“Clf-FS (m=30)”)</li>
<li>Binary classification with fail/pass labels and bootstrapped training data (“Clf-Fail (m=30)”)</li>
</ul>
</section>
<section id="the-verdict" class="level3">
<h3 class="anchored" data-anchor-id="the-verdict">The verdict</h3>
<div id="fig-5" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://hongsupshin.github.io/posts/2025-02-01/Fig5.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="800">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-5-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Mean test-set ranking performance of the binary classification (“Clf-Fail”) and the LTR (“Rank-FS”) model variants.
</figcaption>
</figure>
</div>
<p>Figure&nbsp;5 shows the final model comparison that includes all classifier variants (gray) and LTR variants (light blue) in addition to the existing binary classifier model (black) and the first (default) LTR model (dark blue). Modifying the label encoding slightly improved the performance of classifiers (see “Clf-FS (Bin, &lt;<img src="https://latex.codecogs.com/png.latex?N">)” models in the middle), but their performance was still worse than all LTR variants. Interestingly, the LTR model that used binary labels (“Rank-Fail”) was better than the existing binary classifier’s performance, suggesting that direct ranking optimization result in better performance since our key metrics are ranking metrics.</p>
</section>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>One of the biggest lessons from this project was the importance of reducing the gap between the business objective and the optimization objective of ML models especially when it is challenging to accommodate the former. By switching from binary classification to learning-to-rank, we achieved similar bug discovery rate with 75% fewer tests, while better identifying rare and never-seen failure signatures. The LTR model’s success in learning patterns among rare failures suggests there may be underlying commonalities in these rare failures that require further investigation.</p>
<p>The lightweight nature of our approach - using only test settings without design features - makes it particularly practical for verification teams. While not attempting to fundamentally solve the verification problem like RL studies, this approach offers a more deployment-friendly solution that allows verification engineers to focus their efforts on more challenging bugs. Future work could explore incorporating design features, LTR model fine-tuning, and using test output features for ranking.</p>


</section>

 ]]></description>
  <category>ML</category>
  <category>verification</category>
  <category>Learning-to-rank</category>
  <guid>https://hongsupshin.github.io/posts/2025-02-01/</guid>
  <pubDate>Sat, 01 Feb 2025 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2025-02-01/Fig1.png" medium="image" type="image/png" height="82" width="144"/>
</item>
<item>
  <title>Model tuning with Weights &amp; Biases, Ray Tune, and LightGBM</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2025-01-25/</link>
  <description><![CDATA[ 





<p><em>All healthy models are alike; each failing model fails in its own way.</em></p>
<p>There are many different ways that an ML model can fail and this is what makes model debugging challenging. For comprehensive understanding of model behavior, we log various metrics during model training. Unfortunately, because of their sheer volume, we need tools for logging, data mining, and visualization: MLflow, Neptune, Comet ML, Weights and Biases, and so on (see this <a href="https://neptune.ai/vs/wandb-mlflow">blog post</a> by Neptune about a thorough side-by-side comparison among Neptune, MLflow, and Weights and Biases).</p>
<p>With the increasing complexity of models, their hyperparameter spaces and the challenge of understanding their impact and interaction grow at the same time. In this post, I demonstrate how to use Weights and Biases for monitoring LightGBM model tuning by Ray Tune. I will also discuss how we can share the Weights and Biases reports publicly.</p>
<section id="weights-and-biases-ray-tune" class="level2">
<h2 class="anchored" data-anchor-id="weights-and-biases-ray-tune">Weights and Biases + Ray Tune</h2>
<p><a href="https://wandb.ai/">Weights and Biases (WandB)</a> is an ML model development platform that provides various services such as experiment monitoring, model tuning, model registry management, and workflow automation. In this post, I am focusing on the first two elements: monitoring and tuning. Even though WandB’s <a href="https://wandb.ai/site/sweeps/">Sweeps</a> provides hyperparameter search and optimization, in this post, I am using <a href="https://docs.ray.io/en/latest/tune/index.html">Ray Tune</a> for model tuning and Sweeps for monitoring and visualization. Ray Tune is more frequently used for model tuning in ML community than WandB because it is an open source framework.</p>
<p>Ray’s <a href="https://docs.ray.io/en/latest/tune/examples/tune-wandb.html">documentation</a> describes three ways to interact with WandB via its API, <code>WandbLoggerCallback</code> and <code>setup_wandb</code>:</p>
<ol type="1">
<li>Use <code>WandbLoggerCallback</code> in <code>Train.RunConfig</code> (shown in this post)</li>
<li>Set up <code>setup_wandb</code> in a trainable function with <code>wandb.log</code></li>
<li>Set up <code>setup_wandb</code> in a <code>Trainable</code> class with <code>wandb.log</code></li>
</ol>
<p>Although this documentation is excellent, it only shows iteration-level logging where logs (or metrics) are generated at every iteration (or epoch) and passed to WandB. This isn’t applicable to many existing models like the LightGBM ones. A callback is required to have the models return logged metrics during model training and tuning.</p>
<p>According to <a href="https://wandb.ai/authors/RayTune-dcgan/reports/Ray-Tune-Distributed-Hyperparameter-Optimization-at-Scale--VmlldzoyMDEwNDY">a WandB report</a>, one can use <code>WandbLogger</code> (available in PyTorch Lightning, TorchTune, etc.) or <code>@wandb_mixin</code> decorator. I haven’t tried these methods because the report seems outdated (referring to ray 0.8.7), and they are not described in the Ray documentation.</p>
</section>
<section id="model-tuning-setup" class="level2">
<h2 class="anchored" data-anchor-id="model-tuning-setup">Model tuning setup</h2>
<p>To demonstrate WandB and Ray Tune integration with LightGBM models, I prepared the following setup:</p>
<ul>
<li>Data: Synthetic dataset with a 80:20 train-validation split</li>
<li>Objective: Binary classification with class imbalance</li>
<li>Model API: LightGBM native</li>
<li>Training metrics: Cross entropy, AUROC, and average precision for both training and validation data</li>
<li>Number of training epochs: 100</li>
<li>Tunable hyperparameters:</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"num_leaves"</span>: tune.choice([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">31</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">63</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">127</span>]),</span>
<span id="cb1-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"learning_rate"</span>: tune.loguniform(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-1</span>),</span>
<span id="cb1-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"min_data_in_leaf"</span>: tune.choice([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>]),</span>
<span id="cb1-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"max_depth"</span>: tune.choice([<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>]),</span>
<span id="cb1-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"boosting_type"</span>: tune.choice([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gbdt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dart"</span>]),</span>
<span id="cb1-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"bagging_fraction"</span>: tune.uniform(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>),</span>
<span id="cb1-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"bagging_freq"</span>: tune.choice([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>])</span></code></pre></div></div>
<ul>
<li>Model selection metric (tuning): Cross entropy of the validation set</li>
<li>Number of searches: 8</li>
</ul>
<section id="module-import-and-ray-initialization" class="level3">
<h3 class="anchored" data-anchor-id="module-import-and-ray-initialization">Module import and ray initialization</h3>
<div id="cell-5" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> IFrame</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> make_classification</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> lightgbm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> lgb</span>
<span id="cb2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ray</span>
<span id="cb2-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> ray <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train, tune</span>
<span id="cb2-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> ray.tune.integration.lightgbm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> TuneReportCheckpointCallback</span>
<span id="cb2-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> ray.tune.schedulers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ASHAScheduler</span>
<span id="cb2-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> ray.air.integrations.wandb <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> WandbLoggerCallback</span>
<span id="cb2-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb2-12"></span>
<span id="cb2-13">os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"WANDB_SILENT"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"true"</span></span>
<span id="cb2-14"></span>
<span id="cb2-15">seed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span></span></code></pre></div></div>
</div>
<div id="cell-6" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">ray.init(num_cpus<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span></code></pre></div></div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>2025-01-26 10:57:00,944    INFO worker.py:1812 -- Started a local Ray instance. View the dashboard at <span class="ansi-green-fg ansi-bold">http://127.0.0.1:8265 </span>
</pre>
</div>
</div>
<div class="cell-output cell-output-display" data-execution_count="2">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4bc71992fa7a416c9af9b929ea210a27","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
</section>
<section id="training-data" class="level3">
<h3 class="anchored" data-anchor-id="training-data">Training data</h3>
<div id="cell-8" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">X, y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> make_classification(</span>
<span id="cb4-2">    n_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, n_features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, n_classes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, weights<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.9</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>], random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>seed</span>
<span id="cb4-3">)</span>
<span id="cb4-4"></span>
<span id="cb4-5">X_train, X_test, y_train, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(</span>
<span id="cb4-6">    X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>seed)</span>
<span id="cb4-7"></span>
<span id="cb4-8">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X_train'</span>: X_train, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y_train'</span>: y_train, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X_test'</span>: X_test, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y_test'</span>: y_test} </span></code></pre></div></div>
</div>
</section>
<section id="training-config-parameter-space" class="level3">
<h3 class="anchored" data-anchor-id="training-config-parameter-space">Training config (parameter space)</h3>
<div id="cell-10" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb5-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"objective"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"binary"</span>,</span>
<span id="cb5-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"metric"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"binary_logloss"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"auc"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"average_precision"</span>],</span>
<span id="cb5-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"verbose"</span>: <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb5-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"n_estimators"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb5-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_leaves"</span>: tune.choice([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">31</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">63</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">127</span>]),</span>
<span id="cb5-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"learning_rate"</span>: tune.loguniform(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-1</span>),</span>
<span id="cb5-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"min_data_in_leaf"</span>: tune.choice([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>]),</span>
<span id="cb5-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max_depth"</span>: tune.choice([<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>]),</span>
<span id="cb5-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"boosting_type"</span>: tune.choice([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gbdt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dart"</span>]),</span>
<span id="cb5-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bagging_fraction"</span>: tune.uniform(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>),</span>
<span id="cb5-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bagging_freq"</span>: tune.choice([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]),    </span>
<span id="cb5-13">}</span></code></pre></div></div>
</div>
</section>
<section id="training-function" class="level3">
<h3 class="anchored" data-anchor-id="training-function">Training function</h3>
<p>Here I am using <code>ray.tune.integration.lightgbm.TuneReportCheckpointCallback</code> with <code>frequency=1</code> (every iteration) as a main callback function to log the metrics defined in <code>config</code> (<code>["binary_logloss", "auc", "average_precision"]</code>). Both training and validation dataset metrics are tracked: note that the metric names in the callback have a format of <code>"{valid_names[i]}-{metric[i]}"</code>.</p>
<p>The training function below takes two inputs: <code>config</code> and <code>data</code>. Inside the function, <code>lightgbm.Dataset</code> objects are constructed and the native <code>lightgbm.train</code> is called. Training data (<code>data</code>) can be later passed to the Tune wrapper via <code>tune.with_parameters</code>.</p>
<div id="cell-12" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> train_function(config, data):</span>
<span id="cb6-2">    train_set <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgb.Dataset(data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X_train'</span>], data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y_train'</span>])</span>
<span id="cb6-3">    val_set <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgb.Dataset(data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'X_test'</span>], data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'y_test'</span>], reference<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_set)</span>
<span id="cb6-4"></span>
<span id="cb6-5">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgb.train(</span>
<span id="cb6-6">        config,</span>
<span id="cb6-7">        train_set,</span>
<span id="cb6-8">        valid_sets<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[train_set, val_set],</span>
<span id="cb6-9">        valid_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val"</span>],</span>
<span id="cb6-10">        callbacks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb6-11">            TuneReportCheckpointCallback(</span>
<span id="cb6-12">                frequency<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb6-13">                metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{</span>
<span id="cb6-14">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train_loss"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train-binary_logloss"</span>,</span>
<span id="cb6-15">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train_auc"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train-auc"</span>,</span>
<span id="cb6-16">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train_average_precision"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train-average_precision"</span>,</span>
<span id="cb6-17">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val_loss"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val-binary_logloss"</span>,</span>
<span id="cb6-18">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val_auc"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val-auc"</span>,</span>
<span id="cb6-19">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val_average_precision"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val-average_precision"</span>,</span>
<span id="cb6-20">                },</span>
<span id="cb6-21">            )</span>
<span id="cb6-22">        ],</span>
<span id="cb6-23">    )</span></code></pre></div></div>
</div>
</section>
<section id="tuner" class="level3">
<h3 class="anchored" data-anchor-id="tuner">Tuner</h3>
<p><code>WandbLoggerCallback</code> is used with a project name to send logs to WandB’s server. Like <code>train_function</code>, the tuner accepts <code>config</code> and <code>data</code> arguments. Following Ray’s best practices, datasets are passed through the <code>data</code> argument via <code>tune.with_parameters</code> rather than the config.</p>
<div id="cell-15" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">n_searches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span></span>
<span id="cb7-2"></span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> tune_with_callback(config, data):</span>
<span id="cb7-5">    tuner <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tune.Tuner(</span>
<span id="cb7-6">        tune.with_parameters(train_function, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data),</span>
<span id="cb7-7">        param_space<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config,</span>
<span id="cb7-8">        tune_config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tune.TuneConfig(</span>
<span id="cb7-9">            metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val_loss"</span>, mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"min"</span>, num_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_searches</span>
<span id="cb7-10">        ),</span>
<span id="cb7-11">        run_config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train.RunConfig(</span>
<span id="cb7-12">            callbacks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[WandbLoggerCallback(project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"WandB-RayTune-LightGBM"</span>)]</span>
<span id="cb7-13">        ),</span>
<span id="cb7-14">    )</span>
<span id="cb7-15">    tuner.fit()</span></code></pre></div></div>
</div>
</section>
<section id="wandb-setup" class="level3">
<h3 class="anchored" data-anchor-id="wandb-setup">WandB setup</h3>
<p><code>WandB</code> requires sign-up. Their <a href="https://wandb.ai/site/pricing/">free tier</a> offers limited storage and support but includes core functionality. Follow their <a href="https://docs.wandb.ai/quickstart/">quickstart page</a> for setup.</p>
<div id="cell-18" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">wandb.login()</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>True</code></pre>
</div>
</div>
<div id="cell-19" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">tune_with_callback(config, data)</span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div class="tuneStatus">
  <div style="display: flex;flex-direction: row">
    <div style="display: flex;flex-direction: column;">
      <h3 class="anchored">Tune Status</h3>
      
<table class="caption-top table table-sm table-striped small">
<tbody>
<tr class="odd">
<td>Current time:</td>
<td>2025-01-26 10:57:34</td>
</tr>
<tr class="even">
<td>Running for:</td>
<td>00:00:19.66</td>
</tr>
<tr class="odd">
<td>Memory:</td>
<td>12.6/16.0 GiB</td>
</tr>
</tbody>
</table>

    </div>
    <div class="vDivider"></div>
    <div class="systemInfo">
      <h3 class="anchored">System Info</h3>
      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/4 CPUs, 0/0 GPUs
    </div>
    
  </div>
  <div class="hDivider"></div>
  <div class="trialStatus">
    <h3 class="anchored">Trial Status</h3>
    
<table class="caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">Trial name</th>
<th data-quarto-table-cell-role="th">status</th>
<th data-quarto-table-cell-role="th">loc</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">bagging_fraction</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">bagging_freq</th>
<th data-quarto-table-cell-role="th">boosting_type</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">learning_rate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">max_depth</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">min_data_in_leaf</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">num_leaves</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">iter</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">total time (s)</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">train_loss</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">train_auc</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">train_average_precis ion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>train_function_97fa2_00000</td>
<td>TERMINATED</td>
<td>127.0.0.1:83708</td>
<td style="text-align: right;">0.878482</td>
<td style="text-align: right;">1</td>
<td>gbdt</td>
<td style="text-align: right;">0.0409389</td>
<td style="text-align: right;">-1</td>
<td style="text-align: right;">60</td>
<td style="text-align: right;">31</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.417227</td>
<td style="text-align: right;">0.0631622</td>
<td style="text-align: right;">0.997799</td>
<td style="text-align: right;">0.982008</td>
</tr>
<tr class="even">
<td>train_function_97fa2_00001</td>
<td>TERMINATED</td>
<td>127.0.0.1:83706</td>
<td style="text-align: right;">0.658912</td>
<td style="text-align: right;">5</td>
<td>dart</td>
<td style="text-align: right;">0.0170101</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">60</td>
<td style="text-align: right;">127</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.392265</td>
<td style="text-align: right;">0.241471</td>
<td style="text-align: right;">0.967141</td>
<td style="text-align: right;">0.770121</td>
</tr>
<tr class="odd">
<td>train_function_97fa2_00002</td>
<td>TERMINATED</td>
<td>127.0.0.1:83705</td>
<td style="text-align: right;">0.837067</td>
<td style="text-align: right;">1</td>
<td>dart</td>
<td style="text-align: right;">0.0775392</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">60</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.443744</td>
<td style="text-align: right;">0.102647</td>
<td style="text-align: right;">0.992724</td>
<td style="text-align: right;">0.945557</td>
</tr>
<tr class="even">
<td>train_function_97fa2_00003</td>
<td>TERMINATED</td>
<td>127.0.0.1:83707</td>
<td style="text-align: right;">0.622214</td>
<td style="text-align: right;">0</td>
<td>gbdt</td>
<td style="text-align: right;">0.000216889</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">127</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.37126</td>
<td style="text-align: right;">0.323874</td>
<td style="text-align: right;">0.93965</td>
<td style="text-align: right;">0.554631</td>
</tr>
<tr class="odd">
<td>train_function_97fa2_00004</td>
<td>TERMINATED</td>
<td>127.0.0.1:83838</td>
<td style="text-align: right;">0.821865</td>
<td style="text-align: right;">5</td>
<td>gbdt</td>
<td style="text-align: right;">0.00415785</td>
<td style="text-align: right;">-1</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.41642</td>
<td style="text-align: right;">0.232447</td>
<td style="text-align: right;">0.960898</td>
<td style="text-align: right;">0.734143</td>
</tr>
<tr class="even">
<td>train_function_97fa2_00005</td>
<td>TERMINATED</td>
<td>127.0.0.1:83837</td>
<td style="text-align: right;">0.8452</td>
<td style="text-align: right;">0</td>
<td>dart</td>
<td style="text-align: right;">0.0109837</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">40</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.54864</td>
<td style="text-align: right;">0.266188</td>
<td style="text-align: right;">0.974223</td>
<td style="text-align: right;">0.853426</td>
</tr>
<tr class="odd">
<td>train_function_97fa2_00006</td>
<td>TERMINATED</td>
<td>127.0.0.1:83839</td>
<td style="text-align: right;">0.574684</td>
<td style="text-align: right;">0</td>
<td>gbdt</td>
<td style="text-align: right;">0.00362588</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.412159</td>
<td style="text-align: right;">0.238196</td>
<td style="text-align: right;">0.962041</td>
<td style="text-align: right;">0.730329</td>
</tr>
<tr class="even">
<td>train_function_97fa2_00007</td>
<td>TERMINATED</td>
<td>127.0.0.1:83836</td>
<td style="text-align: right;">0.698182</td>
<td style="text-align: right;">0</td>
<td>gbdt</td>
<td style="text-align: right;">0.0277846</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">40</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">0.466146</td>
<td style="text-align: right;">0.0752791</td>
<td style="text-align: right;">0.99627</td>
<td style="text-align: right;">0.972842</td>
</tr>
</tbody>
</table>

  </div>
</div>
<style>
.tuneStatus {
  color: var(--jp-ui-font-color1);
}
.tuneStatus .systemInfo {
  display: flex;
  flex-direction: column;
}
.tuneStatus td {
  white-space: nowrap;
}
.tuneStatus .trialStatus {
  display: flex;
  flex-direction: column;
}
.tuneStatus h3 {
  font-weight: bold;
}
.tuneStatus .hDivider {
  border-bottom-width: var(--jp-border-width);
  border-bottom-color: var(--jp-border-color0);
  border-bottom-style: solid;
}
.tuneStatus .vDivider {
  border-left-width: var(--jp-border-width);
  border-left-color: var(--jp-border-color0);
  border-left-style: solid;
  margin: 0.5em 1em 0.5em 1em;
}
</style>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>2025-01-26 10:57:14,965    INFO wandb.py:319 -- Already logged into W&amp;B.

WARNING: All log messages before absl::InitializeLog() is called are written to STDERR

I0000 00:00:1737910636.174542 19552148 chttp2_transport.cc:1182] ipv4:127.0.0.1:51265: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:"2025-01-26T10:57:16.17454-06:00", file_line:1171, file:"external/com_github_grpc_grpc/src/core/ext/transport/chttp2/transport/chttp2_transport.cc"}

I0000 00:00:1737910636.176357 19552148 chttp2_transport.cc:1182] ipv4:127.0.0.1:51256: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:"2025-01-26T10:57:16.176356-06:00", file_line:1171, file:"external/com_github_grpc_grpc/src/core/ext/transport/chttp2/transport/chttp2_transport.cc"}

I0000 00:00:1737910645.637782 19552148 chttp2_transport.cc:1182] ipv4:127.0.0.1:51511: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:"2025-01-26T10:57:25.637779-06:00", file_line:1171, file:"external/com_github_grpc_grpc/src/core/ext/transport/chttp2/transport/chttp2_transport.cc"}

I0000 00:00:1737910645.648876 19552148 chttp2_transport.cc:1182] ipv4:127.0.0.1:51523: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:"2025-01-26T10:57:25.648874-06:00", file_line:1171, file:"external/com_github_grpc_grpc/src/core/ext/transport/chttp2/transport/chttp2_transport.cc"}

2025-01-26 10:57:34,623 INFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/hongsupshin/ray_results/train_function_2025-01-26_10-57-14' in 0.0332s.

2025-01-26 10:57:49,893 INFO tune.py:1041 -- Total run time: 34.95 seconds (19.62 seconds for the tuning loop).

<span class="ansi-cyan-fg">(train_function pid=83708)</span> /opt/homebrew/Caskroom/miniforge/base/envs/wandb/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument

<span class="ansi-cyan-fg">(train_function pid=83708)</span>   _log_warning(f"Found `{alias}` in params. Will use it instead of argument")

<span class="ansi-cyan-fg">(train_function pid=83708)</span> Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/hongsupshin/ray_results/train_function_2025-01-26_10-57-14/train_function_97fa2_00000_0_bagging_fraction=0.8785,bagging_freq=1,boosting_type=gbdt,learning_rate=0.0409,max_depth=-1,min_data__2025-01-26_10-57-14/checkpoint_000000)

<span class="ansi-cyan-fg">(train_function pid=83706)</span> /opt/homebrew/Caskroom/miniforge/base/envs/wandb/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument<span class="ansi-green-fg"> [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)</span>

<span class="ansi-cyan-fg">(train_function pid=83706)</span>   _log_warning(f"Found `{alias}` in params. Will use it instead of argument")<span class="ansi-green-fg"> [repeated 3x across cluster]</span>

<span class="ansi-cyan-fg">(train_function pid=83708)</span> Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/hongsupshin/ray_results/train_function_2025-01-26_10-57-14/train_function_97fa2_00000_0_bagging_fraction=0.8785,bagging_freq=1,boosting_type=gbdt,learning_rate=0.0409,max_depth=-1,min_data__2025-01-26_10-57-14/checkpoint_000046)<span class="ansi-green-fg"> [repeated 190x across cluster]</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<div class="ansi-escaped-output">
<pre><span class="ansi-yellow-fg">(raylet)</span> WARNING: 16 PYTHON worker processes have been started on node: 0c8a8cbf6029ce14f7fb87978d96c38f57da4534a8d65e705f6940a9 with address: 127.0.0.1. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).
</pre>
</div>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-yellow-fg">(raylet)</span> WARNING: All log messages before absl::InitializeLog() is called are written to STDERR

<span class="ansi-yellow-fg">(raylet)</span> I0000 00:00:1737910645.636949 19552110 chttp2_transport.cc:1182] ipv4:127.0.0.1:51511: Got goaway [2] err=UNAVAILABLE:GOAWAY received; Error code: 2; Debug Text: Cancelling all calls {grpc_status:14, http2_error:2, created_time:"2025-01-26T10:57:25.636948-06:00", file_line:1171, file:"external/com_github_grpc_grpc/src/core/ext/transport/chttp2/transport/chttp2_transport.cc"}

<span class="ansi-cyan-fg">(train_function pid=83837)</span> /opt/homebrew/Caskroom/miniforge/base/envs/wandb/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument<span class="ansi-green-fg"> [repeated 4x across cluster]</span>

<span class="ansi-cyan-fg">(train_function pid=83837)</span>   _log_warning(f"Found `{alias}` in params. Will use it instead of argument")<span class="ansi-green-fg"> [repeated 4x across cluster]</span>

<span class="ansi-cyan-fg">(train_function pid=83836)</span> Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/hongsupshin/ray_results/train_function_2025-01-26_10-57-14/train_function_97fa2_00007_7_bagging_fraction=0.6982,bagging_freq=0,boosting_type=gbdt,learning_rate=0.0278,max_depth=5,min_data_i_2025-01-26_10-57-15/checkpoint_000000)<span class="ansi-green-fg"> [repeated 212x across cluster]</span>

<span class="ansi-cyan-fg">(train_function pid=83837)</span> Checkpoint successfully created at: Checkpoint(filesystem=local, path=/Users/hongsupshin/ray_results/train_function_2025-01-26_10-57-14/train_function_97fa2_00005_5_bagging_fraction=0.8452,bagging_freq=0,boosting_type=dart,learning_rate=0.0110,max_depth=10,min_data__2025-01-26_10-57-14/checkpoint_000067)<span class="ansi-green-fg"> [repeated 265x across cluster]</span>
</pre>
</div>
</div>
</div>
</section>
</section>
<section id="sweeps-visualization-with-ray-tune-runs" class="level2">
<h2 class="anchored" data-anchor-id="sweeps-visualization-with-ray-tune-runs">Sweeps visualization with Ray Tune runs</h2>
<p>After tuning completes, WandB’s dashboard displays all search runs. I can access visualizations through either the Sweeps sidebar panel or by selecting runs and clicking “New Sweeps.”</p>
<p><img src="https://hongsupshin.github.io/posts/2025-01-25/Fig2.png" class="img-fluid"></p>
<p>This leads to the Sweep Configuration page, which shows an auto-generated YAML file that may need correction. For example, the optimization metric incorrectly shows “Relative Time (Process)” instead of “val_loss”.</p>
<p><img src="https://hongsupshin.github.io/posts/2025-01-25/Fig3.png" class="img-fluid"></p>
<p>While WandB’s <a href="https://docs.wandb.ai/guides/sweeps/">Sweeps</a> offers hyperparameter optimization, its primary strength lies in visualization capabilities. Below is an interactive report showing results from the above tuning run.</p>
<div id="cell-21" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">IFrame(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://wandb.ai/auth0-1wgih-hs/WandB-RayTune-LightGBM/reports/Tuning-trial-1--VmlldzoxMTA5NDQxMg"</span>, style<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"border:none"</span>, height<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>, width<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"100%"</span>)</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="9">

        <iframe width="100%" height="1024" src="https://wandb.ai/auth0-1wgih-hs/WandB-RayTune-LightGBM/reports/Tuning-trial-1--VmlldzoxMTA5NDQxMg?style=border%3Anone" frameborder="0" allowfullscreen=""></iframe>
        
</div>
</div>
<p>The Sweeps visualization offers two key plots: the <strong>hyperparameter importance</strong> plot and the <strong>parallel coordinates</strong> plot. The importance plot (top) reveals that learning rate has the strongest influence on validation loss in this run. Users can analyze different metrics via the drop-down menu and add comparative plots for training and validation scores. The parallel coordinates plot (bottom) visualizes hyperparameter interactions. Mouse-over highlights individual runs, and <code>val_loss</code> color gradient helps identify optimal parameter combinations, with darker colors indicating lower (better) scores.</p>
</section>
<section id="sharing-sweeps-results-publicly" class="level2">
<h2 class="anchored" data-anchor-id="sharing-sweeps-results-publicly">Sharing Sweeps results publicly</h2>
<p>An existing WandB result (report, Sweeps, etc.) can be shown in a Jupyter notebook by using <code>%wandb</code> magic (<a href="https://docs.wandb.ai/guides/track/jupyter/">documentation</a>):</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display a project workspace</span></span>
<span id="cb12-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>wandb USERNAME<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>PROJECT</span>
<span id="cb12-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display a single run</span></span>
<span id="cb12-4"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>wandb USERNAME<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>PROJECT<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>runs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>RUN_ID</span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display a sweep</span></span>
<span id="cb12-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>wandb USERNAME<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>PROJECT<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>sweeps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>SWEEP_ID</span>
<span id="cb12-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Display a report</span></span>
<span id="cb12-8"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>wandb USERNAME<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>PROJECT<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>reports<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>REPORT_ID</span>
<span id="cb12-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Specify the height of embedded iframe</span></span>
<span id="cb12-10"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>wandb USERNAME<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>PROJECT <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>h <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2048</span></span></code></pre></div></div>
<p>To share the interactive plots shown above, I used a different method: creating and sharing a WandB report. In a report, users can add results, visualizations, text, imaged, etc. as if it is a Jupyter notebook. After creating a report, I embedded my report’s iframe output to enable Quarto rendering (the publishing tool I am currently using). To generate a public report, change the visibility to “Public” in the <em>project</em> settings page:</p>
<p><img src="https://hongsupshin.github.io/posts/2025-01-25/Fig4.png" class="img-fluid" style="width:50.0%"></p>
</section>
<section id="model-tuning-with-asha-scheduler" class="level2">
<h2 class="anchored" data-anchor-id="model-tuning-with-asha-scheduler">Model tuning with ASHA scheduler</h2>
<p>To optimize tuning efficiency, in the example below, I added <code>ASHAScheduler</code> (Asynchronous Successive Halving Algorithm) in <code>tune.TuneConfig</code> and increased the number of searches to 128.</p>
<div id="cell-26" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">n_searches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span></span>
<span id="cb13-2"></span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> tune_with_asha(config, data):</span>
<span id="cb13-5">    tuner <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tune.Tuner(</span>
<span id="cb13-6">        tune.with_parameters(train_function, data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>data),</span>
<span id="cb13-7">        param_space<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config,</span>
<span id="cb13-8">        tune_config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tune.TuneConfig(</span>
<span id="cb13-9">            metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val_loss"</span>,</span>
<span id="cb13-10">            mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"min"</span>,</span>
<span id="cb13-11">            num_samples<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_searches,</span>
<span id="cb13-12">            scheduler<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ASHAScheduler(),</span>
<span id="cb13-13">        ),</span>
<span id="cb13-14">        run_config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train.RunConfig(</span>
<span id="cb13-15">            callbacks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[WandbLoggerCallback(project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"WandB-RayTune-LightGBM"</span>)]</span>
<span id="cb13-16">        ),</span>
<span id="cb13-17">    )</span>
<span id="cb13-18">    tuner.fit()</span>
<span id="cb13-19">    </span>
<span id="cb13-20">tune_with_asha(config, data)    </span></code></pre></div></div>
</div>
<p><img src="https://hongsupshin.github.io/posts/2025-01-25/Fig5.png" class="img-fluid"></p>
<p>The parallel coordinates plot from this run includes a <code>Step</code> axis (second from the right) that visualizes <code>ASHAScheduler</code>’s behavior. The dark purple curves represent trials that ran longer (higher <code>Step</code> values) and achieved lower <code>val_loss</code>. This demonstrates ASHA’s effectiveness at pruning unpromising trials through early stopping. With more searches, hyperparameter impacts are more clear here. For example, lower learning rates consistently lead to poorer model performance in this run.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>This post demonstrated how to combine Weights &amp; Biases visualization capabilities with Ray Tune’s hyperparameter optimization for LightGBM models. Ray Tune provides flexible and scalable hyperparameter tuning machinery, while WandB offers detailed visualization tools for analyzing results. Even though WandB offers model tuning service, Ray Tune is still one of the main model tuning frameworks in ML community, and thus it is valuable to understand their integration. Among WandB’s visualization tools, the parallel coordinates and hyperparameter importance plots provide valuable insights into parameter relationships and their impact on model performance.</p>


</section>

 ]]></description>
  <category>ML</category>
  <category>ML Ops</category>
  <category>visualization</category>
  <guid>https://hongsupshin.github.io/posts/2025-01-25/</guid>
  <pubDate>Sat, 25 Jan 2025 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2025-01-25/Fig.png" medium="image" type="image/png" height="139" width="144"/>
</item>
<item>
  <title>Thompson sampling in practice: modifications and limitations</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2025-01-18/</link>
  <description><![CDATA[ 





<div id="a0c92056" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> scipy.stats <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> beta</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span>
<span id="cb1-5"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>config InlineBackend.figure_format<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'retina'</span></span>
<span id="cb1-6">plt.style.use(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ggplot'</span>)</span></code></pre></div></div>
</details>
</div>
<p>On the surface, hardware verification seems to be a pure exploration task because its goal is to reach near-perfect coverage while fixing bugs. However, efficient navigation of a vast design space requires informed decisions based on the past history of verification tests.</p>
<p>My team has been building an ML application for efficient hardware verification that runs in parallel with existing methods. We recently had a discussion about introducing Thompson sampling, a multi-armed bandit (MAB) algorithm, popular among industry practitioners, to balance the load of the two methods. In this post, I will discuss practical challenges and limitations of Thompson sampling, and its potential use in hardware verification.</p>
<section id="premise" class="level2">
<h2 class="anchored" data-anchor-id="premise">Premise</h2>
<p>In our application, we have two workflows (or arms). One is a supervised learning model that learns a function between the features and label of historic data. The other is the default (non-ML) simulation, which runs random tests within a constrained design space set by verification engineers (also known as <em>constraint random verification (CRV)</em>).</p>
<p>We can consider the ML model as an exploitative arm, and the random as an exploratory arm. By utilizing data from previous explorations, the model can identify bug-prone areas in a design and prioritize them in future simulations. At the same time, the random method continues exploration of a (potentially new) design space.</p>
<p>It is crucial to find a right balance of the load between the two arms. If we have a greedy policy for the ML model, design exploration stops and it becomes increasingly challenging to find new bugs, also resulting in stale training data. On the other extreme, the default random method creates numerous redundant and irrelevant tests with little data mining. In this context, a MAB approach is useful to dynamically control the load based on simulation results from both arms.</p>
</section>
<section id="thompson-sampling" class="level2">
<h2 class="anchored" data-anchor-id="thompson-sampling">Thompson sampling</h2>
<p>Thompson sampling uses probabilistic reward functions to choose actions (arms) in a MAB setting. It’s also known as <em>posterior sampling</em> because as we observe more samples (by pulling the arms), we update our posterior distribution accordingly using Bayes’ rule. This way, it naturally addresses uncertainty through the probabilistic update.</p>
<p>In a typical beta-Bernoulli example, we start with two Beta(1, 1) distributions which are uniform priors. We draw a random sample from each distribution of both arms, and select the arm with the higher value. The beta distribution parameters are updated based on the outcome (reward) of this action: in a beta distribution, <img src="https://latex.codecogs.com/png.latex?%5Calpha"> and <img src="https://latex.codecogs.com/png.latex?%5Cbeta"> represent the number of successes + 1, and failures + 1.</p>
<p>The figures below show how beta distributions evolve as we get more successes (top) and failures (bottom):</p>
<div id="04451404" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb2-2">failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb2-3">n_sim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span></span>
<span id="cb2-4">additional_successes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb2-5">additional_failures <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span></code></pre></div></div>
</details>
</div>
<div id="44757453" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(additional_successes), figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), sharex<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, sharey<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb3-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, ax <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(axes):</span>
<span id="cb3-3">    n_success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> additional_successes[i]</span>
<span id="cb3-4">    sim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> beta.rvs(n_success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_sim)</span>
<span id="cb3-5">    sns.histplot(sim, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax)</span>
<span id="cb3-6">    ax.set_title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Beta(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>n_success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb3-7"></span>
<span id="cb3-8">fig.tight_layout()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2025-01-18/index_files/figure-html/cell-5-output-1.png" width="691" height="190" class="figure-img"></p>
<figcaption>Histograms of samples from beta distributions with increasing number of successes</figcaption>
</figure>
</div>
</div>
</div>
<div id="b626a6f7" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(additional_successes), figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), sharex<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, sharey<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, ax <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(axes):</span>
<span id="cb4-3">    n_failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> additional_failures[i]</span>
<span id="cb4-4">    sim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> beta.rvs(success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, n_failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_sim)</span>
<span id="cb4-5">    sns.histplot(sim, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax)</span>
<span id="cb4-6">    ax.set_title(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Beta(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">, </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>n_failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)"</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb4-7"></span>
<span id="cb4-8">fig.tight_layout()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2025-01-18/index_files/figure-html/cell-6-output-1.png" width="691" height="190" class="figure-img"></p>
<figcaption>Histograms of samples from beta distributions with increasing number of failures</figcaption>
</figure>
</div>
</div>
</div>
<p>Thompson sampling’s probabilistic approach helps maintain exploration of <em>arms</em>. The exploration is gradually more optimized and the uncertainty decreases as we gather more samples. How often to pull which arms (i.e., optimal allocation of load across all arms) is adjusted dynamically without manual control.</p>
<p>A simple python version of Thompson sampling can be implemented like this:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ThompsonSampling:</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb5-3">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the beta distribution for both arms (uniform)</span></span>
<span id="cb5-4">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] </span>
<span id="cb5-5">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] </span>
<span id="cb5-6">    </span>
<span id="cb5-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> select_arm(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb5-8">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Sample from both arms and return the index of the better arm</span></span>
<span id="cb5-9">        samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [beta.rvs(a, b, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> a, b <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas)]</span>
<span id="cb5-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.argmax(samples)</span>
<span id="cb5-11"></span>
<span id="cb5-12">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> action(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, chosen_arm):</span>
<span id="cb5-13">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Pull the chosen arm and collect the reward</span></span>
<span id="cb5-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chosen_arm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb5-15">            reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PullArm0()</span>
<span id="cb5-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb5-17">            reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PullArm1()</span>
<span id="cb5-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> reward</span>
<span id="cb5-19">    </span>
<span id="cb5-20">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> update(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb5-21">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the chosen arm's parameters based on the reward</span></span>
<span id="cb5-22">        chosen_arm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.select_arm()</span>
<span id="cb5-23">        reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.action(chosen_arm)        </span>
<span id="cb5-24">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb5-25">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas[chosen_arm] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb5-26">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb5-27">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas[chosen_arm] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div></div>
</section>
<section id="reducing-overconfidence-of-arms" class="level2">
<h2 class="anchored" data-anchor-id="reducing-overconfidence-of-arms">Reducing overconfidence of arms</h2>
<p>While the idea is simple, implementing Thompson sampling in practice requires many considerations. One of the most common issues is that a subset of arms may become too dominant, resulting in <em>greedy exploitation</em>.</p>
<p>The simplest way to address is to set a <em>minimum exploration rate</em>, which guarantees a fixed amount of load dedicated to specific arms.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ThompsonWithMinExplore:</span>
<span id="cb6-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, ..., min_explore_rate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>):</span>
<span id="cb6-3">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_explore_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> min_explore_rate</span>
<span id="cb6-4"></span>
<span id="cb6-5">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> select_arm(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb6-6"></span>
<span id="cb6-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> np.random.random() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.min_explore_rate:            </span>
<span id="cb6-8">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># always return a specific arm index</span></span>
<span id="cb6-9"></span>
<span id="cb6-10">        samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [beta.rvs(a, b, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> a, b <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">zip</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas)]</span>
<span id="cb6-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> np.argmax(samples)        </span></code></pre></div></div>
<p>In the verification scenario, this is a must because design exploration is crucial in verification. By allocating a minimum amount of load to exploration, we ensure that the random method continues to explore new design spaces, preventing the ML model from becoming overly greedy and missing potential new bugs.</p>
<p>Another approach is to adjust the probability distribution of dominant arms. Setting upper bounds of its parameters prevents their updates once they reach a threshold.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ThompsonWithUpperBound:</span>
<span id="cb7-2"></span>
<span id="cb7-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> update(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, alpha_upper_bound, beta_upper_bound):</span>
<span id="cb7-4">        chosen_arm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.select_arm()</span>
<span id="cb7-5">        reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.action(chosen_arm)        </span>
<span id="cb7-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb7-7">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chosen_arm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> alpha_upper_bound:</span>
<span id="cb7-8">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-9">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> chosen_arm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb7-10">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb7-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> chosen_arm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> beta_upper_bound:</span>
<span id="cb7-13">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb7-14">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> chosen_arm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb7-15">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div></div>
<p>Similarly, setting a time-decay on the parameters prevents arms from becoming too dominant.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ThompsonWithTimeDecay:</span>
<span id="cb8-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, decay_rate):</span>
<span id="cb8-3">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.decay_rate <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> decay_rate</span>
<span id="cb8-4">        </span>
<span id="cb8-5">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> update(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb8-6">        chosen_arm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.select_arm()</span>
<span id="cb8-7">        reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.action(chosen_arm)        </span>
<span id="cb8-8"></span>
<span id="cb8-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Decay before update</span></span>
<span id="cb8-10">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.decay_rate <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> a <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas]</span>
<span id="cb8-11">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.decay_rate <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> b <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas]        </span>
<span id="cb8-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> reward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb8-13">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.alphas[chosen_arm] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb8-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb8-15">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.betas[chosen_arm] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div></div>
<p>We can consider the time-decay modification as gradually reducing the influence of older rewards. In addition to the general idea of old data becoming stale, the decay may represent bug fixes. In other words, since bugs found in the past are now fixed in the current design, executing the exact action will not produce a reward (i.e., bug).</p>
</section>
<section id="dealing-with-rare-events" class="level2">
<h2 class="anchored" data-anchor-id="dealing-with-rare-events">Dealing with rare events</h2>
<p>Another common issue arises when reward frequency is too low. This poses two important challenges. First, in a beta-Bernoulli setup, a low frequency of events produces a beta distribution that is highly compressed towards zero with a long tail on the right side. In a situation like this where <img src="https://latex.codecogs.com/png.latex?%5Calpha"> is much smaller than <img src="https://latex.codecogs.com/png.latex?%5Cbeta">, we have an asymmetrical probability distribution update, meaning the probability distribution is much more sensitive to a single success than a single failure.</p>
<div id="d4823ab4" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb9-2">failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">98</span></span>
<span id="cb9-3">n_sim <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span></span>
<span id="cb9-4">sim0 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> beta.rvs(success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_sim)</span>
<span id="cb9-5">sim1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> beta.rvs(success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_sim)</span>
<span id="cb9-6">sim2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> beta.rvs(success <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, failure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_sim)</span>
<span id="cb9-7"></span>
<span id="cb9-8">fig, ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb9-9">sns.kdeplot(sim0, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax, clip<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Baseline: Beta(2, 98)'</span>)</span>
<span id="cb9-10">sns.kdeplot(sim1, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax, clip<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'+1 Success'</span>)</span>
<span id="cb9-11">sns.kdeplot(sim2, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax, clip<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'+1 Failure'</span>)</span>
<span id="cb9-12">ax.legend()</span>
<span id="cb9-13">fig.tight_layout()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2025-01-18/index_files/figure-html/cell-7-output-1.png" width="491" height="290" class="figure-img"></p>
<figcaption>A right-skewed beta distribution (Beta(2, 98), red) is more sensitive to an additional success (blue) than an additional failure (purple).</figcaption>
</figure>
</div>
</div>
</div>
<p>Another challenge is that the low frequency pushes the time horizon much further because we must collect a sizable number of samples to have good probability estimates on positive events. Depending on the time horizon limit, we may not be able to use Thompson sampling at all if the update is too slow.</p>
<p>With these challenges, we can first test several heuristic-based methods. First, we can start with a more optimistic prior to force early exploration of certain arms. The main downside is that wrong initial guesses are costly, and at the same time the forced-exploration effect will disappear soon without rewards.</p>
<p>Second, we can consider batch-based update of parameters instead of instance-based. This can stabilize the distribution update at the price of slower learning. Literature also suggests using contextual bandit to make a more informed decision, or using a hierarchical approach to allow groups of arms share information (prior). This approach is also useful when the number of arms is large, and the cost of exploration becomes too high.</p>
<p>The hierarchical approach is useful in hardware verification if we have a model per design unit or test configuration, or when arms have different verification strategies such as coverage, bug hunting, soak/flood optimization, and especially when a group of arms share a strategy. It’s even possible to have two different layers of beta distributions, one at the individual level and the other at the group level, and take a weighted-average approach.</p>
<p>In hardware verification, the batch-based approach can have an additional edge because the tests are usually generated in batches. Since a typical verification process requires a huge number of tests, the issue of slower learning in the batch update method might not become a huge tradeoff.</p>
</section>
<section id="prior-knowledge-and-continuous-reward" class="level2">
<h2 class="anchored" data-anchor-id="prior-knowledge-and-continuous-reward">Prior knowledge and continuous reward</h2>
<p>In a typical Thompson sampling example, we often start with a non-informative uniform prior (e.g., Beta(1, 1)). If we already have knowledge about an arm, we can start with an informative prior. For instance, in a medical setting, if we want to compare treatment options and we already have preliminary data for certain treatments from clinical trials, we can use this to build a non-uniform prior.</p>
<p>If the arms have continuous rewards, gamma distribution is a good candidate because it’s well-suited for modeling skewed distributions of positive rewards. The distribution has two parameters, <img src="https://latex.codecogs.com/png.latex?%5Calpha">, a shape parameter, and <img src="https://latex.codecogs.com/png.latex?%5Clambda">, a rate parameter. Using the fact that <img src="https://latex.codecogs.com/png.latex?%5Cmu=%5Cfrac%7B%5Calpha%7D%7B%5Clambda%7D"> and <img src="https://latex.codecogs.com/png.latex?%5Csigma%5E2=%5Cfrac%7B%5Calpha%7D%7B%5Clambda%5E2%7D">, we can calculate and update both parameters using the mean and variance from our samples:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Calpha%20=%20%5Cfrac%7B%5Cmu%5E2%7D%7B%5Csigma%5E2%7D"> <img src="https://latex.codecogs.com/png.latex?%5Clambda%20=%20%5Cfrac%7B%5Cmu%7D%7B%5Csigma%5E2%7D"></p>
<p>Defining a right reward function might be the most challenging part in hardware verification because the definition of verification success is often complex and based on many heuristics and factors. Here are some examples. First, we should consider the novelty of bugs, often represented as the cardinality of the set of captured bugs. Second, given multiple tests with an identical bug signature, we prefer tests with shorter runtime to save compute. Finally, the origin of a bug should be considered such as whether a bug is from the design or other sources such as a test bench or infrastructure.</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p>Because of its simplicity, Thompson sampling is highly versatile. However, there are situations where alternative methods might be preferred. An important factor is that Thompson sampling is desirable in a situation that requires both exploration and exploitation, not just one.</p>
<p>For instance, if we can get an accurate estimate from historic data, it’s better to take a greed approach by eliminating low-reward arms, and stick with the best option. This is particularly important in a low-resource environment where exploration is very costly.</p>
<p>Other common limitations, as previously mentioned, are often about how one deals with time horizon limitations and how much information we have about the arms, i.e., choosing the right priors in the beginning.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>We can formulate hardware verification as an MAB problem because it addresses the exploitation-exploration tradeoff. However, it poses a unique challenge because even if we have an oracle ML model, a greedy policy is not optimal. Ongoing exploration is still required to capture new bugs and to update the ML model. Hence, striking a right balance between the exploitation and exploration arms remains a difficult problem.</p>
<p>In this post, I explored Thompson sampling, a simple and straightforward MAB algorithm that can be applied to the verification problem. Regardless of its limitations, given the method’s solid theoretical foundation and its versatility, I think it provides a great starting point for estimating the tradeoff between exploration and exploitation in hardware verification.</p>


</section>

 ]]></description>
  <category>ML</category>
  <category>verification</category>
  <category>Bayesian</category>
  <guid>https://hongsupshin.github.io/posts/2025-01-18/</guid>
  <pubDate>Sat, 18 Jan 2025 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2025-01-18/Fig.png" medium="image" type="image/png" height="85" width="144"/>
</item>
<item>
  <title>Building effective ML teams: lessons from industry</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2025-01-12/</link>
  <description><![CDATA[ 





<p>After a decade as an ML practitioner in industry, I have noticed an interesting dichotomy in how ML is perceived in corporate settings. Senior stakeholders typically fall into two opposing camps.</p>
<p>The Skeptics are interested in adopting ML, but they overestimate the risks of ML product development. They treat standard ML workflows—investigation, experimentation, and evaluation—as if they were experimental research. Proven ML solutions are unnecessarily scrutinized and methodological experiments are considered exploratory and academic.</p>
<p>The Believers view ML as a magical solution for any problem. They fully buy into AI hype and greenlight ML projects without understanding limitations or real business value. They also rush to production even when the solution is half-baked and needs validation.</p>
<p>When it comes to ML discussion, the ML community often talks about state-of-the-art technology but rarely about how ML teams actually get things done. ML teams have to navigate between the two extremes, on the one hand building confidence in ML solutions, and on the other setting realistic expectations about capabilities and limitations. While working with the stakeholders, ML teams must also maintain their autonomy and technical integrity without sacrificing efficiency.</p>
<section id="research-excellence-and-judgment" class="level2">
<h2 class="anchored" data-anchor-id="research-excellence-and-judgment">Research Excellence and Judgment</h2>
<p>Good research judgment is at the core of navigating these extremes. This goes beyond technical expertise and includes:</p>
<ul>
<li>Intuition for distinguishing experimental approaches from proven solutions</li>
<li>Understanding when to invest in deep research versus applying established tools</li>
<li>Accurately evaluating when a problem is truly solved and whether it is usable and scalable</li>
</ul>
<p><a href="http://joschu.net/blog/opinionated-guide-ml-research.html">As John Schulman, an AI researcher at Anthropic has previously mentioned</a>, this is about developing research <em>taste</em>. I have seen teams spend months optimizing problems that could have been solved in a simple way with well-studied existing tools. At the other extreme I have seen teams scale solutions without proper evaluation.</p>
<p>Good research judgment is invaluable when working with stakeholders. For Skeptics, it helps create rigorous validation processes that then build trust through small wins and case studies. For Believers, it helps set realistic technical expectations and encourage stakeholders to play an active role in product development.</p>
<p>Good judgment also implies iterating quickly. Teams must constantly assess whether their approach solves the core problem, and if not, pivot quickly to an alternative solution that still delivers value.</p>
<p>Pivoting sounds easy but in practice, it is not. People naturally become attached to their ideas, and they often get anxious about negative consequences of negative results. Therefore, it is important to have good judgment about how long to pursue an idea versus when to finally abandon it. I’ve seen brilliant colleagues try to force solutions to work despite a lack of evidence. True research maturity includes accepting and learning from negative results.</p>
</section>
<section id="fostering-open-culture-with-clear-technical-vision" class="level2">
<h2 class="anchored" data-anchor-id="fostering-open-culture-with-clear-technical-vision">Fostering Open Culture with Clear Technical Vision</h2>
<p>Research excellence and team culture reinforce each other. Strong research judgment often results from meaningful technical discussions. Teams need a culture where open discussion is encouraged and civil discourse prevails. Without a culture of trust and respect, innovative ideas remain unspoken, and suboptimal solutions go uncontested.</p>
<p>This is why teams need technical leaders with clear vision. A sense of working toward common goals boosts morale and nurtures healthy team dynamics. Clear vision in leaders requires them to have good research judgment, which is why having ML practitioners in management proves crucial. When organizations underestimate researchers’ leadership skills, and exclude them from strategic discussions, it creates a gulf between technical and business objectives in ML projects.</p>
<p>Teams built with clear vision develop conviction when communicating with stakeholders. Clients and stakeholders without strong ML expertise often suggest unrealistic solutions. Instead of agreeing to everything, teams and their tech leads must discern the relevant demands while continuously proving value to the stakeholders. An especially critical role for good research judgment is to tell the stakeholders when ML is not needed. Doing so protects teams from overpromising, helps them establish autonomy, and eventually earns them more trust from stakeholders.</p>
</section>
<section id="establishing-technical-standards" class="level2">
<h2 class="anchored" data-anchor-id="establishing-technical-standards">Establishing Technical Standards</h2>
<p>Even teams with strong culture and technical excellence can collaborate inefficiently. A simple solution is to build clear technical standards. When a team shares a common understanding of technical quality, reviewing and critiquing work becomes less burdensome, and product quality improves quickly.</p>
<p>Technical standards also include reproducibility, benchmarking, and rigorous evaluation. While staying current with new ideas is crucial in the fast-moving ML field, it shouldn’t come at the expense of product quality. Without clear standards, comparing different approaches becomes challenging, leading to technical debt.</p>
<p>When developing standards, we should avoid rigid and overly complicated standards, which hinder innovation and slow down experiments. Knowing where to enforce stricter compliance also matters: the cost of neglecting model evaluation standards is higher than ignoring code style.</p>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>After a decade in industry, I’ve learned that technical excellence alone is insufficient for successful ML projects. As ML has become ubiquitous, technical standards have soared, yet truly effective ML teams remain rare. And with ML tools and expertise becoming increasingly democratized, the factors differentiating teams will be clear: research excellence, strong technical vision, open culture, and thoughtful technical standards. Look for these elements to separate teams that merely dabble in ML from those that transform their organizations through it.</p>


</section>

 ]]></description>
  <category>ML</category>
  <category>collaboration</category>
  <guid>https://hongsupshin.github.io/posts/2025-01-12/</guid>
  <pubDate>Sun, 12 Jan 2025 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2025-01-12/Fig.png" medium="image" type="image/png" height="129" width="144"/>
</item>
<item>
  <title>Building datasets for model benchmarking in production</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2024-10-05/</link>
  <description><![CDATA[ 





<p>At its core, benchmarking serves as a systematic methodology for objectively evaluating techniques or products through carefully curated test samples. In ML, this practice has traditionally been used in academic research, enabling rigorous comparison of various deep learning models. However, its utility extends beyond research, and it becomes an invaluable tool in production environments, similar to A/B testing for new feature evaluation. Here, we can construct benchmark datasets from historical data, tailoring the evaluation process to our own needs in real-world scenarios.</p>
<p>In this post, I am focusing on ML model benchmarking, which primarily evaluates model performance and its robustness, and other factors such as training cost and inference latency. While the landscape of ML benchmarking is dominated by image and text datasets designed for deep learning research, I would like to focus on a less traversed yet equally critical domain: tabular benchmark datasets in production environments. We’ll examine the practical considerations that arise when applying benchmarking to real-world applications.</p>
<section id="data-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-preprocessing">Data preprocessing</h2>
<p>When building benchmark datasets, data preprocessing is typically conducted so that the data are ready for model training, removing the computational burden of data preparation. Although this is a common practice, for data-centric AI, experimentation demands raw data for optimizing preprocessing pipelines or refining feature engineering methodologies. In this case, I propose saving fitted preprocessors within the benchmark itself to only spend compute on data transformation but not preprocessing.</p>
</section>
<section id="data-split-and-reproducibility" class="level2">
<h2 class="anchored" data-anchor-id="data-split-and-reproducibility">Data split and reproducibility</h2>
<p>Deep learning benchmarks, constrained by computational costs, typically employ a train-validation-test split. For instance, the <a href="https://www.tensorflow.org/datasets/catalog/imagenet2012">ImageNet dataset</a> on TensorFlow shows the <code>'train', 'validation', 'test'</code> splits. In contrast, tabular ML often uses cross-validation. Rather than redundantly storing multiple datasets for all folds, I suggest saving train-test index tuples, which can be easily converted to cross-validator iterator. This is also more direct and versatile than storing cross-validator parameters such as parameters of sklearn’s <code>KFold</code>.</p>
</section>
<section id="data-curation" class="level2">
<h2 class="anchored" data-anchor-id="data-curation">Data curation</h2>
<p>While having high-quality and unbiased benchmark datasets is important, the process of data curation in production environments requires a more thoughtful approach. Rather than simply dismissing outliers (and labeling them as simply <em>bad</em>), I suggest still including them while flagging them for separate analysis during benchmarking. This approach not only preserves the integrity of your dataset but also may discover new insights into your data.</p>
</section>
<section id="data-staleness" class="level2">
<h2 class="anchored" data-anchor-id="data-staleness">Data staleness</h2>
<p>In research settings, benchmark datasets are static and rarely updated. In production environments, however, this can be a problem because of data staleness, leading to the decreased representativeness of the benchmark. Drawing inspiration from A/B testing, I recommend periodically refreshing benchmark datasets or building sufficiently diverse datasets that cover the wide spectrum of product lifecycle.</p>
</section>
<section id="overfitting-to-the-benchmark-data" class="level2">
<h2 class="anchored" data-anchor-id="overfitting-to-the-benchmark-data">Overfitting to the benchmark data</h2>
<p><a href="https://arxiv.org/abs/2405.00332">A recent paper</a> has showed the susceptibility of LLMs to overfitting for public benchmark datasets because the benchmark datasets are repeatedly used when designing models. The iterative nature of ML development cycle creates a similar risk of information leakage through repeated test set exposure. To address this, I recommend a more strict test set isolation protocol or regular update to benchmark dataset (addressing data staleness as a bonus).</p>
</section>
<section id="other-considerations" class="level2">
<h2 class="anchored" data-anchor-id="other-considerations">Other considerations</h2>
<p>Beyond these, there are other important factors to consider. If we can define a measure of diversity of benchmark (e.g., subgroup diversity), it’s important that the benchmark is diverse and inclusive. Resource optimization, particularly in terms of data volume, must be balanced according to experiment design. Perhaps most critically, benchmark dataset development must go thorough privacy, security, and ethical evaluations as well to guarantee they meet regulation standards.</p>


</section>

 ]]></description>
  <category>ML</category>
  <category>ML Ops</category>
  <category>data</category>
  <guid>https://hongsupshin.github.io/posts/2024-10-05/</guid>
  <pubDate>Sat, 05 Oct 2024 05:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2024-10-05/GPTbenchmark.png" medium="image" type="image/png" height="128" width="144"/>
</item>
<item>
  <title>Modeling tabular data using conditional GAN</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2024-05-30/</link>
  <description><![CDATA[ 





<p>At work, I train models using tabular data with extreme class imbalance, which is often quite challenging. To tackle this, I have been looking into data augmentation techniques for tabular data, which is a relatively understudied domain compared to unstructured data. <a href="https://docs.sdv.dev/sdv">Synthetic Data Vault</a> is a popular python library for tabular data synthesis, and the main techniques originate from the paper above. Since class imbalance is a common problem in real-world data and most of us work with tabular data, I think this will be an interesting paper to discuss. I presented the paper in Austin ML Journal Club in May 2024.</p>
<section id="paper-summary" class="level2">
<h2 class="anchored" data-anchor-id="paper-summary">Paper summary</h2>
<p>Several challenges lie in tabular data synthesis. They often have mixed data types with non-Gaussian or multi-modal distributions. Categorical variables in a tabular dataset often have severe class imbalance and provide insufficient samples. The authors argue that GAN’s flexibility can address these problems. The authors introduce several techniques for their approach, conditional-tabular GAN (CT-GAN).</p>
<section id="mode-specific-normalization" class="level3">
<h3 class="anchored" data-anchor-id="mode-specific-normalization">Mode-specific normalization</h3>
<p>The basic idea is mode-specific normalization is to convert a continuous-variable column into a set of columns where each column represents an estimated mode (like an indicator) and its value represents the weight of the corresponding mode. To estimate the number of the modes, they use variational Gaussian mixture (VGM) method.</p>
</section>
<section id="conditional-generator-and-training-by-sampling" class="level3">
<h3 class="anchored" data-anchor-id="conditional-generator-and-training-by-sampling">Conditional generator and training-by-sampling</h3>
<p>Traditional GANs have Gaussian assumption where a vector is sampled from a standard multivariate normal distribution. However, this doesn’t account for class imbalance, which is a problem in tabular data. So the goal here is to resample data so that all categories are sampled <em>evenly</em> during training, and to estimate the conditional distribution of rows given that particular value at that particular column.</p>
</section>
<section id="ct-gan-model" class="level3">
<h3 class="anchored" data-anchor-id="ct-gan-model">CT-GAN model</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2024-05-30/Fig 2.png" class="img-fluid figure-img"></p>
<figcaption>CT GAN model</figcaption>
</figure>
</div>
<p>In the CT-GAN model, the data are represented Conditional vector where each discrete column is a one-hot vector. The mask vector is used to only represent a category of a single discrete column (in one-hot way, the rest is all zero). The generator loss is cross-entropy between <img src="https://latex.codecogs.com/png.latex?m_%7Bi%5E*%7D"> (given by data) and <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bd%7D_%7Bi%5E*%7D"> (produced by the generator) averaged over all rows in a batch. During the critic assessment stage, the model measures distance between learned conditional distribution and conditional distribution on real data <em>while exploring all possible values evenly</em>.</p>
</section>
<section id="model-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation">Model evaluation</h3>
<section id="baseline-models" class="level4">
<h4 class="anchored" data-anchor-id="baseline-models">Baseline models</h4>
<p>The paper uses multiple baseline models for performance comparison. They use two Bayesian network models (CLBN and PrivBN), other GAN models (MedGAN, VeeGAN, TableGAN), and a tabular VAE (TVAE) model that they built. The TVAE model has multivariate Gaussian assumption.</p>
</section>
<section id="evaluation-metrics" class="level4">
<h4 class="anchored" data-anchor-id="evaluation-metrics">Evaluation metrics</h4>
<p>For model comparison, the authors use two metrics. Likelihood fitness metric which estimates how well the synthetic data can fit the data oracle well. They also use <em>ML efficacy</em>, which measures whether ML model performance from synthetic data is comparable to that from using real data.</p>
</section>
<section id="results" class="level4">
<h4 class="anchored" data-anchor-id="results">Results</h4>
<p>For model comparison, they used several different sets of data. First, they used multi-modal Gaussian-simulated data. Here, other GANs suffer from model collapse and the CT-GAN showed better performance. When simulated data from Bayesian networks were used, the Bayesian baseline models (CLBN and PrivBN) performed the best. With real-world data, TVAE and CTGAN performed the best although TVAE was often better.</p>
</section>
</section>
</section>
<section id="journal-club-discussion" class="level2">
<h2 class="anchored" data-anchor-id="journal-club-discussion">Journal club discussion</h2>
<p>Even though we were pleased to see good baseline comparison with multiple different datasets, we thought the authors should have did more thorough work on literature review such as comparing their work with <code>synthpop</code>, a widely-used data synthesis package in R. They also could have looked into other statistical models because data synthesis an active research area in statistics.</p>
<p>We also questioned the validity of the VGM technique because it is the core of creating the embedding of continuous variables. The proposed model does not have checks that evaluate the fidelity of VGM estimation, and thus poor estimation of a multi-model distribution by it can further compromise model performance in general.</p>
<p>We also thought their claim on CT-GAN was a bit exaggerated. First, in most benchmark datasets, it was actually TVAE model that performed the best. In the performance comparison table, there was only one regression data, which we thought insufficient to evaluate the <em>ML efficacy</em> metric the authors proposed. Finally, the proposed models for the regression problem showed <em>negative</em> R scores, suggesting that the models performed quite poorly.</p>
<p>Overall, we thought the approach was novel but the evaluation could have been improved given that tabular datasets are quite diverse. Also, given that GAN is expensive train, we would have liked to learn more practical aspects of the implementation.</p>


</section>

 ]]></description>
  <category>paper</category>
  <category>GenAI</category>
  <category>ML</category>
  <guid>https://hongsupshin.github.io/posts/2024-05-30/</guid>
  <pubDate>Thu, 30 May 2024 05:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2024-05-30/Fig 1.png" medium="image" type="image/png" height="128" width="144"/>
</item>
<item>
  <title>Dissecting racial bias in an algorithm used to manage the health of populations</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2024-03-28/</link>
  <description><![CDATA[ 





<p>Fresh out of academia and at my first job, I remember being surprised by the great power I was able to wield as the main data scientist in the team. A few lines of my code could easily have cascading impact on business decisions. And (as is often the case) since management didn’t care much about technical details, this power gave me a sense of grave responsibility, which was honestly often terrifying. To this day, this sense is something I try to remind myself of, especially because ML systems are getting more complex and we still have very little accountability for ML. So in a way, every ML practitioner is the first line of defense. And this responsibility is more critical if one is working in an high-impact domain such as healthcare.</p>
<p>These days it feels like ML is all about LLMs and AI assistants. But algorithmic bias is still widespread, and unfortunately it’s even more overshadowed by this massive hype. This seminal paper from 2019 identified racial bias in a healthcare algorithm and discussed the problem of label choice bias. I find this paper still relevant because this bias can easily sneak when building datasets and algorithms. Since the paper is a few years old, it will be interesting to discuss what’s happened since then. I presented the paper in Mar 2024 in Austin ML Journal Club.</p>
<section id="paper-summary" class="level2">
<h2 class="anchored" data-anchor-id="paper-summary">Paper summary</h2>
<p>This is a famous paper in Fair ML field that’s cited frequently. One reason is that this is one of the first algorithm audit papers that used a creative approach to dissect an algorithm already used in public. The first author Ziad Obermeyer is an active figure in algorithmic bias specifically in healthcare, and the corresponding author Sendhil Mullainathan is a seminal figure in behavioral economics.</p>
<p>The main message of the paper is simple and straightforward. In a widely used healthcare algorithm, the authors found that given a score generated by a trained algorithm, which predicts how sick a patient is, Black patients were much sicker than the White. By using creative approaches, the authors found that this algorithmic behavior originated from label choice bias. The algorithm used healthcare cost as target, which the ML practitioners considered as a proxy for a patient’s sickness. The authors cautioned that seemingly effective proxies for ground truth can cause algorithmic bias.</p>
<section id="background" class="level3">
<h3 class="anchored" data-anchor-id="background">Background</h3>
<p>The authors discussed the difficulty of empirical investigation on commercially used algorithms because they are considered proprietary, and thus researchers have to work “from the outside”. They can come up with creative methods but these can be still limiting because without knowing how the model works, it is difficult to understand how and why. For instance, we need training data, objective function, prediction method, and so on, to have a deeper understanding of an algorithm.</p>
<section id="high-risk-care-management-system" class="level4">
<h4 class="anchored" data-anchor-id="high-risk-care-management-system">High-risk care management system</h4>
<p>This study is about a high-risk care management system often used in hospitals to provide care for complex medical needs, which tend to be quite expensive. In essence, hospitals want to prioritize patients so that they can optimize which patients will benefit the most by optimizing resource allocation. For instance, early identification of a high risk patient can reduce expensive cost later, like an ER visit. The authors said healthy care systems rely on algorithms <em>extensively</em> for this type of care management. This type of algorithm actually has many analogies, and an algorithm like this is often called as a risk assessment tool, which is also used in finance, criminal justice, and so on.</p>
</section>
<section id="who-will-benefit-the-most" class="level4">
<h4 class="anchored" data-anchor-id="who-will-benefit-the-most">“Who will benefit the most?”</h4>
<p>The authors emphasized that this is a difficult <em>causal inference</em> problem. We need to estimate individual treatment effects after the resources are allocated. The underlying assumption is “those with the greatest needs will benefit the most,” and thus we are setting <em>future health care needs</em> as main target.</p>
</section>
</section>
<section id="the-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="the-algorithm">The algorithm</h3>
<p>For this study, the authors had a unique advantage to have access to training data, objective function, and prediction. This is mainly due to that the first author worked at the hospital which used the algorithm and he had access.</p>
<p>The data are from a large academic hospital, collected between 2013 and 2015. The authors focused on the white vs.&nbsp;black relationship to examine racial bias. There were about 6k black patients and 40k white patients. For the algorithm, <strong>total medical expenditure</strong> (<img src="https://latex.codecogs.com/png.latex?C">) is used as target variable. The input feature data are collected from insurance claim data, which includes demographics, insurance type, ICD-9 (international classification of diseases code), medications, medical encounters such as surgery or radiology, and so on. The authors shared the code and data <a href="https://gitlab.com/labsysmed/dissecting-bias/-/tree/master">here</a> and we can take a look at the data ourselves.</p>
<div id="660576c6" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb1-5">plt.style.use(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ggplot'</span>)</span>
<span id="cb1-6"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>config InlineBackend.figure_format<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'retina'</span></span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> seaborn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> sns</span></code></pre></div></div>
</details>
</div>
<div id="0f908394" class="cell" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://gitlab.com/labsysmed/dissecting-bias/-/raw/master/data/data_new.csv"</span>)</span>
<span id="cb2-2">data.head()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="8">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">risk_score_t</th>
<th data-quarto-table-cell-role="th">program_enrolled_t</th>
<th data-quarto-table-cell-role="th">cost_t</th>
<th data-quarto-table-cell-role="th">cost_avoidable_t</th>
<th data-quarto-table-cell-role="th">bps_mean_t</th>
<th data-quarto-table-cell-role="th">ghba1c_mean_t</th>
<th data-quarto-table-cell-role="th">hct_mean_t</th>
<th data-quarto-table-cell-role="th">cre_mean_t</th>
<th data-quarto-table-cell-role="th">ldl_mean_t</th>
<th data-quarto-table-cell-role="th">race</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">trig_min-high_tm1</th>
<th data-quarto-table-cell-role="th">trig_min-normal_tm1</th>
<th data-quarto-table-cell-role="th">trig_mean-low_tm1</th>
<th data-quarto-table-cell-role="th">trig_mean-high_tm1</th>
<th data-quarto-table-cell-role="th">trig_mean-normal_tm1</th>
<th data-quarto-table-cell-role="th">trig_max-low_tm1</th>
<th data-quarto-table-cell-role="th">trig_max-high_tm1</th>
<th data-quarto-table-cell-role="th">trig_max-normal_tm1</th>
<th data-quarto-table-cell-role="th">gagne_sum_tm1</th>
<th data-quarto-table-cell-role="th">gagne_sum_t</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>1.987430</td>
<td>0</td>
<td>1200.0</td>
<td>0.0</td>
<td>NaN</td>
<td>5.4</td>
<td>NaN</td>
<td>1.110000</td>
<td>194.0</td>
<td>white</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>7.677934</td>
<td>0</td>
<td>2600.0</td>
<td>0.0</td>
<td>119.0</td>
<td>5.5</td>
<td>40.4</td>
<td>0.860000</td>
<td>93.0</td>
<td>white</td>
<td>...</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>4</td>
<td>3</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>0.407678</td>
<td>0</td>
<td>500.0</td>
<td>0.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>white</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>0.798369</td>
<td>0</td>
<td>1300.0</td>
<td>0.0</td>
<td>117.0</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>white</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>17.513165</td>
<td>0</td>
<td>1100.0</td>
<td>0.0</td>
<td>116.0</td>
<td>NaN</td>
<td>34.1</td>
<td>1.303333</td>
<td>53.0</td>
<td>white</td>
<td>...</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>5 rows × 160 columns</p>
</div>
</div>
</div>
<p>Note that the risk score (<img src="https://latex.codecogs.com/png.latex?R">, <code>risk_score_t</code>) and the predicted cost (<img src="https://latex.codecogs.com/png.latex?C">, <code>cost_t</code>) are not the same. <strong>We do NOT know how the risk score is calculated based on the predicted score.</strong></p>
<div id="2cd7f6e3-d93d-4af6-a896-fbc4abb1a59a" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">plt.figure(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>))</span>
<span id="cb3-2">plt.plot(data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cost_t'</span>], data[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_score_t'</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'.'</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span>)</span>
<span id="cb3-3">plt.loglog()</span>
<span id="cb3-4">plt.axis(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>)</span>
<span id="cb3-5">plt.xlabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Predicted Cost'</span>)</span>
<span id="cb3-6">plt.ylabel(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Risk Score'</span>)</span>
<span id="cb3-7">plt.show()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2024-03-28/index_files/figure-html/cell-4-output-1.png" width="548" height="528" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The algorithm score was generated for each patient during the enrollment period. After ranking this prediction scores from a group, the top 3% (97th percentile) is automatically flagged as required to be enrolled although this does not guarantee enrollment. The top 45% (55th percentile) is referred to their PCP for further examination.</p>
</section>
<section id="the-algorithm-audit" class="level3">
<h3 class="anchored" data-anchor-id="the-algorithm-audit">The algorithm audit</h3>
<p>As a main method, the authors measured the algorithm calibration to assess fairness across different racial groups. This means that the authors focused on parity of how risk score is calibrated across race. Fair result would satisfy <img src="https://latex.codecogs.com/png.latex?E%5BY%7CR,%20W%5D%20=%20E%5BY%7CR,%20B%5D"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?Y"> is our main interest, <img src="https://latex.codecogs.com/png.latex?W"> is the White, <img src="https://latex.codecogs.com/png.latex?B"> is the Black, and <img src="https://latex.codecogs.com/png.latex?R"> is the risk score.</p>
<p>To dissect the algorithm, the authors compared the distribution of <img src="https://latex.codecogs.com/png.latex?R_%7Bi,%20t%7D%7CH_%7Bi,%20t%7D"> and <img src="https://latex.codecogs.com/png.latex?R_%7Bi,%20t%7D%7CC_%7Bi,%20t%7D"> between White and Black patients where - <img src="https://latex.codecogs.com/png.latex?R_%7Bi,%20t%7D">: risk score given patient <img src="https://latex.codecogs.com/png.latex?i"> in year <img src="https://latex.codecogs.com/png.latex?t"> given the input feature <img src="https://latex.codecogs.com/png.latex?X_%7Bi,%20t-1%7D"> from the previous year - <img src="https://latex.codecogs.com/png.latex?H_%7Bi,%20t%7D">: realized health - <img src="https://latex.codecogs.com/png.latex?C_%7Bi,%20t%7D">: actual cost</p>
<p>To measure <img src="https://latex.codecogs.com/png.latex?H">, the authors used health record data, diagnoses, lab results, and vital sign data. As a main measure of realized health, the authors used comorbidity score, the total number of chronic illnesses over a year, which is a measure of medical complexity. The cost variable <img src="https://latex.codecogs.com/png.latex?C"> includes insurance claims on utilization, outpatient/ER visit, hospitalization, and general health care costs.</p>
</section>
<section id="using-a-counterfactual-scenario-to-describe-racial-bias-fig.-1b" class="level3">
<h3 class="anchored" data-anchor-id="using-a-counterfactual-scenario-to-describe-racial-bias-fig.-1b">Using a counterfactual scenario to describe racial bias (Fig. 1B)</h3>
<p>Fig. 1A shows mean comorbidity vs.&nbsp;risk score. At a given risk score, Blacks have significantly more illness than Whites. For instance, at the 97th percentile, mean comorbidity score was 4.8 for Black and 3.8 for White. This means that sicker black patients and healthier white patients can have the same score, causing substantial disparities in program screening. The authors designed a counterfactual scenario with no racial bias, and described the severity of the disparity.</p>
<p><strong>We found it difficult to understand how the authors measured the disparity between the counterfactual and actual</strong>. Fortunately, the code that the authors shared helped us. Here is how this assessment was done in the paper:</p>
<ol type="1">
<li>At a given percentile (e.g., 97th percentile) identify the following:
<ul>
<li>Group “White-above”: White patients whose risk score is above the threshold</li>
<li>Group “Black-above”: Black patients whose risk score is above the threshold</li>
</ul></li>
<li>If the comorbidity score of the healthiest patient in the White-above group is <em>lower</em> than that of the sickest patient in the Black-lower group, remove the healthiest white patients from White-above, and move the sickest Black patient from the Black-lower above the threshold.</li>
<li>Repeat this process until patients cannot be moved any more.</li>
</ol>
<p>The second step can be considered as a White patient who shouldn’t be in the enrollment group (above the threshold) giving their spot to the sicker black patient, who was supposed to be in the enrollment group. The authors’ original code was written in R but I translated it into python to further investigate this simulation.</p>
<div id="2cfdc3c9" class="cell" data-execution_count="25">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> setup(data, default_in_percentile<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">95</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">97</span>]):</span>
<span id="cb4-2">    cohort <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'race'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_score_t'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>]]</span>
<span id="cb4-3">    dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cohort.copy()</span>
<span id="cb4-4">    dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_pctile'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.cut(dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_score_t'</span>], bins<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>np.unique(np.percentile(dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_score_t'</span>], np.arange(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">101</span>))), include_lowest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, labels<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb4-5">    </span>
<span id="cb4-6">    enroll_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(default_in_percentile), <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>))</span>
<span id="cb4-7">    enroll_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(enroll_stats, columns<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black_before'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black_after'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ratio'</span>])</span>
<span id="cb4-8">    enroll_stats.index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> default_in_percentile</span>
<span id="cb4-9">    </span>
<span id="cb4-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dt'</span>: dt, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'enroll_stats'</span>: enroll_stats}</span></code></pre></div></div>
</details>
</div>
<div id="81e4949a" class="cell" data-execution_count="49">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">default_in_percentile <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">97</span>]</span>
<span id="cb5-2">j <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb5-3"></span>
<span id="cb5-4">dt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> setup(data, default_in_percentile)[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dt'</span>]</span>
<span id="cb5-5">enroll_stats <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> setup(data, default_in_percentile)[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'enroll_stats'</span>]</span>
<span id="cb5-6"></span>
<span id="cb5-7">prior_enrolled <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dt[dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_pctile'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> default_in_percentile[j]]</span>
<span id="cb5-8">prior_w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prior_enrolled[prior_enrolled[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'race'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>]</span>
<span id="cb5-9">prior_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prior_enrolled[prior_enrolled[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'race'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>]</span>
<span id="cb5-10"></span>
<span id="cb5-11">upperb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dt[(dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_pctile'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> default_in_percentile[j]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'race'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>)]</span>
<span id="cb5-12">upperw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dt[(dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_pctile'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> default_in_percentile[j]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'race'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'white'</span>)]</span>
<span id="cb5-13">lowerb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dt[(dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_pctile'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> default_in_percentile[j]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&amp;</span> (dt[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'race'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'black'</span>)]</span>
<span id="cb5-14"></span>
<span id="cb5-15">upperw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> upperw.sort_values(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>)</span>
<span id="cb5-16">lowerb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lowerb.sort_values([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'risk_score_t'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>], ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>])</span>
<span id="cb5-17"></span>
<span id="cb5-18">upperb_actual <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> upperb.copy()</span>
<span id="cb5-19">upperw_actual <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> upperw.copy()</span>
<span id="cb5-20">lowerb_actual <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lowerb.copy()</span></code></pre></div></div>
</details>
</div>
<div id="106954f1" class="cell" data-execution_count="50">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">sw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb6-2">sb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb6-3">switched_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb6-4">switched_w <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb6-5">switched_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb6-6"></span>
<span id="cb6-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> sb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> lowerb.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]:</span>
<span id="cb6-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> upperw.iloc[sw][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> lowerb.iloc[sb][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>]:</span>
<span id="cb6-9">        switched_w.append(upperw.iloc[sw])</span>
<span id="cb6-10">        switched_b.append(lowerb.iloc[sb])</span>
<span id="cb6-11"></span>
<span id="cb6-12">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># healthiest white patient is dropped and sickest black patient is added</span></span>
<span id="cb6-13">        upperb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.concat([upperb, pd.DataFrame(lowerb.iloc[sb]).T], axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb6-14">        upperw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> upperw.drop(upperw.index[sw])</span>
<span id="cb6-15">        upperw <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> upperw.sort_values(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>)</span>
<span id="cb6-16">        </span>
<span id="cb6-17">        sb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb6-18">        switched_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb6-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-20">        sb <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb6-21">        switched_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> switched_count</span></code></pre></div></div>
</details>
</div>
<div id="f4c85304" class="cell" data-execution_count="51">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">fig, axes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>), sharex<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, sharey<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-2">sns.kdeplot(upperw_actual[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'White-upper'</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb7-3">sns.kdeplot(upperb_actual[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Black-upper'</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb7-4">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(xlabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Comorbidity score'</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Actual'</span>)</span>
<span id="cb7-5">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].legend()</span>
<span id="cb7-6"></span>
<span id="cb7-7">sns.kdeplot(upperw[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'White-upper'</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb7-8">sns.kdeplot(upperb[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gagne_sum_t'</span>], label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Black-upper'</span>, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb7-9">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(xlabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Comorbidity score'</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Counterfactual'</span>)</span>
<span id="cb7-10">axes[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].legend()</span>
<span id="cb7-11"></span>
<span id="cb7-12">fig.suptitle(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'97th percentile'</span>, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>, y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.95</span>, fontsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>)</span>
<span id="cb7-13">fig.tight_layout()</span></code></pre></div></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2024-03-28/index_files/figure-html/cell-8-output-1.png" width="789" height="386" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The left figure shows the distribution of comorbidity score of white and black patients who are above the 97th percentile threshold, identified by the algorithm as those who need the high-risk care. The white patient distribution is tilted to the left and the black patient’s has more density towards right, indicating that white patients are generally healthier thant the black patients in the above-threshold group. The right figure is after we simulate the counterfactual scenario by swapping the healthiest white patient’s slot above the threshold with the sickest black patient below the threshold until the swapping cannot be done any more. The distribution now shows that the two distributions are similar.</p>
</section>
<section id="mechanisms-of-bias" class="level3">
<h3 class="anchored" data-anchor-id="mechanisms-of-bias">Mechanisms of bias</h3>
<p>Based on Fig. 3A, the algorithm calibrates cost (target variable) quite well, meaning this is not a problem of prediction quality. Fig. 3B shows that at a given level of health score, black patients generate lower costs than the White, making the algorithm prioritizing the White patients. Tab. S2 shows that how healthcare cost is spent between the black and white patients vary by categories. For instance, the black patients have higher costs related to ER and dialysis and fewer inpatient surgical and outpatient specialist costs, which also suggest that their healthcare cost occurs when the worst scenario happens (ER visit). The negative values mean black patients spend less money in that category.</p>
<p><img src="https://hongsupshin.github.io/posts/2024-03-28/Tab S2.png" class="img-fluid"></p>
<p>There are several socio-economic reasons. First, poor patients face substantial barriers to accessing health care, even the insured ones such as geography or transportation, demands from job and child care, and knowledge of reasons to seek care. There is also cost that is directly affected by race. <a href="https://en.wikipedia.org/wiki/Taste-based_discrimination">Taste-based discrimination</a>, employers’ prejudice or dislikes in an organizational culture rooted in prohibited grounds can have negative results in hiring minority workers, is one, and the doctor-patient relationship is another. It is known that black patients would take preventive care suggested by black provider more and they also have lower trust in health care system in general due to an incident like Tuskegee study. Doctors also may have different perceptions of black patients regarding such as intelligence, affiliation, or pain tolerance.</p>
</section>
<section id="experiments-on-label-choice-and-human-ai-interaction" class="level3">
<h3 class="anchored" data-anchor-id="experiments-on-label-choice-and-human-ai-interaction">Experiments on label choice and human-AI interaction</h3>
<p>The authors then conducted experiments to see alternative label choices other than the total health care cost can result in fairer results. They compared the original model (total cost) against the two alternatives: avoidable cost such as ER visit, and health (comorbidity score). Even though it was not perfect, they found that the algorithms trained on alternative labels produced fairer results.</p>
<p>Finally, the authors examined the interaction between human doctors and the algorithm. The algorithm’s risk score suggests a pool of patients candidates to doctors and they make the ultimate decision on the enrollment. The experiment showed that the doctors can “redress” (=correct) algorithm’s bias but not by much. This indicates that the racial bias produced by the algorithm can have drastic disparaging effect on healthcare management across different race groups that humans cannot correct completely.</p>
</section>
<section id="working-on-solutions-together" class="level3">
<h3 class="anchored" data-anchor-id="working-on-solutions-together">Working on solutions together</h3>
<p>Interestingly, the authors mentioned that they reached out to the manufacturer of the algorithm with their results. Fortunately, they were able to replicate the authors’ results on their own and by collaborating with the authors, they were able to reduce the bias by 84%. With this, the authors ended the paper on a hopeful note. They emphasized that algorithmic bias is fixable and this does not necessarily require changes in the algorithm itself.</p>
<p>The paper triggered multiple investigations and stimulated algorithm audit research in the following years. In the same year in 2019, <a href="https://www.wsj.com/articles/new-york-regulator-probes-unitedhealth-algorithm-for-racial-bias-11572087601">New York regulators started investing UnitedHealth algorithm for racial bias</a> and similarly in <a href="https://oag.ca.gov/news/press-releases/attorney-general-bonta-launches-inquiry-racial-and-ethnic-bias-healthcare">California in 2022</a>. In 2021, <a href="https://www.ftc.gov/business-guidance/blog/2021/04/aiming-truth-fairness-equity-your-companys-use-ai">FTC published a guidance document on truth, fairness, and equity in the use of AI in industry</a>. In 2024, there has been a <a href="https://www.finance.senate.gov/chairmans-news/wyden-statement-at-finance-committee-hearing-on-ai-in-health-care">Senate Finance Committee Hearing on AI in healthcare</a> as well.</p>
</section>
</section>
<section id="journal-club-discussion" class="level2">
<h2 class="anchored" data-anchor-id="journal-club-discussion">Journal club discussion</h2>
<p>We first had several questions about the care management system described in the paper. The cost categories listed in the paper seemed to include cost for both patients and hospitals and we were not sure whether the cost allocation mattered at all. Some of us were also curious about the actual outcome of the care management system especially for the patients who were enrolled (and potential racial bias of the realized outcome). We also talked about other demographic features that can cause medical bias such as gender and age, and especially their intersectionality.</p>
<p>We agreed that the technical description of the counterfactual scenario was not clear in the paper, and we spent some time understanding how it worked. Similarly, Tab. 2, where the authors created different models with alternative labels and measured the proportion of the high-risk patients identify each model, was a bit confusing to understand, but fortunately, because the authors shared their code for all analyses, we were able to follow eventually.</p>
<p>We then talked about how to satisfy certain criteria during model training. We questioned the feasibility of satisfying multiple criteria (e.g., fairness metric and accuracy) in healthcare where we often have to work with very small data. This problem will get worsened when considering intersectionality, for instance. And the small data problem naturally leads to safety and privacy issues, especially when data contain sensitive information like in healthcare.</p>
<p>We also discussed practical aspects such as how to roll out an algorithm carefully especially when it touches millions of people. Some companies release their models gradually and share training data publicly, but we were wondering whether there were more specific tips on how ML deployment can evolve while having human in the loop, especially those who are impacted by the algorithm. And finally, we agreed that even though it’s important to understand how algorithmic bias damages our society and people, we were hopeful that we would like to learn about positive and beneficial use case of ML.</p>


</section>

 ]]></description>
  <category>paper</category>
  <category>ML</category>
  <category>ethics</category>
  <category>fairness</category>
  <guid>https://hongsupshin.github.io/posts/2024-03-28/</guid>
  <pubDate>Thu, 28 Mar 2024 05:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2024-03-28/Fig 1b.png" medium="image" type="image/png" height="151" width="144"/>
</item>
<item>
  <title>Algorithmic decision-making and fairness (Stanford Tech Ethics course, Week 1)</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2023-10-11-ethics-week2/</link>
  <description><![CDATA[ 





<section id="reading-assignments" class="level2">
<h2 class="anchored" data-anchor-id="reading-assignments">Reading assignments</h2>
<section id="weapons-of-math-destruction-introduction-and-chapter-1" class="level3">
<h3 class="anchored" data-anchor-id="weapons-of-math-destruction-introduction-and-chapter-1"><a href="https://archive.org/details/weapons-of-math-destruction_202209">Weapons of Math Destruction</a>, Introduction and Chapter 1</h3>
<p>This book by Cathy O’Neil is always a nice introduction to learning about algorithmic harms. I sometimes gift the book to friends and colleagues who just start their career in the field. The first two chapters of the book is especially enough to understand the general idea.</p>
<p>I was most interested in the D.C.’s Teacher Evaluation System, <a href="https://dcps.dc.gov/page/impact-dcps-evaluation-and-feedback-system-school-based-personnel">IMPACT</a> and its problems. The system uses student performance score to assess teacher performance. This extremely simple assumption itself seems to be highly problematic, in my opinion. My assumption is that the city considered that this would be one of the easiest solutions to act on (i.e., hiring and firing of teachers). After the system is implemented, highly praised teachers sometimes get fired and for them it was really difficult to understand why the decision was made. It also turned out that teachers sometimes cheat and correct students’ scores.</p>
<p>At the end of the first chapter, the author summarized a pattern of algorithimc harms in three ways. First, the models are usually opaque, which reduce accountability and make them inscrutable. Second, often these models can harm the people who are targeted because training data’s bias is simply reproduced. Third, these models are easily scalable and thus generate harms in a much larger scale.</p>
</section>
<section id="case-study-algorithmic-decision-making-and-accountability" class="level3">
<h3 class="anchored" data-anchor-id="case-study-algorithmic-decision-making-and-accountability"><a href="https://drive.google.com/file/d/12R_CKlk1T8GgvSfUXixWlYWPzyhMooAQ/view?usp=sharing">Case Study: Algorithmic Decision-Making and Accountability</a></h3>
<p>This cast study is about an algorithmic transparency bill introduced by a New York City Council, James Vacca back in 2017. The original version of the bill would require city agencies “that use algorithms or other automated processing methods that target services, impose penalties, or police persons to <strong>publish the source code</strong> used for such processing.” Given that this is still something very difficult to practice in 2023, I find this proposal quite radical and refreshing. His motivation made sense though: complete transparency on any public automated decision-making.</p>
<p>Unfortunately the bill has met many criticisms such as privacy concerns, exposure of proprietary information, and effectiveness in public understanding of the source code. The bill was modified several times and the final <em>watered-down</em> version was to create a task force that is comprised of experts in diverse fields that would examine algorithmic decision-making (ADS) tools that the city uses, and make recommendations. The catch though was that various city departments who use these tools are not required to participate in the collaboration with the task force, meaning the participation was voluntary. Also the fact that the task force would simply make recommendations means there is zero enforceability.</p>
<p>I did some digging because I got curious about what happened to the task force. Their website (<a href="https://www.nyc.gov/site/adstaskforce/index.page">New York City Automated Decision Systems Task Force</a>) shows the members of the task force, which actually have active members/researchers in the field of AI ethics. They published <a href="https://www.nyc.gov/assets/adstaskforce/downloads/pdf/ADS-Report-11192019.pdf">a report</a> back in 2019 and at a glance, they do make concrete recommendations on each type of algorithmic decision-making systems in NYC. In Nov 2019, the city seemed to decide to establish an Algorithms Management and Policy Officer (AMPO). But some news articles say this position doesn’t exist any more. Regardless, AMPO did release <a href="https://www.nyc.gov/assets/oti/downloads/pdf/reports/ampo-agency-compliance-cy-2020.pdf">a report</a> in 2020, which has “algorithmic tool directory” that shows how the city’s ADS tools work, which I find pretty useful. Here’s an example:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-10-11-ethics-week2/ampo_2020_example.png" class="img-fluid figure-img"></p>
<figcaption>NYC Algorithmic Management and Policy Officer, Summary of Agency Compliance Reporting. Algorithmic Tool Directory example: Department of Correction</figcaption>
</figure>
</div>
</section>
<section id="a-guide-to-solving-social-problems-with-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="a-guide-to-solving-social-problems-with-machine-learning"><a href="https://hbr.org/2016/12/a-guide-to-solving-social-problems-with-machine-learning">A Guide to Solving Social Problems with Machine Learning</a></h3>
<p>This short 2016 guide was written by Jon Kleinberg, Jens Ludwig, and Sendhil Mullainathan. I’ve been to Kleinberg’s talks several times at FAccT and so I was aware of his previous work.</p>
<p>This guide stood out compared to other reading assignments this week because there was mention of the “enthusiasm” about solving social problems with machine learning (ML). <em>If</em> we can implement a ML system to solve these issues, we can provide greater transparency and potentially better and more desirable outcome especially because sometimes human decision-making process is opaque. This guide was also more technical than other reading materials. The authors mention the following tips:</p>
<section id="look-for-policy-problems-that-hinge-on-prediction" class="level4">
<h4 class="anchored" data-anchor-id="look-for-policy-problems-that-hinge-on-prediction">1. Look for policy problems that hinge on prediction</h4>
<p>The authors emphasize that many social-sector decisions do not require a prediction and the practitioners should be careful when formulating the problem. This is mostly related to assessing the predictive algorithm’s social impact.</p>
<blockquote class="blockquote">
<p>“just because something is predictable, that doesn’t mean we are comfortable having our decision depend on that prediction.”</p>
</blockquote>
</section>
<section id="make-sure-you-are-comfortable-with-the-outcome-youre-predicting" class="level4">
<h4 class="anchored" data-anchor-id="make-sure-you-are-comfortable-with-the-outcome-youre-predicting">2. Make sure you are comfortable with the outcome you’re predicting</h4>
<p>Since ML is rooted in statistics, there are cases where one has to deal with higher level of uncertainty in a system. This alone makes the system less reliable and more challenging to work with, but if the risk is also high, it is better to reconsider whether ML is well-suited here. The authors also mention that ML is often good at optimizing a defined metric only <em>at the expense of everything else</em>.</p>
</section>
<section id="check-for-bias" class="level4">
<h4 class="anchored" data-anchor-id="check-for-bias">3. Check for bias</h4>
<p>In this section, the author mentions racial bias in criminal justice system and how the bias can be easily replicated in ML when the training data simply consist of historic incidents. Another important thing they mentioned was that ML is not good for measuring hard-to-define combination of outcomes such as sentencing where society’s sense of retribution, mercy, and redemption should be factored in (and they are all hard to measure).</p>
</section>
<section id="verify-your-algorithm-in-an-experiment-on-data-it-hasnt-seen" class="level4">
<h4 class="anchored" data-anchor-id="verify-your-algorithm-in-an-experiment-on-data-it-hasnt-seen">4. Verify your algorithm in an experiment on data it hasn’t seen</h4>
<p>This section was about evaluating the model with the right validation data. They specifically talk about cases where there are inherent sampling bias in collecting labeled data. For instance, in a ML-based filter system, you end up collecting positively-labeled cases because the negative predictions never come through. They also warn about scalability:</p>
<blockquote class="blockquote">
<p>“It can be misguided, and sometimes outright harmful, to adopt and scale up new predictive tools when they’ve only been evaluated on cases from historical data with labels, rather than evaluated based on their effect on the key policy decision of interest.”</p>
</blockquote>
</section>
<section id="remember-there-is-still-a-lot-we-dont-know" class="level4">
<h4 class="anchored" data-anchor-id="remember-there-is-still-a-lot-we-dont-know">5. Remember there is still a lot we don’t know</h4>
<p>This part was more about how to build a human-in-the-loop system and how human decision-makers can coexist with ADS, which is an active area of human-centered AI (HAI). An example would be how judges use the model prediction from risk assessment tools in decision-making.</p>
</section>
</section>
<section id="algorithmic-accountability-a-primer" class="level3">
<h3 class="anchored" data-anchor-id="algorithmic-accountability-a-primer"><a href="https://datasociety.net/library/algorithmic-accountability-a-primer/">Algorithmic Accountability: A Primer</a></h3>
<p>This primer was written by <a href="https://datasociety.net/">Data &amp; Society</a>, an independent nonprofit research organization about tech ethics and governance. This was an excellent overview of ADS and algorithmic accountability.</p>
<p>It gives a summary of <a href="https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say">ProPublica’s COMPAS investigation</a>. It says the two issues of this incident are 1) lack of standard definition of algorithmic bias (related to the debate between Northpointe and Propublica’s conflicting opinions about what is fair) and 2) lack of mechanism for algorithmic accountability (wasn’t mentioned here but probably related to <a href="https://en.wikipedia.org/wiki/Loomis_v._Wisconsin">Loomis v. Wisconsin</a>).</p>
<p>Then it lists several key issues related to ADS. Regarding fairness and bias, it pointed out that algorithms can be quickly outdated unless they are consistently monitored and adjusted. About opacity and transparency, it mentioned that transparency can be exploited by bad actors gaming the system. Importantly, it mentioned the <em>repurposing</em> of algorithms and data meaning algorithms built for a problem can be repurposed and applied to a completely different problem (PredPol using an algorithm built for earthquake modeling). Finally it mentioned the lack of standards for auditing.</p>
<p>Regarding algorithmic accountability, which the primer defines as <strong>“the assignment of responsibility for how an algorithm is created ans its impact on society”</strong>, the lack of this makes me think the moral disengagement paper we read last week. In terms of the enforcement and regulation, it did mention a possibility of self-regulation by corporations but as I expected (and agreed), it said this approach is often ad hoc and out of control of citizens and governments, which is unreliable.</p>
</section>
</section>
<section id="the-lecture-and-talk-with-rumman-chowdhury" class="level2">
<h2 class="anchored" data-anchor-id="the-lecture-and-talk-with-rumman-chowdhury">The lecture and talk with Rumman Chowdhury</h2>
<p>This week’s lecture was led by Professor Mehran Sahami, who talked about algorithmic decision-making, different definitions of fairness, and their relationship to the COMPAS incident. Among many definitions of fairness, we covered anti-classification, classification parity, calibration, and lack of disparate impact. The first three are mathematically well-defined and the last one focuses on empirical evidence. Regarding the COMPAS case, he mentioned that Northpointe’s argument was that their model is fair because from the perspective of the <em>calibration</em> definition of fairness, their model had similar predictive probability between white and black based on their risk factors. But as our guest speaker for the week, Rumman Chowdhury pointed out, Nortpointe’s survey questions included irrelevant and bias-reproducing questions such as whether a person grew up in a poor neighborhood or knew people who went to jail, etc.</p>
<p>During Rumman Chowdhury’s session, she mentioned several interesting points. First, she summarized the problem of ADS as “models are good at generalization but bad at specificity.” Second, regarding her experience in Twitter, she mentioned that working on a product team by implementing research ideas was very helpful to produce power and momentum. Regarding generative AI, she mentioned that the error space by AI is now much wider than before, which creates bigger concerns, and where often the key question is “who gets to be the arbitor of the truth?” Regarding algorithmic auditing, on one hand she promoted red-teaming (especially as a community-driven approach), but also at the same time she said it’s important to have community consensus on auditing.</p>
</section>
<section id="overall-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="overall-thoughts">Overall thoughts</h2>
<p>The reading assignments were excellent and interesting. However, the course felt quite rushed. We had to cover 4 definitions of fairness and COMPAS case study within 15 minutes. I was already quite familiar with everything but I wonder how many attendees were able to process all of it in that short amount of time.</p>
<p>During the breakout session, instead of talking about fairness, ADS, and algorithmic accountability, we were asked to think about when we were denied to talk about tech ethics at work or work-adjacent settings, and why we thought that was the case. Then we did an exercise where we listed various values we care about and see whether any values are diametrical.</p>
<p>To begin with, the breakout session (group discussion) was short, but I was quite unhappy that the discussion was not much related to the topics or the readings. Yes, when building an ADS system, one needs to think about how to handle the trade-offs between different values but especially since this course was advertised as “for practitioners,” I was looking for something more concrete. The post-it exercise was in a way useful but I also thought it prevented us from having an actual conversational discussion.</p>
<p>Overall, this week has been a review of the stuff that I was mostly familiar with (thank you FAccT conferences!). I hope there are more active and practical engagements in the coming weeks.</p>


</section>

 ]]></description>
  <category>ethics</category>
  <category>fairness</category>
  <category>criminal justice</category>
  <guid>https://hongsupshin.github.io/posts/2023-10-11-ethics-week2/</guid>
  <pubDate>Wed, 11 Oct 2023 05:00:00 GMT</pubDate>
  <media:content url="https://assets-c3.propublica.org/legacy/images/_threeTwo800w/20160523-machine-bias-630x420_1.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Moral complicity and moral disengagement (Stanford Tech Ethics course, Week 1)</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2023-10-04-ethics-week1/</link>
  <description><![CDATA[ 





<section id="the-course-ethics-technology-public-policy-for-practitioners" class="level2">
<h2 class="anchored" data-anchor-id="the-course-ethics-technology-public-policy-for-practitioners">The course: <a href="https://online.stanford.edu/courses/soe-xetech0001-ethics-technology-public-policy-practitioners">Ethics, Technology + Public Policy for Practitioners</a></h2>
<p>It’s been several years since I got interested in AI ethics. I have been to conferences and workshops about the topic but it wasn’t easy to find a course with a well-structured curriculum. It’s probably because AI ethics covers so many different disciplines: social/political science, ethics and philosophy, and computer science. And of course, the policy aspect requires real-world knowledge from public sector, which is hard to find in academia anyway.</p>
<p>A few months ago, I learned about <a href="https://online.stanford.edu/courses/soe-xetech0001-ethics-technology-public-policy-practitioners">Ethics, Technology + Public Policy for Practitioners</a> from <a href="https://www.linkedin.com/in/smithgk/XQ%3D%3D">Geneviève</a>, an Insight Data Science fellow whom I met at the Grace Hopper conference before the pandemic. I’ve been following <a href="https://hai.stanford.edu/">Stanford HAI</a> already and I was aware of their endeavor for human-centered AI and AI ethics, so in a way, this course made sense. At a glance, its outline seemed to be quite comprehensive because it covered various topics such as fairness, algorithmic bias, and generative AI. I also liked that it invited many guest speakers from academia, industry, and public sectors. Luckily, my application got accepted and I was able to join the course this fall.</p>
<p>Each week, we get reading assignments for the coming week’s discussion. For Week 1, we got to read the famous sci-fi and fantasy writer, Ursula K. Le Guin’s <a href="https://shsdavisapes.pbworks.com/f/Omelas.pdf">The Ones Who Walk Away from Omelas</a>. As an optional reading, <a href="https://drive.google.com/file/d/1VvicB1c1MMZpkq2CcYfkxSqqFuGGN_jO/view">Selective Moral Disengagement in the Exercise of Moral Agency</a> by <a href="https://en.wikipedia.org/wiki/Albert_Bandura">Albert Bandura</a> was assigned although we didn’t discuss the paper during the lecture.</p>
</section>
<section id="the-ones-who-walk-away-from-omelas" class="level2">
<h2 class="anchored" data-anchor-id="the-ones-who-walk-away-from-omelas">The Ones Who Walk Away from Omelas</h2>
<p>The story is about a place called Omelas, described as a utopian place. The author later reveals that there is a poor child locked up in a dungeon in Omelas, and this child’s poor condition is what makes Omelas a utopia. Interestingly, all people in Omelas are aware of this. But they just accept this fact and enjoy their life. At the end of the story, we find that sometimes some folks decide to walk away from Omelas to settle somewhere else.</p>
<p>In the course, the discussion was moderated by <a href="https://robreich.stanford.edu/">Rob Reich</a>, a philosopher and a political science professor at Stanford (he is also one of the main faculty of this course). He asked the cohort several questions about the story.</p>
<section id="heroes-or-cowards-what-would-you-do" class="level3">
<h3 class="anchored" data-anchor-id="heroes-or-cowards-what-would-you-do">Heroes or cowards? What would you do?</h3>
<p>We were first asked about those who left Omelas: are they heroes or cowards? The majority of the cohort said they were neither, which was also my answer. They were definitely not heroes because they didn’t do anything to improve the condition of the victim (the child) but simply walked away. But I also didn’t think that they were cowards because in a way, their decision of not wanting to be a part of Omelas, which included walking away from the comfortable life, should be weighed in.</p>
<p>As a follow up, we were now asked what <em>we</em> would do in this situation. This change of viewpoint already made me uncomfortable (later, we learned that this feeling can be called <em>moral caffeination</em>). I decided to poke a hole of the concept of utopia and thought a non-utopia would not mean a hellish place, meaning the cost of rescuing the child would be tolerable, which all have to think about. And if the people of Omelas share the cost together, it would be acceptable. Thus, I would first raise this question to other like-minded folks to investigate the situation and find a solution. (This definitely shows my researcher background!)</p>
<p>Some cohort members shared their thoughts. It was only a handful but I was surprised to know that some seemed to have a very strong conviction of righteousness by confidently saying that they would rescue the child for sure. Prof.&nbsp;Reich challenged their answers by asking them what gives them the moral superiority, how they think about this unilateral decision-making and the cost other people in Omelas would pay due to their actions. I don’t think I heard a satisfying answer but that’s probably because these are all very tough questions that we have to wrestle with.</p>
</section>
<section id="adulthood-and-complicity" class="level3">
<h3 class="anchored" data-anchor-id="adulthood-and-complicity">Adulthood and complicity</h3>
<p>Prof.&nbsp;Reich provided more explanations. He said, those who walk away may often have desire of keeping their hands very clean, which could be seen as a bit delusional because their walking away doesn’t make that the injustice just disappears. He said, the more important thing we need to think about is how we sit with <em>complicity</em> if we realize that we are complicit and in this together.</p>
<p>Regarding this, several cohort members mentioned the TV show, The Good Place. In one of the episodes, the show reveals that it’s been almost impossible to get into the good place these days because everybody is complicit (e.g., unknowingly buying a t-shirt made by a company who runs a sweatshop). Some of us also pointed out that it might not be possible to “leave” Omelas in our world.</p>
<p>We only briefly mentioned this but one thing I found interesting in the story was the young people who were upset about the child’s condition in the beginning, but later got used to the fact and accepted the situation. In a way, as they grow up, they become to accept the injustice as a background noise and move on with their lives. To be honest, I think we all have a similar experience like this. But I was particularly curious about how one becomes conditioned, dull, and feeling comfortable living with moral complicity.</p>
</section>
</section>
<section id="selective-moral-disengagement-in-the-exercise-of-moral-agency" class="level2">
<h2 class="anchored" data-anchor-id="selective-moral-disengagement-in-the-exercise-of-moral-agency">Selective Moral Disengagement in the Exercise of Moral Agency</h2>
<p>This ethics paper, written by Albert Bandura, provided some answers to this question. Overall, this paper provides a good summary of how and when moral disengagement happens in various social situations. We all have our moral standards that promote certain actions and prevent us from behaving immorally. When moral disengagement occurs, this regulatory checks can be skipped, which often leads to social harm. In a way, moral disengagement sets people free from feeling guilty and tortured about their immoral behavior.</p>
<p>The author goes through various mechanisms of moral disengagement and provides examples from human history. For instance, <em>moral justification</em> can be deployed by politicized religion such as holy terror. <em>Sanitizing language</em> is often seen by corporations and governments who want to minimize their moral and ethical responsibilities in sticky situations to make themselves look innocent. <em>Advantageous comparison</em> could be applied to the Omelas situation because we can always apply the utilitarianism argument to justify the child’s suffering.</p>
<section id="moral-disengagement-in-tech" class="level3">
<h3 class="anchored" data-anchor-id="moral-disengagement-in-tech">Moral disengagement in tech</h3>
<p>I found <em>displacement</em> and <em>diffusion</em> of <em>responsibility</em> more prominent in ethical problems in tech. The <em>displacement</em> means that the farther we are from witnessing harms directly, the easier moral disengagement can happen. This often happens in machine learning and data science where a human being can be reduced to a single data point in a dataset with a million rows. Popularity of a black-box algorithm like deep learning also accelerates this because we can’t even explain what is done to each individual data points. The <em>diffusion</em> of responsibility is an inevitable outcome of a complex modern society because division of labor means diffusion of moral responsibility. This is also a crucial point when we talk about algorithmic accountability because ML products are often complicated and multiple parties are involved, which makes it challenging to ask accountability.</p>
</section>
<section id="dual-nature-and-hope" class="level3">
<h3 class="anchored" data-anchor-id="dual-nature-and-hope">Dual nature and hope</h3>
<p>I found a hopeful and insightful message from the <em>Dual Nature of Moral Agency</em> section. Here, the author told a story of a soldier who directly witnessed civilian killing in a war. This experience later spiked courage in him and he ended up rescuing other remaining civilians. The author said the following about this story:</p>
<blockquote class="blockquote">
<p>Social psychology emphasises the power of the situation over the individual. In the case of proactive moral courage, the individual triumphs as a moral agent over compelling situational forces.</p>
</blockquote>
<p>The dual nature here means as a moral agent, we can inhibit immoral behaviors but also be proactive and courageous to behave humanely. I think probably most of the cohort members who signed up for this course were interested in the latter. And as the author said, if individual triumphs matter in moral courage, as I have often thought, educating individual engineers, who are often just treated as a cog in the wheel, would be a significant step towards building ethical tech, especially when building a machine learning product where a single line of code change can create a butterfly effect.</p>
</section>
</section>
<section id="final-thoughts-on-week-1" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts-on-week-1">Final thoughts on Week 1</h2>
<p>All in all, I very much enjoyed the reading material and the discussion during the course. Prof.&nbsp;Reich’s guiding words were also crucial to understand the bigger picture and idea of moral complicity. When we were talking about how we identify this uncomfortable feeling about the Omelas story, I confessed that it often felt like walking on the fine line between hope and despair. Moral complicity can have a profound emotional impact on one’s psyche and potentially put us in depression because the overwhelming complexity and the amount of complicity and injustice in the world makes us feel helpless and hopeless.</p>
<p>But I think that’s why we want to call this exercise as moral caffeination. Once we recognize this situation, we don’t want to just stay feeling uncomfortable, disoriented, and depressed. We want to alert ourselves and think about “now what?” as Prof.&nbsp;Reich said. Personally, I think learning about the complicity and thinking about it in depth with others is a first step towards solving ethics problems in tech.</p>


</section>

 ]]></description>
  <category>ethics</category>
  <guid>https://hongsupshin.github.io/posts/2023-10-04-ethics-week1/</guid>
  <pubDate>Wed, 04 Oct 2023 05:00:00 GMT</pubDate>
  <media:content url="https://upload.wikimedia.org/wikipedia/en/c/c3/TheOnesWhoWalkAwayFromOmelas.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Constitutional AI: harmlessness from AI feedback</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2023-08-31/</link>
  <description><![CDATA[ 





<p>I’ve been interested in AI safety and responsible AI for several years, and the rise of LLMs has certainly increased stakes. Currently there is an intense arms race among several major tech companies and Anthropic is one of them. They recently published a paper about their LLM and claims to adopt a more cautious approach than others by designing their LLMs to minimize potential harm. They call this <em>constitutional AI (CAI)</em> because their LLMs follow a constitution of principles. I wanted to learn more about how they teach their algorithm to follow these principles. I presented the paper in Austin ML Journal Club in Aug 2023.</p>
<section id="background-knowledge" class="level2">
<h2 class="anchored" data-anchor-id="background-knowledge">Background knowledge</h2>
<p>To understand this paper properly, it’s better to be familiar with AI alignment problem and reinforcement learning from human feedback (RLHF). AI alignment is about aligning AI systems’ design and values with humanity values such as honesty. Norbert Wiener, an AI researcher back in 1960s, described the AI alignment problem as following:</p>
<blockquote class="blockquote">
<p>“If we use, to achieve our purposes, a mechanical agency with whose operation we cannot interfere effectively (…) we had better be quite sure that the purpose put into the machine is the purpose which we really desire.”</p>
</blockquote>
<p>Regarding RLHF, I recommend <a href="https://huggingface.co/blog/rlhf">this great summary</a> from Hugging Face. At its core, RLHF is an attempt to distill human feedback into a model (often called <em>reward</em> or <em>preference</em> model) when training LLMs. This is because human feedback is often expensive to collect and difficult to generalize. An important thing to know is that to train this model, practitioners often use ranked preference modeling where human annotators are asked to rank generated text ouptuts from language models. The assumption here is that this approach may mimic human preference of certain responses over others. And because of this preference approach, RLHF papers use <a href="https://en.wikipedia.org/wiki/Elo_rating_system">Elo scores</a>, a rating system originated from chess to show a player’s winning rates, to evaluate model performance.</p>
<p>In terms of the alignment values, Anthropic chose honesty, helpfulness, and harmlessness. The detailed definition of these concepts are described in one of their previous works:</p>
<div class="callout callout-style-default callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span><a href="https://arxiv.org/abs/2112.00861">Askell et al.&nbsp;2021</a>, What are Helpfulness, Honesty, and Harmlessness?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Helpful</strong></p>
<ul>
<li>The AI should make a clear attempt to perform the task or answer the question posed (as long as it isn’t harmful). It should do this as concisely and efficiently as possible.</li>
<li>When more information is required, the AI should ask relevant follow-up questions and obtain necessary details. It should respond with appropriate levels of sensitivity, insight, and discretion.</li>
<li>Ideally the AI will also re-direct ill-informed requests, e.g.&nbsp;if asked ‘how can I build a website in assembly language’ it might suggest a different approach.</li>
</ul>
<p><strong>Honest</strong></p>
<ul>
<li>At its most basic level, the AI should give accurate information. Moreover, it should be calibrated (e.g.&nbsp;it should be correct 80% of the time when it claims 80% confidence) and express appropriate levels of uncertainty. It should express its uncertainty without misleading human users.</li>
<li>Crucially, the AI should be honest about its own capabilities and levels of knowledge – it is not sufficient for it to simply imitate the responses expected from a seemingly humble and honest expert.</li>
<li>Ideally the AI would also be honest about itself and its own internal state, insofar as that information is available to it.</li>
<li>Honesty is more objective than helpfulness and harmlessness, so more aspects of honesty training may be possible without human input. This might include calibration training on factual claims and claims about the internal state of the model, and the use of search to augment accuracy.</li>
</ul>
<p><strong>Harmless</strong></p>
<ul>
<li>The AI should not be offensive or discriminatory, either directly or through subtext or bias.</li>
<li>When asked to aid in a dangerous act (e.g.&nbsp;building a bomb), the AI should politely refuse. Ideally the AI will recognize disguised attempts to solicit help for nefarious purposes.</li>
<li>To the best of its abilities, the AI should recognize when it may be providing very sensitive or consequential advice and act with appropriate modesty and care.</li>
<li>What behaviors are considered harmful and to what degree will vary across people and cultures. It will also be context-dependent, i.e.&nbsp;it will depend on the nature of the user query, who is using the AI assistant, and the time and place in which the assistant is being used.</li>
</ul>
</div>
</div>
</section>
<section id="motivations" class="level2">
<h2 class="anchored" data-anchor-id="motivations">Motivations</h2>
<p>The first motivation was scaling supervision. Given that LLMs require numerous examples, it’s better to automate the supervision process and use human annotators to get more curated and high quality answers. This is a similar idea behind the preference modeling in RLHF. The authors called theirs “reinforcement learning from AI Feedback” (RL<strong>AI</strong>F, not RL<strong>H</strong>F). A more interesting motivation was building a <em>non-evasive</em> and yet helpful AI assistant. Many currently available AI assistants often simply refuse to answer questions to harmful prompts (e.g., simply saying “I don’t know” or “I can’t answer that”). Their model was never evasive but tried to explain the reasoning behind their negative response to harmful questions. Finally, similar to the first point, they claimed that distilling human supervision into a model could help better understand general aspects of human feedback from many crowd-workers.</p>
</section>
<section id="the-constitutional-ai-approach" class="level2">
<h2 class="anchored" data-anchor-id="the-constitutional-ai-approach">The Constitutional AI Approach</h2>
<section id="supervised-stage" class="level3">
<h3 class="anchored" data-anchor-id="supervised-stage">Supervised stage</h3>
<p>Their constitutional AI (CAI) consisted of two stages: a supervised stage and a reinforcement learning stage. In the supervised stage, they used a pretrained LM (“Helpful RLHF model” from their previous work) as a starting point, and <a href="https://en.wikipedia.org/wiki/Red_team">red-teamed</a> the model by presenting harmful prompts (by human workers) and sampled the responses. Then, (this is the most interesting part in my opinion!) they used <em>natural language</em> to ask the model to critique and revise its own response based on certain principles. Here’s an example from the paper:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-08-31/appendixA.png" class="img-fluid figure-img"></p>
<figcaption>Appendix A. Sample critiques and revisions. The first two revisions are shown in this screenshot.</figcaption>
</figure>
</div>
<p>Appendix C contains a list of principles (constitution) they used to create the critique-revision requests. The paper doesn’t talk much about how they came up with the principles but according to <a href="https://www.anthropic.com/index/claudes-constitution">Anthropic’s website</a>, the principles were based on existing documents such as <a href="https://www.un.org/en/about-us/universal-declaration-of-human-rights">Universal Declaration of Human Rights</a> or Apple’s Terms of Service. As shown in the example above, a response can go through multiple critique-revision requests. The authors found that generally the more revisions mean less harmfulness although the first revision contributes most.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-08-31/fig5.png" class="img-fluid figure-img"></p>
<figcaption>Fig. 5. Preference Model scores of responses and revisions from helpful RLHF models, evaluated on a set of red team prompts.</figcaption>
</figure>
</div>
</section>
<section id="reinforcement-learning-rl-stage" class="level3">
<h3 class="anchored" data-anchor-id="reinforcement-learning-rl-stage">Reinforcement learning (RL) stage</h3>
<p>The main idea behind this stage is identical to the RL stage in RLHF. The goal is to distill knowledge from a group of responses by training a reward model. The key difference is that <strong>these responses are now generated by a model not human</strong> (the supervised learning model from the previous stage). The authors called this reward model “feedback model” although it was a bit unclear which exact LMs they were referring to.</p>
<p>Another interesting aspect they added here was a “chain-of-thought” approach. This was inspired by <a href="https://arxiv.org/abs/2305.20050">Let’s Verify Step by Step</a>, a paper we covered in <a href="https://austinmljournalclub.github.io/posts/20230622/">a previous journal club meeting</a>. Here, after getting a response, the authors added the natural-language phrase <strong>“Let’s think step by step”</strong> to generate richer intermediate responses from the model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-08-31/appendixE.png" class="img-fluid figure-img"></p>
<figcaption>An example from Appendix E.2. Chain-of-Thought Prompts for RL-CAI.</figcaption>
</figure>
</div>
<p>In their final model (Reinforcement Learning-Constitutional AI with Chain of Thought, or <strong>RL-CAI w/ CoT</strong>), the authors found a major improvement in harmlessness Elo score without compromising the helpfulness Elo score much. Note that in the figure below, Elo score of 0 on the y axis (starting point of the RL model) represents the supervised learning model (SL-CAI), which means the SL-CAI model was used as initial base model for RL.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-08-31/fig8.png" class="img-fluid figure-img"></p>
<figcaption>Fig. 8. Helpfulness (left) and harmlessness (right) Elo scores as a function of the total number of RL training sequences, as judged by crowd-workers via comparison tests.</figcaption>
</figure>
</div>
<p>One interesting aspect of the RL model the authors shared was its behavior when the model was over-fitted. They found that in this case, the response often included <em>boilerplate</em> language such as “you are valid, valued, and cared for.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-08-31/4.3.png" class="img-fluid figure-img"></p>
<figcaption>An example of over-trained RL-CAI model response showing boilerplate language as part of their response (e.g.&nbsp;“you are valid, valued, and cared for”).</figcaption>
</figure>
</div>
</section>
</section>
<section id="broader-impacts" class="level2">
<h2 class="anchored" data-anchor-id="broader-impacts">“Broader Impacts”</h2>
<p>At the end of the paper, the authors emphasized that natural language feedback could change AI behavior and potentially increase robustness because red-teaming efforts could become more scalable (because feedback supervision can be generated by a model not humans). In section 6.2 Broader Impacts, they <em>briefly</em> mentioned the potential harm of the constitutional AI approach. Using natural language to change AI behavior means it will become much easier to train a malicious AI assistant especially given that this method reduces the need for human feedback.</p>
</section>
<section id="journal-club-discussion" class="level2">
<h2 class="anchored" data-anchor-id="journal-club-discussion">Journal club discussion</h2>
<p>First of all, compared to other on-average deep learning papers, we found this paper easier to read. We also appreciated that the authors provided numerous examples. We could see they also tried to do a better job at providing many details of the model although still not enough, especially when they were referring to their previous work.</p>
<section id="harmlessness-as-an-easy-alignment" class="level3">
<h3 class="anchored" data-anchor-id="harmlessness-as-an-easy-alignment">Harmlessness as an <em>easy</em> alignment</h3>
<p>Some of us suspected that the authors might have chosen harmlessness as their main target of alignment perhaps because it was relatively easier to tackle than other alignment such as helpfulness. The authors did mention the tension between harmfulness and helpfulness in the paper in that an AI assistant could become harmful if it was too eager to be helpful (e.g., providing a detailed answer to a prompt about how to commit a crime). We talked about more nuanced alignments (such as humor) and whether it would be possible to use natural language to change model behavior. Some of us pointed out that harmlessness could be relatively easy because diametrically opposed examples could be easily found in languages.</p>
</section>
<section id="does-chain-of-thought-count-as-an-explanation" class="level3">
<h3 class="anchored" data-anchor-id="does-chain-of-thought-count-as-an-explanation">Does chain-of-thought count as an explanation?</h3>
<p>Many of us were skeptical of treating responses from the chain-of-thought approach as explanations. Most examples shown in the paper seemed reasonable but given that what the model did with a CoT request was nothing more than just generating more detailed responses, we agreed that we should not treat them as step-by-step deductive reasoning. We were interested in looking at CoT examples that might sound gibberish and redundant. I personally also thought this was one of the examples of ML practitioners anthropomorphizing a behavior of an ML model.</p>
</section>
<section id="no-more-efforts-to-understand-the-model" class="level3">
<h3 class="anchored" data-anchor-id="no-more-efforts-to-understand-the-model">No more efforts to understand the model</h3>
<p>Most of us were surprised that the approach of using natural language to critique and revise its own behavior seemed to have worked. Before I read the paper, I was very curious to know what constraints they came up with and how they tried to model complex social concepts such as justice and harm. The fact that their approach seemed to be working was interesting but this also meant that we are in an era where we are no longer trying to change the model behavior at a lower level, but rather we treat the language models as if they are something we don’t completely understand. This paper was completely missing explanations of why this approach actually worked. From my perspective, as other numerous deep learning papers, this paper was saying “we tried this, we don’t exactly know why it works, but it seems to work.”</p>
</section>
<section id="why-diminish-the-work-and-labor-of-human-annotators" class="level3">
<h3 class="anchored" data-anchor-id="why-diminish-the-work-and-labor-of-human-annotators">Why diminish the work and labor of human annotators?</h3>
<p>In the abstract and at the end of the paper, the authors kept saying their model was trained “without any human labels identifying harmful outputs.” All of us agreed that this was an exaggeration. To train the supervised model, they needed human annotators, and once the supervised model was ready, then they were able to generate <em>AI</em> feedback. Given that Anthropic is a for-profit company that sells AI assistant software, highlighting that the maintenance cost of their system is <em>cheaper</em> than others because human feedback can be replaced by AI feedback, could be a good marketing strategy, but at the cost of marginalizing human labor.</p>
</section>
<section id="how-did-you-come-up-with-the-principles" class="level3">
<h3 class="anchored" data-anchor-id="how-did-you-come-up-with-the-principles">How did you come up with the principles?</h3>
<p>In Appendix C, the authors provided a comprehensive list of all principles they used to generate critique-revision responses. These were the core principles that guided the model behavior but the authors didn’t mention much about how they curated the list. Some principles were general and others were more specific to particular types of harms such as racism and misogyny. We suspected that there had been an iterative curation process to narrow the list down to these 16 principles specifically. If these were the main drivers of changes in model behavior, we think they should have provided much more details.</p>
</section>
<section id="the-double-edged-sword" class="level3">
<h3 class="anchored" data-anchor-id="the-double-edged-sword">The double-edged sword</h3>
<p>Finally, some of us were disappointed that the authors didn’t elaborate much on the potential harm of their approach. They spent a lot of time talking about harmlessness of their algorithms and yet they really fell short when talking about social impacts of their model, especially regarding lowering the barrier for experimenting with LMs and automating supervision by removing human further out of the loop. Particularly for the former, we agreed that it wouldn’t be surprising to see, in near future bad actors take advantage of this approach and come up with a highly toxic, malicious, and harmful AI assistant.</p>


</section>
</section>

 ]]></description>
  <category>paper</category>
  <category>GenAI</category>
  <category>LLM</category>
  <category>ML</category>
  <guid>https://hongsupshin.github.io/posts/2023-08-31/</guid>
  <pubDate>Thu, 31 Aug 2023 05:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2023-08-31/principle.png" medium="image" type="image/png" height="156" width="144"/>
</item>
<item>
  <title>Visualization in Bayesian workflow</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2023-03-29/</link>
  <description><![CDATA[ 





<p>This paper summarizes types of data visualization that we can use in Bayesian modeling and inference. This is also a good overview of how to do Bayesian modeling properly, including validating results. The fact that the main author is one of the maintainers of the <a href="https://mc-stan.org/">stan</a> package, is another motivating factor. I presented the paper in Austin ML Journal Club in Mar 2023.</p>
<section id="paper-summary" class="level2">
<h2 class="anchored" data-anchor-id="paper-summary">Paper summary</h2>
<p>Given a problem, we incorporate our scientific knowledge into a causal (generative) model to simulate how the relevant variables are produced (input and output). Researchers need more than null hypothesis because it doesn’t talk about how your observation is generated. We can use a DAG as a scientific causal model and data generation process can be expressed in a generative model, which is often accompanied with Bayesian data analysis (BDA). BDA is particularly useful because we can simulate data from the model directly to design and debug during inference. To effectively estimate a posterior distribution, we need computational methods such as MCMC and others. One may say Bayesian might be an overkill but it’s extremeley useful for typical modeling problems such as measurement error, missing data, latent variables, and regularization. Again, it’s also generative!</p>
<p>The paper uses data visualization to express the followings: - Exploratory data analysis to come up with a proper model - Prior predictive distribution check to check model’s assumption - MCMC computational check to evaluate the sampling process - Posterior predictive check to validate inference process</p>
<p>This paper is based on R’s <code>bayesplot</code> but there are several python equivalents to this such as <code>pymc</code>, <code>arviz</code>, and <code>numpyro</code>. It uses a global air polllution dataset (pm2.5 particles) measured from satellite images. The goal of modeling is to predict the level of pm2.5 from the images. Hence, this is a regression problem. Fig. 1 shows the linear trend between the two variables of interest but also shows how sparse the data is depending on groups.</p>
<section id="exploratory-data-analysis-eda" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis-eda">Exploratory data analysis (EDA)</h3>
<p>EDA is essential to understand and capture features and heterogeneity of data. The data pattern helps building a group-up modeling strategy to address the imbalance and sparsity of data. The authors emphasize that the top-down approach in typical ML communities these days is to throw everything into a non-parametric procedure, which can severely overfit. Fig. 2 shows that simple regression works pretty well, especially when the group identity is taken into account, which means we need a hierarchical approach.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-03-29/fig4.png" class="img-fluid figure-img"></p>
<figcaption>Fig. 4: Visualizing the prior predictive distribution</figcaption>
</figure>
</div>
</section>
<section id="prior-predictive-check" class="level3">
<h3 class="anchored" data-anchor-id="prior-predictive-check">Prior predictive check</h3>
<p>Instead of using a non-informative or uniform prior, weakly informative prior is always recommended, which takes into account modeler’s perspective. In the paper, we assume that the target varialbe follows a normal distribution defined by a mean and a <img src="https://latex.codecogs.com/png.latex?%5Csigma"> where the mean is a linear function of input variable (satellite data) and linear coefficients, which also have priors (0 mean and std (<img src="https://latex.codecogs.com/png.latex?%5Ctau">)).</p>
<p>Prior predictive checks are useful to visualize the impact of our assumption for prior definition. If we use a vague prior (very wide range, Fig. 4a), ranges from the sample don’t match the observation. Fig. 4b shows a much tighter prior where the simulated data points still overestimate but are in a much reasonable range. Obviously, tighter and sensible priors are better.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-03-29/fig5.png" class="img-fluid figure-img"></p>
<figcaption>Fig. 5: Diagnostic plots for Hamiltonian Monte Carlo</figcaption>
</figure>
</div>
</section>
<section id="mcmc-diagnostics" class="level3">
<h3 class="anchored" data-anchor-id="mcmc-diagnostics">MCMC diagnostics</h3>
<p>Success of Hamiltonion Monte Carlo (HMC) depends on how smooth the posterior distribution is; if not smooth, HMC proposal diverges from the true trajectory, which may signal that the trajectories are stuck. Healthy MCMC samples, shown as a bivariate plot in Fig. 5a, shouldn’t have obvious patterns. The funnel shape there is due to <img src="https://latex.codecogs.com/png.latex?%5Cbeta_%7B11%7D%20%5Csim%20N(0,%20%5C,%20%5Ctau_%7B1%7D%5E%7B2%7D)"> where small <img src="https://latex.codecogs.com/png.latex?%5Ctau_%7B1%7D"> means <img src="https://latex.codecogs.com/png.latex?%5Cbeta_%7B11%7D"> distribution is narrow. The parallel co-ordinate plot (Fig. 5b) also shouldn’t have any particular structure.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-03-29/fig9.png" class="img-fluid figure-img"></p>
<figcaption>Fig. 9: Graphical check of leave-one-out cross-validated probability integral transform (LOO-PIT)</figcaption>
</figure>
</div>
</section>
<section id="posterior-predictive-check" class="level3">
<h3 class="anchored" data-anchor-id="posterior-predictive-check">Posterior predictive check</h3>
<p>If a trained model has a good fit, generated data from the model should follow observations. Posterior predictive checking is mostly qualitative but it’s effective to compare empirical and simulated values (Fig. 6). Fig. 7 shows checking whether samples from models captures other statistics such as skewness (kurtosis) and Fig. 8 shows how we can evaluate whether samples from models capture summary statistics such as median Fig. 9 shows using visualization that checks whether leave-one-out cross-validation (LOO-CV) predictive cumulative density function is uniform or not, similar to the idea of a K-S test.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-03-29/fig10a.png" class="img-fluid figure-img"></p>
<figcaption>Fig. 10a: Model comparisons using leave-one-out (LOO) cross-validation. The difference in pointwise ELPD values obtained from PSIS-LOO</figcaption>
</figure>
</div>
</section>
<section id="model-comparison" class="level3">
<h3 class="anchored" data-anchor-id="model-comparison">Model comparison</h3>
<p>When comparing models, Bayesian data analysis allows detailed examination of individual data points on a given model. We can use cross-validated LOO predictive distribution to do so; it shows the distribution of a data point from a model that’s built without that data point (i.e., LOO). We can use expected log-predictive densities (ELPD), which is essentially the mean of the log probability of each data point <em>i</em>, computed with posterior that omits the point <em>i</em> (the bigger the better). We use Pareto-smoothed importance sampling (PSIS) to compute this metric (we don’t have to fit the models N times). Once we have ELPD value for every data point of a model, we can repeat this for all the models we have and make comparison (Fig. 10a).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2023-03-29/fig10b.png" class="img-fluid figure-img"></p>
<figcaption>Fig. 10b: Model comparisons using leave-one-out (LOO) cross-validation. The <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bk%7D"> diagnostics from PSIS-LOO for Model 2</figcaption>
</figure>
</div>
<p>Similarly, we can compute <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bk%7D"> as well which represents degree of influence of a specific observation. High value means this data point is “unexpected”, meaning that it is likely to be an outlier or the model struggles to make valid prediction for this data point.</p>
</section>
</section>
<section id="journal-club-discussion" class="level2">
<h2 class="anchored" data-anchor-id="journal-club-discussion">Journal club discussion</h2>
<p>We had a lengthy discussion about the choice of prior and how tricky it can be. As the authors mentioned in conclusion, we were also slightly worried about double-dipping the data when running prior predictive checks and potential data leakage. It was also interesting to share our own experience on Bayesian inference ranging from dealing with prior assumptions, model comparison, to decision-making with uncertainty. But we all agreed that Bayesian data analysis is more empowering for us modellers compared to the typical top-down approach in ML where we often don’t have any generative models about data. We also agreed that Bayesian data anlsysis is absolutely more powerful when we suffer from a small data problem.</p>
<p>But we also some downsides of Bayesian data analysis too. It’s difficult to scalable and someone we ML practitioners are not the domain experts and without the domain expertise, it’s difficult to come up with a good DAG. Due to the nature of Bayesian analysis where we don’t often make a point-estimate summary, we appreciated that the paper spent a good amount of time discussing how to summarize a posterior distribution. We also discussed the importance of loss function when decision making with uncertainty.</p>
<p>In general, we liked the paper but we thought it fell slightly short because it wasn’t focusing on understanding scientific mechanism but rather on predictive modeling nature of Bayesian analysis. When it comes to model comparison particularly, we thought it’s important to evaluate the structure of the model too in addition to evaluating the goodness of fit. For instance, if the model performance varies across the regions, the way we compare the models would like to change as well, and potentially the DAGs too.</p>


</section>

 ]]></description>
  <category>paper</category>
  <category>Bayesian</category>
  <category>visualization</category>
  <category>ML</category>
  <guid>https://hongsupshin.github.io/posts/2023-03-29/</guid>
  <pubDate>Wed, 29 Mar 2023 05:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2023-03-29/fig10a.png" medium="image" type="image/png" height="120" width="144"/>
</item>
<item>
  <title>Interoperability testing for hyperparameter tuning: MLflow, LightGBM, sklearn, and dask-ml</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/2023-03-17-mlflow-lightgbm-dask.html</link>
  <description><![CDATA[ 





<p>There are numerous open source ML packages in python ecosystem. Developers do their best to maximize interoperability in relation to other main ML packages but it’s not possible to check every possible combination. That’s why I think some of the responsibility of interoperability lies on users. MLflow’s autologging method is quite handy because with a single line of code (<code>mlflow.autologging</code>), we obtain useful metrics of model behavior such as confusion matrix, feature importance, or training loss over epochs. However, this is not always guaranteed when we apply model tuning on top by using scikit-learn and dask.</p>
<p>In this notebook, I first demonstrated what MLflow autologging method did particularly for LightGBM models. Then, I tried the same autologging in model tuning frameworks of scikit-learn and Dask-ML backend, and how the autologging method behaves. Check <code>environment.yml</code> to run the notebook.</p>
<div id="b9100bba-fd42-4807-bb14-6e85953611a5" class="cell" data-tags="[]" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> lightgbm <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> lgb</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> mlflow</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> mlflow.client <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MlflowClient</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> datasets</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> train_test_split, RandomizedSearchCV, PredefinedSplit</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.pipeline <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Pipeline</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> sklearn.metrics <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> log_loss, roc_auc_score</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> dask_ml.model_selection <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RandomizedSearchCV <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> dask_RandomizedSearchCV</span>
<span id="cb1-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> distributed <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Client</span>
<span id="cb1-14"></span>
<span id="cb1-15">seed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">97531</span></span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>load_ext autoreload</span>
<span id="cb1-18"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>autoreload <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>load_ext watermark</span>
<span id="cb1-21"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>watermark <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>u <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>v <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>iv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>a <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hongsup Shin"</span></span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>Author: Hongsup Shin

Last updated: 2023-03-19 23:00:45

Python implementation: CPython
Python version       : 3.9.16
IPython version      : 8.10.0

Git hash: 0eaf0c3c88c3e909b76c36af9b13fea1f04d7c08

Git repo: https://github.com/hongsupshin/hongsupshin.github.io.git

Git branch: 1-mlflow

lightgbm: 3.3.2
sklearn : 1.2.0
numpy   : 1.24.0
mlflow  : 2.1.1
</code></pre>
</div>
</div>
<center>
<img src="https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/images/index.png" width="600">
</center>
<section id="set-up" class="level2">
<h2 class="anchored" data-anchor-id="set-up">Set up</h2>
<section id="mlflow" class="level3">
<h3 class="anchored" data-anchor-id="mlflow">MLflow</h3>
<p>MLflow comes with a tracking UI, which you can launch by running <code>mlflow ui</code>. By default, you can see the UI http://localhost:5000. Here, I assumed that you ran <code>mlflow ui</code> before the following cell where experiment location was defined.</p>
<div id="3741ce1c-7adb-4fdd-83f4-a7a024abd900" class="cell" data-tags="[]" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">mlflow.set_tracking_uri(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"http://127.0.0.1:5000"</span>)</span>
<span id="cb3-2">mlflow.set_experiment(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mlflow_tune_demo"</span>)</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>&lt;Experiment: artifact_location='mlflow-artifacts:/618881380489654419', creation_time=1679103932467, experiment_id='618881380489654419', last_update_time=1679103932467, lifecycle_stage='active', name='mlflow_tune_demo', tags={}&gt;</code></pre>
</div>
</div>
<p><code>mlflow.autolog()</code> should be called before running training but this enables all supported libraries that are imported. Thus, specific autologging is recommened:</p>
<div id="54c14ad0-99a1-45f6-b313-50b1c76af24b" class="cell" data-tags="[]" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">mlflow.lightgbm.autolog()</span></code></pre></div></div>
</div>
</section>
<section id="data-and-model" class="level3">
<h3 class="anchored" data-anchor-id="data-and-model">Data and model</h3>
<p>For this walkthrough, I used the breast cancer dataset from scikit-learn (<code>sklearn.datasets.load_breast_cancer()</code>), which is a binary classificaiton problem. For training, I split the dataset into train (50%), validation (25%) and test sets (25%). The validation set was used for model tuning.</p>
<div id="c3fda29c-d030-4411-a2e6-a10732b2f839" class="cell" data-tags="[]" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">breast_cancer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> datasets.load_breast_cancer()</span>
<span id="cb6-2">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> breast_cancer.data</span>
<span id="cb6-3">y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> breast_cancer.target</span>
<span id="cb6-4"></span>
<span id="cb6-5">X_train_val, X_test, y_train_val, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.25</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>seed)</span>
<span id="cb6-6">X_train, X_val, y_train, y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X_train_val, y_train_val, test_size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.33</span>, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>seed)</span>
<span id="cb6-7"></span>
<span id="cb6-8">train_set <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgb.Dataset(X_train, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_train)</span>
<span id="cb6-9">valid_set <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgb.Dataset(X_val, label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>y_val)</span></code></pre></div></div>
</div>
<p>Instead of <code>lightgbm.LGBMClassifier</code>, the scikit-learn API, we use the native LightGBM (<code>lightgbm.train</code>).</p>
</section>
</section>
<section id="lightgbm-autologging-for-a-single-training-run-no-tuning" class="level2">
<h2 class="anchored" data-anchor-id="lightgbm-autologging-for-a-single-training-run-no-tuning">LightGBM autologging for a single training run (no tuning)</h2>
<p>To test the limits of autologging and make things more interesting, I set up the following: - Apply an early-stopping callback - Track two types of metrics: log-loss (<code>"binary_logloss"</code>) and AUROC (<code>"auc"</code>) - Track two types of datasets: training and validation - Log test metrics in addition to the autologged metrics using <code>mlflow.log_metrics</code></p>
<p>and passed artbitrary hyperparameter values.</p>
<div id="01b3ca48-0642-4007-a3c1-23b3872347e3" class="cell" data-tags="[]" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb7-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"objective"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"binary"</span>,</span>
<span id="cb7-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"metric"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"binary_logloss"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"auc"</span>],</span>
<span id="cb7-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"learning_rate"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>,</span>
<span id="cb7-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"subsample"</span>: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>,</span>
<span id="cb7-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"seed"</span>: seed,</span>
<span id="cb7-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_iterations"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,</span>
<span id="cb7-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"early_stopping_round"</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>,</span>
<span id="cb7-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"first_metric_only"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb7-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"force_col_wise"</span>:<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb7-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"verbosity"</span>: <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,    </span>
<span id="cb7-12">}</span></code></pre></div></div>
</div>
<div id="29875de3-ddac-4c67-9673-cb62634d446e" class="cell" data-tags="[]" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> mlflow.start_run(run_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lgb_single"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb8-2">    </span>
<span id="cb8-3">    model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgb.train(</span>
<span id="cb8-4">        params<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>params,</span>
<span id="cb8-5">        train_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>train_set,</span>
<span id="cb8-6">        callbacks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[lgb.early_stopping(stopping_rounds<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>), lgb.log_evaluation()],</span>
<span id="cb8-7">        valid_sets<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[train_set, valid_set],</span>
<span id="cb8-8">        valid_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"train"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val"</span>],</span>
<span id="cb8-9">    )</span>
<span id="cb8-10">    </span>
<span id="cb8-11">    y_pred_proba <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.predict(X_test)</span>
<span id="cb8-12">    loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_loss(y_test, y_pred_proba)</span>
<span id="cb8-13">    roc_auc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> roc_auc_score(y_test, y_pred_proba)</span>
<span id="cb8-14">    </span>
<span id="cb8-15">    mlflow.log_metrics(</span>
<span id="cb8-16">        {</span>
<span id="cb8-17">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test-logloss"</span>:loss,</span>
<span id="cb8-18">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test-auc"</span>: roc_auc,</span>
<span id="cb8-19">        }</span>
<span id="cb8-20">    )</span></code></pre></div></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/mlflow_tune/lib/python3.9/site-packages/lightgbm/engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument
  _log_warning(f"Found `{alias}` in params. Will use it instead of argument")</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] train's binary_logloss: 0.587637    train's auc: 0.986343   val's binary_logloss: 0.577365  val's auc: 0.942092
Training until validation scores don't improve for 5 rounds
[2] train's binary_logloss: 0.525352    train's auc: 0.989106   val's binary_logloss: 0.52163   val's auc: 0.963598
[3] train's binary_logloss: 0.473652    train's auc: 0.990591   val's binary_logloss: 0.47546   val's auc: 0.978383
[4] train's binary_logloss: 0.427402    train's auc: 0.992129   val's binary_logloss: 0.428912  val's auc: 0.983647
[5] train's binary_logloss: 0.388029    train's auc: 0.994553   val's binary_logloss: 0.392357  val's auc: 0.985551
[6] train's binary_logloss: 0.355106    train's auc: 0.995543   val's binary_logloss: 0.361549  val's auc: 0.986335
[7] train's binary_logloss: 0.323011    train's auc: 0.996247   val's binary_logloss: 0.330934  val's auc: 0.990031
[8] train's binary_logloss: 0.297144    train's auc: 0.996247   val's binary_logloss: 0.309573  val's auc: 0.990255
[9] train's binary_logloss: 0.272297    train's auc: 0.996508   val's binary_logloss: 0.286207  val's auc: 0.990927
[10]    train's binary_logloss: 0.250728    train's auc: 0.996455   val's binary_logloss: 0.265777  val's auc: 0.991823
Did not meet early stopping. Best iteration is:
[10]    train's binary_logloss: 0.250728    train's auc: 0.996455   val's binary_logloss: 0.265777  val's auc: 0.991823</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2023/03/19 23:00:57 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: "/opt/anaconda3/envs/mlflow_tune/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils."</code></pre>
</div>
</div>
<p>When training was done, the UI showed the autologged metrics such as feature importance scores and plots:</p>
<p><img src="https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/images/lightgbm_autologging.png" class="img-fluid"></p>
<p>The UI also shoed other metrics I defined when setting up the training. This information is under “Metrics” section in the run. When I selected <code>train-binary_logloss</code>, it showed a log-loss vs.&nbsp;iteration curve. I could overlay <code>val-binary_logloss</code> on top of it, which would be useful to identify model overfitting.</p>
<p><img src="https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/images/train-val-binary_logloss.png" class="img-fluid"></p>
<p>I could fetch all logged metrics via <code>mlflow.client.MlflowClient</code>.</p>
<div id="9cf1bf8c-23fd-4ced-b627-d29a49f2ea33" class="cell" data-tags="[]" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">mlflow_client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MlflowClient()</span>
<span id="cb12-2">run_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> run.info.run_id</span>
<span id="cb12-3">mlflow_run <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mlflow_client.get_run(run_id)</span>
<span id="cb12-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(mlflow_run.data.metrics)</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'train-auc': 0.9964553794829024, 'train-binary_logloss': 0.2507277280941103, 'val-binary_logloss': 0.2657767821072834, 'test-auc': 0.9735537190082645, 'stopped_iteration': 10.0, 'val-auc': 0.9918234767025089, 'best_iteration': 10.0, 'test-logloss': 0.30723647532041254}</code></pre>
</div>
</div>
<p>This confirms that with <code>mlflow.lightgbm.autolog</code>, the following metrics were logged in the UI: - Optimization loss over iterations - Metrics from train and validation datasets - Feature importance scores and plots - Additional metrics logged by <code>mlflow.log_metrics</code></p>
</section>
<section id="hyperparameter-tuning-and-mlflow-autologging" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameter-tuning-and-mlflow-autologging">Hyperparameter tuning and MLflow autologging</h2>
<p>After some testing, I learned that the autologging behavior changed depending on tuner and autologging types. I tested scikit-learn and LightGBM autologging, and scikit-learn and Dask-ML tuners. This resulted in the following four combinations to test:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th>Test #</th>
<th>LightGBM autologging</th>
<th>scikit-learn autologging</th>
<th>Tuner backend</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>No</td>
<td>Yes</td>
<td>scikit-learn</td>
</tr>
<tr class="even">
<td>2</td>
<td>No</td>
<td>Yes</td>
<td>dask-ml</td>
</tr>
<tr class="odd">
<td>3</td>
<td>Yes</td>
<td>Yes</td>
<td>scikit-learn</td>
</tr>
<tr class="even">
<td>4</td>
<td>Yes</td>
<td>Yes</td>
<td>dask-ml</td>
</tr>
</tbody>
</table>
<section id="test-1.-sklearn-autolog-and-sklearn-tuner" class="level3">
<h3 class="anchored" data-anchor-id="test-1.-sklearn-autolog-and-sklearn-tuner">Test 1. sklearn autolog and sklearn tuner</h3>
<p>To reduce the interaction btw <code>mlflow.lightgbm.autolog</code> and <code>mlflow.sklearn.autolog</code>, I turned the former first.</p>
<div id="e3ab5e10-3192-4d76-beaa-4325b511fedf" class="cell" data-tags="[]" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">mlflow.lightgbm.autolog(disable<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div></div>
</div>
<div id="f6daf717-37b6-4348-a2f8-e9005b9aabc6" class="cell" data-tags="[]" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">mlflow.sklearn.autolog(max_tuning_runs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># log all runs</span></span></code></pre></div></div>
</div>
<p>Here, I also used <code>PredefinedSplit</code> instead of k-fold to match the datasets for a hyperparameter search and evaluation parameters in LightGBM.</p>
<div id="033d7833-cbfb-40e3-b0d4-b8f5da4a2349" class="cell" data-tags="[]" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">X_train_val, X_test, y_train_val, y_test <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train_test_split(X, y, random_state<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>seed)</span>
<span id="cb16-2"></span>
<span id="cb16-3">n_val_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span></span>
<span id="cb16-4">n_train_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_val.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> n_val_size</span>
<span id="cb16-5">ps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PredefinedSplit(test_fold<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_val_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_train_size)</span>
<span id="cb16-6"></span>
<span id="cb16-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> train_index, val_index <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> ps.split():</span>
<span id="cb16-8">    X_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_val[train_index, :]</span>
<span id="cb16-9">    X_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X_train_val[val_index, :]</span>
<span id="cb16-10">    y_train <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_train_val[train_index]</span>
<span id="cb16-11">    y_val <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> y_train_val[val_index]</span></code></pre></div></div>
</div>
<p>Additionally, to be consistent with the autologging and tuner types, I used the scikit-learn API version of LightGBM (<code>LGBMClassifier</code>). For this tuning example, I chose <code>learning_rate</code> and <code>subsample</code> hyperparameters.</p>
<div id="82c861f2-d74a-4792-ba0a-e80460bcd864" class="cell" data-tags="[]" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">n_search <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span></span>
<span id="cb17-2"></span>
<span id="cb17-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> mlflow.start_run(run_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test_1"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb17-4">    </span>
<span id="cb17-5">    clf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> lgb.LGBMClassifier(</span>
<span id="cb17-6">        objective<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"binary"</span>,</span>
<span id="cb17-7">        metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"binary_logloss"</span>,</span>
<span id="cb17-8">        seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>seed,</span>
<span id="cb17-9">        class_weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"balanced"</span>,</span>
<span id="cb17-10">        n_estimators<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,</span>
<span id="cb17-11">    )</span>
<span id="cb17-12">    </span>
<span id="cb17-13">    pipe <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Pipeline([(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"clf"</span>, clf)])</span>
<span id="cb17-14">    param_space <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb17-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"clf__learning_rate"</span>: np.linspace(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.05</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>),</span>
<span id="cb17-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"clf__subsample"</span>: np.linspace(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>),</span>
<span id="cb17-17">    }</span>
<span id="cb17-18">    </span>
<span id="cb17-19">    search_cv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomizedSearchCV(pipe, param_space, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ps, n_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_search)</span>
<span id="cb17-20">    search_cv.fit(</span>
<span id="cb17-21">        X_train_val,</span>
<span id="cb17-22">        y_train_val,</span>
<span id="cb17-23">        clf__eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[(X_val, y_val)],</span>
<span id="cb17-24">        clf__eval_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'val'</span>],</span>
<span id="cb17-25">        clf__eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'binary_logloss'</span>],</span>
<span id="cb17-26">    )</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] val's binary_logloss: 0.624749
[2] val's binary_logloss: 0.568357
[3] val's binary_logloss: 0.520761
[4] val's binary_logloss: 0.480421
[5] val's binary_logloss: 0.442099
[6] val's binary_logloss: 0.410214
[7] val's binary_logloss: 0.382292
[8] val's binary_logloss: 0.357785
[9] val's binary_logloss: 0.335433
[10]    val's binary_logloss: 0.31392
[1] val's binary_logloss: 0.637054
[2] val's binary_logloss: 0.589451
[3] val's binary_logloss: 0.547508
[4] val's binary_logloss: 0.511241
[5] val's binary_logloss: 0.478765
[6] val's binary_logloss: 0.448812
[7] val's binary_logloss: 0.423736
[8] val's binary_logloss: 0.398193
[9] val's binary_logloss: 0.377066
[10]    val's binary_logloss: 0.356542
[1] val's binary_logloss: 0.653833
[2] val's binary_logloss: 0.618878
[3] val's binary_logloss: 0.586995
[4] val's binary_logloss: 0.558061
[5] val's binary_logloss: 0.531579
[6] val's binary_logloss: 0.507355
[7] val's binary_logloss: 0.485109
[8] val's binary_logloss: 0.463636
[9] val's binary_logloss: 0.444977
[10]    val's binary_logloss: 0.427695
[1] val's binary_logloss: 0.620853
[2] val's binary_logloss: 0.56225
[3] val's binary_logloss: 0.512275
[4] val's binary_logloss: 0.464753
[5] val's binary_logloss: 0.426894
[6] val's binary_logloss: 0.390463
[7] val's binary_logloss: 0.358157
[8] val's binary_logloss: 0.330555
[9] val's binary_logloss: 0.305165
[10]    val's binary_logloss: 0.282671</code></pre>
</div>
</div>
<p>The UI showed that 1 parent run and <code>n_search</code> (3) child runs were created, where the parent run had the autologged metrics such as confusion matrix, ROC curve, and PR curve:</p>
<p><img src="https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/images/test1.png" class="img-fluid"></p>
<p><code>cv_results</code> was also returned and the logged metrics from all child runs were similar to <code>cv_results</code>.</p>
</section>
<section id="test-2.-sklearn-autolog-and-dask-ml-tuner" class="level3">
<h3 class="anchored" data-anchor-id="test-2.-sklearn-autolog-and-dask-ml-tuner">Test 2. sklearn autolog and dask-ml tuner</h3>
<div id="3bbff4d0-39d3-4832-8711-1e82a11916d0" class="cell" data-tags="[]" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Client(processes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, threads_per_worker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, n_workers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div></div>
</div>
<div id="dc7954c5-4d19-4b2c-94fc-8d2b25f8dd4a" class="cell" data-tags="[]" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> mlflow.start_run(run_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test_2"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb20-2">    </span>
<span id="cb20-3">    search_cv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dask_RandomizedSearchCV(pipe, param_space, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ps, n_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_search)</span>
<span id="cb20-4">    search_cv.fit(</span>
<span id="cb20-5">        X_train_val,</span>
<span id="cb20-6">        y_train_val,</span>
<span id="cb20-7">        clf__eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[(X_val, y_val)],</span>
<span id="cb20-8">        clf__eval_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val"</span>],</span>
<span id="cb20-9">        clf__eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"binary_logloss"</span>],</span>
<span id="cb20-10">    )</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] val's binary_logloss: 0.6207[1] val's binary_logloss: 0.6207
[1] val's binary_logloss: 0.64539

[2] val's binary_logloss: 0.603905
[2] val's binary_logloss: 0.561648
[2] val's binary_logloss: 0.561648
[3] val's binary_logloss: 0.566663
[3] val's binary_logloss: 0.51229
[3] val's binary_logloss: 0.51229
[4] val's binary_logloss: 0.533792
[4] val's binary_logloss: 0.470843
[4] val's binary_logloss: 0.470843
[5] val's binary_logloss: 0.504106
[5] val's binary_logloss: 0.43163
[5] val's binary_logloss: 0.43163
[6] val's binary_logloss: 0.476199
[6] val's binary_logloss: 0.399279
[6] val's binary_logloss: 0.399279
[7] val's binary_logloss: 0.452345
[7] val's binary_logloss: 0.371128
[7] val's binary_logloss: 0.371128
[8] val's binary_logloss: 0.430183
[8] val's binary_logloss: 0.345312
[8] val's binary_logloss: 0.345312
[9] val's binary_logloss: 0.409486
[9] val's binary_logloss: 0.323905
[9] val's binary_logloss: 0.323905
[10]    val's binary_logloss: 0.388993
[10]    val's binary_logloss: 0.303382
[10]    val's binary_logloss: 0.303382
[1] val's binary_logloss: 0.642694
[2] val's binary_logloss: 0.599408
[3] val's binary_logloss: 0.5599
[4] val's binary_logloss: 0.525228
[5] val's binary_logloss: 0.490788
[6] val's binary_logloss: 0.461964
[7] val's binary_logloss: 0.433798
[8] val's binary_logloss: 0.409936
[9] val's binary_logloss: 0.385757
[10]    val's binary_logloss: 0.365051</code></pre>
</div>
</div>
<p><code>mlflow.sklearn.autolog</code> still created confusion matrix, ROC curve, and PR curve but <strong>only a single run is returned,</strong> and all child runs are now missing. Besides, the UI also didn’t log <code>cv_results</code>.</p>
<p><img src="https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/images/test2.png" width="400"></p>
<section id="is-the-only-logged-run-the-best-run" class="level4">
<h4 class="anchored" data-anchor-id="is-the-only-logged-run-the-best-run">Is the only logged run the best run?</h4>
<p>Here was where the behavior of <code>mlflow.sklearn.autolog</code> changed. It was supposed to return a single parent run and multiple child runs but when <code>dask-ml</code> was used as tuner, it only logged a single run. I didn’t know whether thi was the best run or not, so I decided to compare the MLflow logged result with the actual search result.</p>
<div id="2977fc6e-2d8b-4e50-9201-84d886a080cd" class="cell" data-tags="[]" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">mlflow_run <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mlflow_client.get_run(run.info.run_id)</span></code></pre></div></div>
</div>
<div id="a31b2c59-a15e-41d1-9c6f-d10948db8417" class="cell" data-tags="[]" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(search_cv.best_estimator_.get_params()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'clf__learning_rate'</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb23-2">mlflow_run.data.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'clf__learning_rate'</span>]</span>
<span id="cb23-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(search_cv.best_estimator_.get_params()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'clf__subsample'</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb23-4">mlflow_run.data.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'clf__subsample'</span>]</span></code></pre></div></div>
</div>
<p>Luckily, the assertions have passed, meaning that the single recorded run by MLflow was the best run. Except that users can’t see the child runs in the UI, this behavior seems acceptable.</p>
</section>
</section>
<section id="test-3.-lightgbmsklearn-autolog-and-sklearn-tuner" class="level3">
<h3 class="anchored" data-anchor-id="test-3.-lightgbmsklearn-autolog-and-sklearn-tuner">Test 3. lightgbm+sklearn autolog and sklearn tuner</h3>
<p>This test idea came to my mind becasue I imagined it would be very convenient if one could use autologging on top of a sklearn tuner. Thus, I decided to turn on lightgbm autologging in addition to the sklearn autologging.</p>
<div id="388183c5-ffaf-4d93-bf23-ce499ed243d0" class="cell" data-tags="[]" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">mlflow.lightgbm.autolog()</span></code></pre></div></div>
</div>
<div id="1a629ef7-4a01-406e-af8a-eb6ccd74353f" class="cell" data-tags="[]" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> mlflow.start_run(run_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'test_3'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb25-2">    </span>
<span id="cb25-3">    search_cv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomizedSearchCV(pipe, param_space, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ps, n_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_search)</span>
<span id="cb25-4">    search_cv.fit(</span>
<span id="cb25-5">        X_train_val,</span>
<span id="cb25-6">        y_train_val,</span>
<span id="cb25-7">        clf__eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[(X_val, y_val)],</span>
<span id="cb25-8">        clf__eval_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val"</span>],</span>
<span id="cb25-9">        clf__eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"binary_logloss"</span>],</span>
<span id="cb25-10">    )</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] val's binary_logloss: 0.64539
[2] val's binary_logloss: 0.603905
[3] val's binary_logloss: 0.566663
[4] val's binary_logloss: 0.533792
[5] val's binary_logloss: 0.504106
[6] val's binary_logloss: 0.476199
[7] val's binary_logloss: 0.452345
[8] val's binary_logloss: 0.430183
[9] val's binary_logloss: 0.409486
[10]    val's binary_logloss: 0.388993
[1] val's binary_logloss: 0.6207
[2] val's binary_logloss: 0.561648
[3] val's binary_logloss: 0.51229
[4] val's binary_logloss: 0.470843
[5] val's binary_logloss: 0.43163
[6] val's binary_logloss: 0.399279
[7] val's binary_logloss: 0.371128
[8] val's binary_logloss: 0.345312
[9] val's binary_logloss: 0.323905
[10]    val's binary_logloss: 0.303382
[1] val's binary_logloss: 0.632926
[2] val's binary_logloss: 0.582412
[3] val's binary_logloss: 0.538314
[4] val's binary_logloss: 0.500565
[5] val's binary_logloss: 0.467006
[6] val's binary_logloss: 0.436234
[7] val's binary_logloss: 0.410759
[8] val's binary_logloss: 0.384813
[9] val's binary_logloss: 0.361938
[10]    val's binary_logloss: 0.342656
[1] val's binary_logloss: 0.642694
[2] val's binary_logloss: 0.599408
[3] val's binary_logloss: 0.5599
[4] val's binary_logloss: 0.525228
[5] val's binary_logloss: 0.490788
[6] val's binary_logloss: 0.461964
[7] val's binary_logloss: 0.433798
[8] val's binary_logloss: 0.409936
[9] val's binary_logloss: 0.385757
[10]    val's binary_logloss: 0.365051</code></pre>
</div>
</div>
<p>This time, I found that sklearn autologging behaved normally but lightgbm autologging didn’t work at all. First, lightgbm autologging metrics such as feature importance scores were missing:</p>
<p><img src="https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/images/test3.png" width="400"></p>
<p>Second, <code>training-log_loss</code> wasn’t logged for every iteration but it was logged as a single numeric value, and thus was visualized as a bar graph:</p>
<p><img src="https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/images/test3_1.png" class="img-fluid"></p>
</section>
<section id="test-4.-lightgbmsklearn-autolog-and-dask-ml-tuner" class="level3">
<h3 class="anchored" data-anchor-id="test-4.-lightgbmsklearn-autolog-and-dask-ml-tuner">Test 4. lightgbm+sklearn autolog and dask-ml tuner</h3>
<p>Finally, I used the dask-ml tuner, lightgbm and sklearn autologging altogether.</p>
<div id="7d789316-6f32-425b-8082-c3cf605d3df9" class="cell" data-tags="[]" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> mlflow.start_run(run_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'test_4'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> run:</span>
<span id="cb27-2">    </span>
<span id="cb27-3">    search_cv <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dask_RandomizedSearchCV(pipe, param_space, cv<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ps, n_iter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>n_search)</span>
<span id="cb27-4">    search_cv.fit(</span>
<span id="cb27-5">        X_train_val,</span>
<span id="cb27-6">        y_train_val,</span>
<span id="cb27-7">        clf__eval_set<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[(X_val, y_val)],</span>
<span id="cb27-8">        clf__eval_names<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"val"</span>],</span>
<span id="cb27-9">        clf__eval_metric<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"binary_logloss"</span>],</span>
<span id="cb27-10">    )</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] val's binary_logloss: 0.632926[1]   val's binary_logloss: 0.653833

[1] val's binary_logloss: 0.632926
[2] val's binary_logloss: 0.582412
[2] val's binary_logloss: 0.618878
[2] val's binary_logloss: 0.582412
[3] val's binary_logloss: 0.586995
[3] val's binary_logloss: 0.538314
[3] val's binary_logloss: 0.538314
[4] val's binary_logloss: 0.558061
[4] val's binary_logloss: 0.500565
[4] val's binary_logloss: 0.500565
[5] val's binary_logloss: 0.531579
[5] val's binary_logloss: 0.467006
[5] val's binary_logloss: 0.467006
[6] val's binary_logloss: 0.507355
[6] val's binary_logloss: 0.436234
[6] val's binary_logloss: 0.436234
[7] val's binary_logloss: 0.485109
[7] val's binary_logloss: 0.410759
[7] val's binary_logloss: 0.410759
[8] val's binary_logloss: 0.463636
[8] val's binary_logloss: 0.384813
[8] val's binary_logloss: 0.384813
[9] val's binary_logloss: 0.444977
[9] val's binary_logloss: 0.361938
[9] val's binary_logloss: 0.361938
[10]    val's binary_logloss: 0.427695
[10]    val's binary_logloss: 0.342656
[10]    val's binary_logloss: 0.342656
[1] val's binary_logloss: 0.651621
[2] val's binary_logloss: 0.615177
[3] val's binary_logloss: 0.581242
[4] val's binary_logloss: 0.550942
[5] val's binary_logloss: 0.522853
[6] val's binary_logloss: 0.494685
[7] val's binary_logloss: 0.470868
[8] val's binary_logloss: 0.447008
[9] val's binary_logloss: 0.42506
[10]    val's binary_logloss: 0.406164</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>2023/03/19 23:02:26 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 4f0ea51beb0748139aa4364c5d332279. Failed operations: [MlflowException("API request to http://127.0.0.1:5000/api/2.0/mlflow/runs/log-batch failed with exception HTTPConnectionPool(host=\'127.0.0.1\', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError(\'too many 500 error responses\'))")]')]</code></pre>
</div>
</div>
<p>This time, similar to Test 2, a single run was returned but it seemed that lightgbm autologging actually worked because the UI generated images from both sklearn and lightgbm autologging methods:</p>
<p><img src="https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/images/test4.png" width="400"></p>
<p>However, only single run was returned, again like in Test 2. Unfortunately, this time, this single run didn’t pass the assertion test.</p>
<div id="6fbc0c8d-a207-4fbc-a084-e7e86a1a8b19" class="cell" data-tags="[]" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">mlflow_run <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mlflow_client.get_run(run.info.run_id)</span></code></pre></div></div>
</div>
<div id="527128e5-6c5e-4e62-8e0f-7616560f7701" class="cell" data-tags="[]" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(search_cv.best_estimator_.get_params()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'clf__learning_rate'</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb31-2">mlflow_run.data.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>]</span>
<span id="cb31-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(search_cv.best_estimator_.get_params()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'clf__subsample'</span>]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb31-4">mlflow_run.data.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>]</span></code></pre></div></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AssertionError</span>                            Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[21], line 1</span>
<span class="ansi-green-fg">----&gt; 1</span> <span style="font-weight:bold;color:rgb(0,135,0)">assert</span> <span style="color:rgb(0,135,0)">str</span>(search_cv<span style="color:rgb(98,98,98)">.</span>best_estimator_<span style="color:rgb(98,98,98)">.</span>get_params()[<span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">clf__learning_rate</span><span style="color:rgb(175,0,0)">'</span>]) <span style="color:rgb(98,98,98)">==</span> \
<span class="ansi-green-fg ansi-bold">      2</span> mlflow_run<span style="color:rgb(98,98,98)">.</span>data<span style="color:rgb(98,98,98)">.</span>params[<span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">learning_rate</span><span style="color:rgb(175,0,0)">'</span>]
<span class="ansi-green-fg ansi-bold">      3</span> <span style="font-weight:bold;color:rgb(0,135,0)">assert</span> <span style="color:rgb(0,135,0)">str</span>(search_cv<span style="color:rgb(98,98,98)">.</span>best_estimator_<span style="color:rgb(98,98,98)">.</span>get_params()[<span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">clf__subsample</span><span style="color:rgb(175,0,0)">'</span>]) <span style="color:rgb(98,98,98)">==</span> \
<span class="ansi-green-fg ansi-bold">      4</span> mlflow_run<span style="color:rgb(98,98,98)">.</span>data<span style="color:rgb(98,98,98)">.</span>params[<span style="color:rgb(175,0,0)">'</span><span style="color:rgb(175,0,0)">subsample</span><span style="color:rgb(175,0,0)">'</span>]

<span class="ansi-red-fg">AssertionError</span>: </pre>
</div>
</div>
</div>
<div id="d93e952b-4be8-46d7-9afd-7176dbc5ace4" class="cell" data-tags="[]" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(search_cv.best_estimator_.get_params()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'clf__learning_rate'</span>]),</span>
<span id="cb32-2">      mlflow_run.data.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'learning_rate'</span>])</span>
<span id="cb32-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>(search_cv.best_estimator_.get_params()[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'clf__subsample'</span>]),</span>
<span id="cb32-4">      mlflow_run.data.params[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subsample'</span>])</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.05 0.07777777777777778
0.5 0.7000000000000001</code></pre>
</div>
</div>
<p>This means that when dask-ml, sklearn autolog, and lightgbm autologgin are used at once, we cannot trust the MLflow tracking UI becasue the single set of represented hyperparameters in the UI are not the best estimator’s hyperparameters. This means this combination gives unreliable results, which we should avoid at all costs.</p>
<div id="b4ff5db1-d59e-4445-adfc-be8a9f9c5594" class="cell" data-tags="[]" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">client.close()</span></code></pre></div></div>
</div>
</section>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>In this notebook, I demonstrated how different combinations of autologging and tuners could produce different results. Some of these changed behaviors were simple omissions but I found a more troubling combination as well where the results were just simply wrong. This suggests that when it comes to testing interoperability, we should not only check whether they work together but also whether the returned results are accurate.</p>


</section>

 ]]></description>
  <category>ML</category>
  <category>ML Ops</category>
  <guid>https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/2023-03-17-mlflow-lightgbm-dask.html</guid>
  <pubDate>Fri, 17 Mar 2023 05:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2023-03-17-mlflow-lightgbm-dask/images/index.png" medium="image" type="image/png" height="109" width="144"/>
</item>
<item>
  <title>Comparing type inference methods for mixed data arrays</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2023-03-02-compare-type-inference/2023-03-02-compare-type-inference.html</link>
  <description><![CDATA[ 





<p>Some people work with data where the meaning of features (columns) is very clear because only common sense is required. For instance, even without a schema, in a housing price dataset, a column called “number of rooms” would be the number of rooms in a housing unit, and it’s very likely that the values of this column will be integers.</p>
<p>In hardware (microprocessor) verification, it’s often impossible to understand the meaning of the columns. If you are an ML practitioner without hardware engineering background, you can nag verification engineers to explain it but it’s very likely that you wouldn’t completely understand, and there are hundreds and thousands of columns that need explanation. Even if you do have the background, depending on the product type, it’s likely that you can’t have full understanding of all columns.</p>
<p>Besides, sometimes you need to work with so called “mixed data type” arrays. An example would be an array of boolean and float such as <code>[True, 0.0]</code>. If you use pandas to read this type of data, you should know that it infers the data type of an array like this as <code>object</code> quite often. This inference is done by the <code>pandas.DataFrame.infer_objects</code> method. However, a lot of different types of mixed arrays can be inferred as <code>object</code> dtype. This “blanket” approach might be useful for practical data handling but it is not suitable for more accurate and granular type inference. If the goal is to <em>understand the actual content</em> of the arrays.</p>
<p>You may not have known that pandas has another type inference method in their api: <code>pandas.api.types.infer_dtype</code>, which provides granular type inference and allows to ignore null values (<code>skipna=True</code>). This method returns a name of inferred type as a string such as <code>"boolean"</code> or <code>"floating"</code>. For the comprehensive list of the type names, see the <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.api.types.infer_dtype.html">pandas documentation</a>.</p>
<p>This notebook compares the two type inference methods of pandas (<code>pandas.DataFrame.infer_objects</code> and <code>pandas.api.types.infer_dtype</code>) when they are faced with various cases of mixed data type arrays. For the comparison, I used exhaustive combination of <code>None, array(list), str, bool, float, int</code> data to generate various mixed arrays, and then applied the two inference methods to compare the results.</p>
<div id="3791c520-1a4e-447a-b5c8-3c6c801ec4d8" class="cell" data-tags="[]" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span></code></pre></div></div>
</div>
<section id="testing-data-generating-arrays-of-mixed-data-types" class="level2">
<h2 class="anchored" data-anchor-id="testing-data-generating-arrays-of-mixed-data-types">Testing data: generating arrays of mixed data types</h2>
<p>Here I generated a dataframe with various mixed types: <code>"nan"(</code>np.nan<code>), "none", "array" (</code>list<code>), "str", "bool", "float", "int"</code>. Using their exhaustive combinations (<img src="https://latex.codecogs.com/png.latex?N_%7Btype%7D=2">), I created a 2-element array for each combination. For fair comparison, I assigned <code>object</code> dtypes to all columns.</p>
<div id="b2a4941e-169a-4482-bcfa-cfd42c6813cc" class="cell" data-tags="[]" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">example <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.DataFrame(</span>
<span id="cb2-2">    {</span>
<span id="cb2-3">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nan'</span>: [np.nan, np.nan],</span>
<span id="cb2-4">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nan_none'</span>: [np.nan, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>],</span>
<span id="cb2-5">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nan_array'</span>: [np.nan, []],</span>
<span id="cb2-6">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nan_str'</span>: [np.nan, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>],</span>
<span id="cb2-7">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nan_bool'</span>: [np.nan, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>],        </span>
<span id="cb2-8">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nan_float'</span>: [np.nan, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],        </span>
<span id="cb2-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'nan_int'</span>: [np.nan, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb2-10">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>],        </span>
<span id="cb2-11">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none_array'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, []],</span>
<span id="cb2-12">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none_str'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>],        </span>
<span id="cb2-13">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none_bool'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>],</span>
<span id="cb2-14">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none_float'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>],</span>
<span id="cb2-15">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none_int'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb2-16">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'array'</span>: [[], []],</span>
<span id="cb2-17">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'array_str'</span>: [[], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>],</span>
<span id="cb2-18">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'array_bool'</span>: [[], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>],</span>
<span id="cb2-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'array_float'</span>: [[], <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb2-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'array_int'</span>: [[], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb2-21">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'str'</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"b"</span>],</span>
<span id="cb2-22">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'str_bool'</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>],</span>
<span id="cb2-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'str_float'</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>],</span>
<span id="cb2-24">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'str_int'</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb2-25">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bool'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>],</span>
<span id="cb2-26">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bool_float'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>],</span>
<span id="cb2-27">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bool_int'</span>: [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>],</span>
<span id="cb2-28">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'float'</span>: [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>],</span>
<span id="cb2-29">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'float_int'</span>: [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb2-30">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'int'</span>: [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>],</span>
<span id="cb2-31">    },</span>
<span id="cb2-32">    dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">object</span></span>
<span id="cb2-33">)</span>
<span id="cb2-34"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(example.dtypes.value_counts())</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>object    28
dtype: int64</code></pre>
</div>
</div>
<div id="992bfe14-39d5-41b9-b4b6-81311e9fdbac" class="cell" data-tags="[]" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">example.head()</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">nan</th>
<th data-quarto-table-cell-role="th">nan_none</th>
<th data-quarto-table-cell-role="th">nan_array</th>
<th data-quarto-table-cell-role="th">nan_str</th>
<th data-quarto-table-cell-role="th">nan_bool</th>
<th data-quarto-table-cell-role="th">nan_float</th>
<th data-quarto-table-cell-role="th">nan_int</th>
<th data-quarto-table-cell-role="th">none</th>
<th data-quarto-table-cell-role="th">none_array</th>
<th data-quarto-table-cell-role="th">none_str</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">str</th>
<th data-quarto-table-cell-role="th">str_bool</th>
<th data-quarto-table-cell-role="th">str_float</th>
<th data-quarto-table-cell-role="th">str_int</th>
<th data-quarto-table-cell-role="th">bool</th>
<th data-quarto-table-cell-role="th">bool_float</th>
<th data-quarto-table-cell-role="th">bool_int</th>
<th data-quarto-table-cell-role="th">float</th>
<th data-quarto-table-cell-role="th">float_int</th>
<th data-quarto-table-cell-role="th">int</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>None</td>
<td>None</td>
<td>None</td>
<td>...</td>
<td>a</td>
<td>a</td>
<td>a</td>
<td>a</td>
<td>True</td>
<td>True</td>
<td>True</td>
<td>1.0</td>
<td>1.0</td>
<td>1</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>NaN</td>
<td>None</td>
<td>[]</td>
<td>a</td>
<td>True</td>
<td>1.0</td>
<td>1</td>
<td>None</td>
<td>[]</td>
<td>a</td>
<td>...</td>
<td>b</td>
<td>True</td>
<td>1.0</td>
<td>1</td>
<td>False</td>
<td>0.0</td>
<td>1</td>
<td>0.0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>2 rows × 28 columns</p>
</div>
</div>
</div>
</section>
<section id="type-inference-with-pandas.dataframe.infer_objects" class="level2">
<h2 class="anchored" data-anchor-id="type-inference-with-pandas.dataframe.infer_objects">Type inference with <code>pandas.DataFrame.infer_objects</code></h2>
<div id="889a05aa-2582-4b9f-bd04-40367eb0e344" class="cell" data-tags="[]" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">example_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> example.T</span>
<span id="cb5-2">example_results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pd_infer_objects'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> example.infer_objects().dtypes</span>
<span id="cb5-3">example_results</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">pd_infer_objects</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">nan</th>
<td>NaN</td>
<td>NaN</td>
<td>float64</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">nan_none</th>
<td>NaN</td>
<td>None</td>
<td>float64</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">nan_array</th>
<td>NaN</td>
<td>[]</td>
<td>object</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">nan_str</th>
<td>NaN</td>
<td>a</td>
<td>object</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">nan_bool</th>
<td>NaN</td>
<td>True</td>
<td>object</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">nan_float</th>
<td>NaN</td>
<td>1.0</td>
<td>float64</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">nan_int</th>
<td>NaN</td>
<td>1</td>
<td>float64</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">none</th>
<td>None</td>
<td>None</td>
<td>object</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">none_array</th>
<td>None</td>
<td>[]</td>
<td>object</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">none_str</th>
<td>None</td>
<td>a</td>
<td>object</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">none_bool</th>
<td>None</td>
<td>True</td>
<td>object</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">none_float</th>
<td>None</td>
<td>0.0</td>
<td>float64</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">none_int</th>
<td>None</td>
<td>1</td>
<td>float64</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">array</th>
<td>[]</td>
<td>[]</td>
<td>object</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">array_str</th>
<td>[]</td>
<td>a</td>
<td>object</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">array_bool</th>
<td>[]</td>
<td>True</td>
<td>object</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">array_float</th>
<td>[]</td>
<td>1.0</td>
<td>object</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">array_int</th>
<td>[]</td>
<td>1</td>
<td>object</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">str</th>
<td>a</td>
<td>b</td>
<td>object</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">str_bool</th>
<td>a</td>
<td>True</td>
<td>object</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">str_float</th>
<td>a</td>
<td>1.0</td>
<td>object</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">str_int</th>
<td>a</td>
<td>1</td>
<td>object</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">bool</th>
<td>True</td>
<td>False</td>
<td>bool</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">bool_float</th>
<td>True</td>
<td>0.0</td>
<td>object</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">bool_int</th>
<td>True</td>
<td>1</td>
<td>object</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">float</th>
<td>1.0</td>
<td>0.0</td>
<td>float64</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">float_int</th>
<td>1.0</td>
<td>0</td>
<td>float64</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">int</th>
<td>1</td>
<td>0</td>
<td>int64</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>At a glance, this method infers most of these mixed arrays as <code>object</code>, which naturally doesn’t deliver much information about what exact mixture of types the arrays have. Plus, some <code>object</code> arrays can receive <code>int</code> or <code>float</code> casting (e.g., <code>[True, 1]</code>), but some can’t (e.g., <code>['a', 1]</code>).</p>
</section>
<section id="type-inference-with-pandas.api.types.infer_dtype" class="level2">
<h2 class="anchored" data-anchor-id="type-inference-with-pandas.api.types.infer_dtype">Type inference with <code>pandas.api.types.infer_dtype</code></h2>
<p>This method allows two variants: with skipping na values and without. Let’s get inference results from the both.</p>
<div id="2fffe96a-ee40-4a50-8972-b46906f75b2c" class="cell" data-tags="[]" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">example_results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pd_infer_dtype'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> example.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x:pd.api.types.infer_dtype(x, skipna<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>))</span>
<span id="cb6-2">example_results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pd_infer_dtype_skipna'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> example.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x:pd.api.types.infer_dtype(x, skipna<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>))</span></code></pre></div></div>
</div>
<div id="718bcc57" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">example_results</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">pd_infer_objects</th>
<th data-quarto-table-cell-role="th">pd_infer_dtype</th>
<th data-quarto-table-cell-role="th">pd_infer_dtype_skipna</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">nan</th>
<td>NaN</td>
<td>NaN</td>
<td>float64</td>
<td>floating</td>
<td>empty</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">nan_none</th>
<td>NaN</td>
<td>None</td>
<td>float64</td>
<td>mixed</td>
<td>empty</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">nan_array</th>
<td>NaN</td>
<td>[]</td>
<td>object</td>
<td>mixed</td>
<td>mixed</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">nan_str</th>
<td>NaN</td>
<td>a</td>
<td>object</td>
<td>mixed</td>
<td>string</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">nan_bool</th>
<td>NaN</td>
<td>True</td>
<td>object</td>
<td>mixed</td>
<td>boolean</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">nan_float</th>
<td>NaN</td>
<td>1.0</td>
<td>float64</td>
<td>floating</td>
<td>floating</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">nan_int</th>
<td>NaN</td>
<td>1</td>
<td>float64</td>
<td>integer-na</td>
<td>integer</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">none</th>
<td>None</td>
<td>None</td>
<td>object</td>
<td>mixed</td>
<td>empty</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">none_array</th>
<td>None</td>
<td>[]</td>
<td>object</td>
<td>mixed</td>
<td>mixed</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">none_str</th>
<td>None</td>
<td>a</td>
<td>object</td>
<td>mixed</td>
<td>string</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">none_bool</th>
<td>None</td>
<td>True</td>
<td>object</td>
<td>mixed</td>
<td>boolean</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">none_float</th>
<td>None</td>
<td>0.0</td>
<td>float64</td>
<td>mixed</td>
<td>mixed-integer-float</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">none_int</th>
<td>None</td>
<td>1</td>
<td>float64</td>
<td>mixed-integer</td>
<td>integer</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">array</th>
<td>[]</td>
<td>[]</td>
<td>object</td>
<td>mixed</td>
<td>mixed</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">array_str</th>
<td>[]</td>
<td>a</td>
<td>object</td>
<td>mixed</td>
<td>mixed</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">array_bool</th>
<td>[]</td>
<td>True</td>
<td>object</td>
<td>mixed</td>
<td>mixed</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">array_float</th>
<td>[]</td>
<td>1.0</td>
<td>object</td>
<td>mixed</td>
<td>mixed</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">array_int</th>
<td>[]</td>
<td>1</td>
<td>object</td>
<td>mixed-integer</td>
<td>mixed-integer</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">str</th>
<td>a</td>
<td>b</td>
<td>object</td>
<td>string</td>
<td>string</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">str_bool</th>
<td>a</td>
<td>True</td>
<td>object</td>
<td>mixed</td>
<td>mixed</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">str_float</th>
<td>a</td>
<td>1.0</td>
<td>object</td>
<td>mixed</td>
<td>mixed</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">str_int</th>
<td>a</td>
<td>1</td>
<td>object</td>
<td>mixed-integer</td>
<td>mixed-integer</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">bool</th>
<td>True</td>
<td>False</td>
<td>bool</td>
<td>boolean</td>
<td>boolean</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">bool_float</th>
<td>True</td>
<td>0.0</td>
<td>object</td>
<td>mixed</td>
<td>mixed</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">bool_int</th>
<td>True</td>
<td>1</td>
<td>object</td>
<td>mixed-integer</td>
<td>mixed-integer</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">float</th>
<td>1.0</td>
<td>0.0</td>
<td>float64</td>
<td>floating</td>
<td>floating</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">float_int</th>
<td>1.0</td>
<td>0</td>
<td>float64</td>
<td>mixed-integer-float</td>
<td>mixed-integer-float</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">int</th>
<td>1</td>
<td>0</td>
<td>int64</td>
<td>integer</td>
<td>integer</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="comparison-with-vs.-without-na-values-in-pandas.api.types.infer_dtype" class="level2">
<h2 class="anchored" data-anchor-id="comparison-with-vs.-without-na-values-in-pandas.api.types.infer_dtype">Comparison: with vs.&nbsp;without na values in <code>pandas.api.types.infer_dtype</code></h2>
<p>When we don’t skip na values (<code>skipna=False</code>), we often get <code>"mixed"</code> results from <code>pandas.api.types.infer_dtype</code> for arrays that are inferred as <code>object</code> by <code>pandas.DataFrame.infer_objects</code>. This means, the inference results are not granular, like we just saw from <code>pandas.DataFrame.infer_objects</code>. For instance, in the table above, <code>"nan_array", "nan_str", "nan_bool"</code> are all identified as <code>"mixed"</code> when we don’t ignore nan.</p>
<div id="aab69619" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">example_results.loc[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nan_array"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nan_str"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nan_bool"</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pd_infer_dtype"</span>]</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>nan_array    mixed
nan_str      mixed
nan_bool     mixed
Name: pd_infer_dtype, dtype: object</code></pre>
</div>
</div>
<p>However, when we ignore na values, we get more granular results, which identify the correct data types (without missing).</p>
<div id="819b8ecf" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">example_results.loc[[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nan_array"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nan_str"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nan_bool"</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pd_infer_dtype_skipna"</span>]</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>nan_array      mixed
nan_str       string
nan_bool     boolean
Name: pd_infer_dtype_skipna, dtype: object</code></pre>
</div>
</div>
</section>
<section id="comparison-pandas.dataframe.infer_objects-vs.-pandas.api.types.infer_dtypeskipnatrue" class="level2">
<h2 class="anchored" data-anchor-id="comparison-pandas.dataframe.infer_objects-vs.-pandas.api.types.infer_dtypeskipnatrue">Comparison: <code>pandas.DataFrame.infer_objects</code> vs.&nbsp;<code>pandas.api.types.infer_dtype(skipna=True)</code></h2>
<p>Because <code>pandas.DataFrame.infer_objects</code> has a blanket approach to mixed data arrays, using this method to various mixed arrays, we get a lot of <code>object</code> columns. Let’s take a deeper look at the columns inferred as <code>object</code> by <code>pandas.DataFrame.infer_objects</code>, and examine the inference result from <code>pandas.api.types.infer_dtype(skipna=True)</code>.</p>
<div id="f8e3242e-7d90-4e7e-a7a3-1012464128ca" class="cell" data-tags="[]" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">example_results[example_results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pd_infer_objects'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">object</span>].drop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pd_infer_dtype'</span>, axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).sort_values(by<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pd_infer_dtype_skipna'</span>)</span></code></pre></div></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">pd_infer_objects</th>
<th data-quarto-table-cell-role="th">pd_infer_dtype_skipna</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">nan_bool</th>
<td>NaN</td>
<td>True</td>
<td>object</td>
<td>boolean</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">none_bool</th>
<td>None</td>
<td>True</td>
<td>object</td>
<td>boolean</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">none</th>
<td>None</td>
<td>None</td>
<td>object</td>
<td>empty</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">nan_array</th>
<td>NaN</td>
<td>[]</td>
<td>object</td>
<td>mixed</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">str_float</th>
<td>a</td>
<td>1.0</td>
<td>object</td>
<td>mixed</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">str_bool</th>
<td>a</td>
<td>True</td>
<td>object</td>
<td>mixed</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">array_float</th>
<td>[]</td>
<td>1.0</td>
<td>object</td>
<td>mixed</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">array_bool</th>
<td>[]</td>
<td>True</td>
<td>object</td>
<td>mixed</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">array_str</th>
<td>[]</td>
<td>a</td>
<td>object</td>
<td>mixed</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">array</th>
<td>[]</td>
<td>[]</td>
<td>object</td>
<td>mixed</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">none_array</th>
<td>None</td>
<td>[]</td>
<td>object</td>
<td>mixed</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">bool_float</th>
<td>True</td>
<td>0.0</td>
<td>object</td>
<td>mixed</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">array_int</th>
<td>[]</td>
<td>1</td>
<td>object</td>
<td>mixed-integer</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">str_int</th>
<td>a</td>
<td>1</td>
<td>object</td>
<td>mixed-integer</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">bool_int</th>
<td>True</td>
<td>1</td>
<td>object</td>
<td>mixed-integer</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">none_str</th>
<td>None</td>
<td>a</td>
<td>object</td>
<td>string</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">str</th>
<td>a</td>
<td>b</td>
<td>object</td>
<td>string</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">nan_str</th>
<td>NaN</td>
<td>a</td>
<td>object</td>
<td>string</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>This shows that a variety of mixed arrays is inferred as <code>object</code> by <code>pandas.DataFrame.infer_objects</code> but <code>pandas.api.types.infer_dtype(skipna=True)</code> can often identify true types. It’s true that the latter returns a lot of different arrays as <code>"mixed"</code> but most of them have non-numerical values such as string or array.</p>
<p>One interesting observation is that <code>[True, 0.0]</code> is inferred as <code>"mixed"</code> but <code>[True, 1]</code> as <code>"mixed-integer"</code>, which implies that <code>pandas.api.types.infer_dtype</code> method is designed to highlight the presence of integers in inferred type information.</p>
<p>Finally, we can compare the returned values of two methods:</p>
<div id="bd601df0-8797-4da3-8d81-9006bb4e60c1" class="cell" data-tags="[]" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> val <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(example_results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pd_infer_objects'</span>]):</span>
<span id="cb13-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(val, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(val))</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>int64 &lt;class 'numpy.dtype[int64]'&gt;
float64 &lt;class 'numpy.dtype[float64]'&gt;
bool &lt;class 'numpy.dtype[bool_]'&gt;
object &lt;class 'numpy.dtype[object_]'&gt;</code></pre>
</div>
</div>
<div id="4ea2f495-c820-4733-8611-fdb8ead00094" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> val <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(example_results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pd_infer_dtype_skipna'</span>]):</span>
<span id="cb15-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(val, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(val))</span></code></pre></div></div>
<div class="cell-output cell-output-stdout">
<pre><code>mixed &lt;class 'str'&gt;
floating &lt;class 'str'&gt;
boolean &lt;class 'str'&gt;
mixed-integer &lt;class 'str'&gt;
string &lt;class 'str'&gt;
integer &lt;class 'str'&gt;
mixed-integer-float &lt;class 'str'&gt;
empty &lt;class 'str'&gt;</code></pre>
</div>
</div>
<p>This shows that <code>pandas.DataFrame.infer_objects</code> returns a readily usable python types as inference results but <code>pandas.api.types.infer_dtype</code> returns string values, that need to be further processed or mapped if we want to cast more granular data types to these mixed arrays.</p>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>Hardware verification datasets often do not have schema and the feature meanings cannot be understood without extremely specialized domain knowledge. The fact that the datasets often have mixed data type arrays makes it difficult for ML practitioners to understand the content of the datasets. Therefore, type inference becomes an important step in the data digestion stage.</p>
<p>We can use pandas for type inference. But it has two methods: <code>pandas.DataFrame.infer_objects</code>, <code>pandas.api.types.infer_dtype</code>. The former (<code>pandas.DataFrame.infer_objects</code>) is designed to return practical python data types that can be easily cast on arrays. Thus its type inference tends to adopt a blanket approach where inferred type should work without any further steps to handle the data immediately.</p>
<p>On the other hand, <code>pandas.api.types.infer_dtype</code> does a more granular type inference job where it can also ignore na values. However, it returns string values as a result, not python types. Therefore, we need a further process to use this information for type casting such as <code>"boolean" -&gt; bool</code>.</p>


</section>

 ]]></description>
  <category>ML</category>
  <category>data</category>
  <guid>https://hongsupshin.github.io/posts/2023-03-02-compare-type-inference/2023-03-02-compare-type-inference.html</guid>
  <pubDate>Thu, 02 Mar 2023 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2023-03-02-compare-type-inference/Fig.png" medium="image" type="image/png" height="87" width="144"/>
</item>
<item>
  <title>Zero-shot text-to-image generation</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2022-12-15/</link>
  <description><![CDATA[ 





<p>Generative AI has a lot of hype in ML community these days. OpenAI’s DALL·E, GPT-3, and ChatGPT are good examples. And there’s also stable diffusion. Since they all have public API, not just ML practitioners but general public can use the models to generate texts or images, which creates even bigger hype around generative AI.</p>
<p>But whenever there is hype around something, I think we should be more curious about what’s going on behind the scene. Understanding how it works helps us see through the hype and that is why I chose this paper. We can understand how DALL·E’s text-to-image generative model works, what the authors did to make this happen, and how they validated the result.</p>
<p>To understand this paper thoroughly, you need to know other deep learning model frameworks such as transformer, variational autoencoder, and OpenAI’s CLIP (Contrastive Language-Image Pre-training) model. I found these <a href="https://ml.berkeley.edu/blog/posts/vq-vae/">two</a> <a href="https://ml.berkeley.edu/blog/posts/dalle2/">articles</a> extremely useful, written by Charlie Snell at UC Berkeley. In this post, I will talk about a high-level summary and the interesting discussion we had as a group. If you are interested in more detailed summary of the paper itself, I recommend those two posts.</p>
<section id="big-picture" class="level2">
<h2 class="anchored" data-anchor-id="big-picture">Big picture</h2>
<p>The authors created a deep learning model which <strong>generate images from a text input</strong>. For instance, if you type “hands”, the model will generate images of hands. As the title says, this is done in <em>zero-shot</em> way, meaning that it can generate images that it hasn’t seen before. To be clear, the authors of this paper are not the first ones who created a model like this. There have been precedents but the authors say that the generated images from those still suffer from severe artifacts such as object distortion, illogical object placement, or unnatural blending of foreground and background elements. So the authors made improvements by adopting these two approaches: using a large set of training data and <strong>building a bigger model</strong>.</p>
<p>Before we look into the results, let’s first talk about the model architecture. Their model consists of two parts: <strong>variational autoencoder (VAE)</strong> and <strong>transformer</strong>.</p>
</section>
<section id="variational-autoencoder-vae" class="level2">
<h2 class="anchored" data-anchor-id="variational-autoencoder-vae">Variational autoencoder (VAE)</h2>
<p>The VAE contributes to the generative nature of the model because VAEs have latent representation in the middle that is a probability distribution. Once trained, we can use this distribution to draw samples from it, providing a <em>generative</em> framework. To train the VAE, the authors assumed uniform prior over the latent space. The model can <strong>learn the actual prior from the transformer later</strong> to generate images that match to text input. To train the VAE, the authors used images with text captions from various sources such as Wikipedia images.</p>
<p>What is interesting about the VAE they used is that it assumes <strong>discrete latent distribution</strong> instead of continuous. This variant of VAE is called <strong>vector-quantized VAE (VQ-VAE)</strong>. The motivation is that images and texts are discrete than continuous. But this assumption comes with a major complication: a discrete space is non-differentiable (i.e., can’t back-propagate). That’s why VQ-VAE has a <strong>codebook</strong>, which is essentially a look-up table where a discrete representation is associated with a codebook vector. To be accurate, this paper used a variant of VQ-VAE called <strong>dVAE</strong> where they made this look-up as a weighted average to further smooth out the space.</p>
<p>This VAE also acts as a dimensionality reduction technique because the discrete latent space the authors used has a resolution of 32x32 instead of 256x256, the resolution of the original training images. This brings compression benefit so that the transformer doesn’t have to memorize extremely long sequence but a sequence of length 1024 (=32*32).</p>
</section>
<section id="transformer" class="level2">
<h2 class="anchored" data-anchor-id="transformer">Transformer</h2>
<p>Once the VAE is learned, <strong>we can abandon the uniform prior assumption and use transformer to learn the actual prior</strong>. Transformers help image generation by pixel-wise prediction in an autoregressive way. For instance, given the sequence of previous pixels, the transformer can predict what the next pixel would look like.</p>
<p>Once the transformer is trained, when we give a text prompt to the model, the transformer makes predictions for the image latents (32x32 space) in an autoregressive way. Once we have all predictions, we use the dVAE codebook to lookup the vectors and generate the image. Since we can sample the sequence in a new way, we can generate multiple images. The authors used a <strong>top k approach</strong> to return the <em>best</em> images by ranking the generated images from a candidate pool based on the <strong>scores from OpenAI’s CLIP model</strong>, which represents how well the images match the caption.</p>
<p>The transformer has <strong>12 billion parameters</strong> and a good chunk of the paper is dedicated to all the tricks the authors came up with to fit the model in GPU.</p>
</section>
<section id="journal-club-discussion" class="level2">
<h2 class="anchored" data-anchor-id="journal-club-discussion">Journal club discussion</h2>
<section id="are-the-results-representative-enough" class="level3">
<h3 class="anchored" data-anchor-id="are-the-results-representative-enough"><font color="blue">Are the results representative enough?</font></h3>
<p>Most of us were somewhat <em>disappointed</em> by the authors’ model validation. Figures 3 and 4 in the paper gave some idea of how realistic the generated images are but we were <strong>not sure whether these were cherry-picked or not</strong> because the spectrum of images the model can generate is so wide. Figure 7 showed results from human evaluators. Most of them said the authors’ model was more realistic than the competitors’. Aside from the ethical issues surrounding hiring mturk workers, we thought <strong>the number of mturk workers was small</strong> (5 people) and the number of images they evaluated was small as well.</p>
</section>
<section id="why-not-investigate-model-failures" class="level3">
<h3 class="anchored" data-anchor-id="why-not-investigate-model-failures"><font color="blue">Why not investigate model failures?</font></h3>
<p>What was more interesting to us was Fig. 8, the CUB dataset which have images of birds. The example images here looked worse than others and the authors speculated that this was due to the detail-oriented text information of images, which might have been lost during the compression in dVAE. This was a plausible explanation but <strong>we wanted to see more in-depth investigation on model failures</strong>. There are numerous examples of terrifyingly looking images of hands generated by DALL·E because apparently it keeps failing at generating images of humans hands with five fingers.</p>
<p>We also discussed the <strong>lack of investigation on model failure from an ethical and responsible AI perspective.</strong> If OpenAI was going to publish a public API for a model like this, which would have varying degrees of socio-technical impact (look at all the issues ChatGPT has been creating these days), it would have been more responsible for them to test the model’s capacity more thoroughly and rigorously before rolling it out.</p>
<p>We found <a href="https://github.com/openai/DALL-E/blob/master/model_card.md">a model card</a> from their repository and it was <strong>disappointingly short and did not address any possible ethical and social ramifications</strong> that would be caused by the model.</p>
</section>
<section id="validity-of-the-scoring-metrics" class="level3">
<h3 class="anchored" data-anchor-id="validity-of-the-scoring-metrics"><font color="blue">Validity of the scoring metrics</font></h3>
<p>The authors used FID and IS scores (generated by the CLIP model) to assess how well the images reflect the text input. The scores were used to rank a pool of candidate images and the model returned top k results. We questioned the validity of the decision behind using these scores because they are model-dependent, which means <strong>they are training-data-dependent</strong>. Plus, there was no mention of (at least) a qualitative comparison between the training datasets of this paper and the CLIP paper. This made us question the reliability of the CLIP model scores. It might have been interesting to see a batch of images that were ranked high (or low) so that we could judge the validity of the scores and understand the model behavior better.</p>
</section>
<section id="qualitative-contribution" class="level3">
<h3 class="anchored" data-anchor-id="qualitative-contribution"><font color="blue">Qualitative contribution</font></h3>
<p>As in other deep learning papers, it was <strong>difficult for us to understand which decisions they made led to their results and advancement</strong>. For instance, they highlighted the larger training dataset and the larger model size. What was the measurable impact of each, and which one was more important? Similar to this, it would have been nice if they had some guidance on model tuning and hyperparameter selection to inform other researchers on model architecture design.</p>
</section>
<section id="reproducibility-and-novelty" class="level3">
<h3 class="anchored" data-anchor-id="reproducibility-and-novelty"><font color="blue">Reproducibility and novelty</font></h3>
<p>To be blunt, <strong>the main highlight of this paper seemed to be the scale</strong>. They were able to use bigger datasets with a bigger model. But let’s be honest, how many academic institutions or companies are able to afford to train a model with 12 billion parameters? Especially without proper model inspection, <strong>how can we understand the model properly when we can’t reproduce it easily?</strong> Although there were certain elements of novelty especially on their tricks of utilizing GPU resources to train the model, if the scale is the main factor of success, <strong>can we really call this as a novel invention?</strong></p>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final thoughts</h2>
<p>Thanks to the paper, we learned that VQ-VAE and transformer together can generate images from text inputs. However, we questioned the results and model validation especially due to the lack of investigation on model failure. We also thought about ethical aspect of this model being available in public. Just because it belongs to computer vision, which tends to <em>amuse</em> general audience, it does not mean that it is exempt from any social responsibility. And in deep learning with image and speech data, it is often the case that model validation is often looser than tabular data used in industries with higher stakes such as health care, finance, or risk assessment. That said, we would like to learn more about other techniques mentioned in the paper to have a deeper understanding of how they work.</p>


</section>

 ]]></description>
  <category>paper</category>
  <category>GenAI</category>
  <guid>https://hongsupshin.github.io/posts/2022-12-15/</guid>
  <pubDate>Thu, 15 Dec 2022 06:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2022-12-15/Fig 8.png" medium="image" type="image/png" height="124" width="144"/>
</item>
<item>
  <title>“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI</title>
  <dc:creator>Hongsup Shin</dc:creator>
  <link>https://hongsupshin.github.io/posts/2022-10-27/</link>
  <description><![CDATA[ 





<p>Many ML articles exist but few talk about how the sausage gets made. They are often based on toy or clean benchmark datasets, which are quite different from what we get in real world. That’s why I enjoy reading survey papers. They interview people in the field like us and try to address common pain points to find a broader picture.</p>
<p>For the past several years, I have been noticing a trend in ML community. Many practitioners tend to ignore data quality but instead put all their efforts into models and algorithms. I find it very troubling because many problems in real-world ML are caused by data-related issues. <a href="https://research.google/pubs/pub49953/">“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI</a> talks about this pattern based on the interviews from dozens of ML practitioners all over the globe. I presented the paper in Austin ML Journal Club in Oct 2022.</p>
<section id="data-cascades" class="level2">
<h2 class="anchored" data-anchor-id="data-cascades">Data cascades</h2>
<p>The paper focuses on “data cascades,” a series of compounding negative events due to data-related issues. The authors say the problems are wildly prevalent (92% reported experience at least one type of data cascades). <font color="blue">During the discussion, we thought about sampling bias because those who are ignorant of these problems may not be able to recognize them.</font> Indeed, they are often opaque because there are no clear indicators and often discovered later. Data cascades often lead to technical debt and harm to beneficiary communities. They can sour relationships between stakeholders and in extremely cases, force ML practitioners discard entire datasets. Figure 1 shows the schematic of the data cascades. <font color="blue">We thought the figure wasn’t particularly informative because too many arrows exist between the points. We hoped that the authors explained why there aren’t arrows between certain points.</font></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2022-10-27/Data cascades in high-stakes AI full.png" class="img-fluid figure-img"></p>
<figcaption>Figure 1. Data cascades in high-stakes AI</figcaption>
</figure>
</div>
</section>
<section id="high-stake-domains" class="level2">
<h2 class="anchored" data-anchor-id="high-stake-domains">High-stake domains</h2>
<p>Data cascades are more critical in high stake domains such as landslide detection, suicide prevention, and cancer detection. There are several reasons:</p>
<ul>
<li>More ML applications are deployed in these domains where more direct humanitarian impact exists.</li>
<li>This impact can be disproportionate towards vulnerable communities.</li>
<li>It is often very challenging to acquire high quality data in these domains.</li>
<li>The problems frequently require more multidisciplinary approach.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hongsupshin.github.io/posts/2022-10-27/Summary of participant demographics.png" class="img-fluid figure-img"></p>
<figcaption>Table 1. Summary of participant demographics; Domain</figcaption>
</figure>
</div>
<p>The authors find that the problems are due to human factors. Unfortunately solutions have been focusing on other issues such as database, legal, or license. To gather firsthand experience in the field, the authors interviewed 50+ ML practitioners all over the world, ranging from the US to India and African countries, and from founders to developers. Table 1 summarizes various high-stake domains. <font color="blue">It was fascinating for us to learn that ML is used in areas as landslide detection, poaching prevention, or regenerative farming. It would have been more interesting to see how data cascades create specific negative consequences in some domains.</font></p>
</section>
<section id="data-cascade-triggers" class="level2">
<h2 class="anchored" data-anchor-id="data-cascade-triggers">Data cascade triggers</h2>
<p>The authors introduce three triggers that cause data cascades.</p>
<section id="physical-world-brittleness" class="level3">
<h3 class="anchored" data-anchor-id="physical-world-brittleness">Physical world brittleness</h3>
<p>Physical world changes over time and thus often ML systems can’t produce robust results. Data drifts due to hardware (measurements) and environmental changes are commonly mentioned in ML Ops literature. In high-stake domains, they become more pronounced because training data are very limited and policy or regulation changes can impact the ML systems in various ways.</p>
</section>
<section id="inadequate-application-domain-expertise" class="level3">
<h3 class="anchored" data-anchor-id="inadequate-application-domain-expertise">Inadequate application-domain expertise</h3>
<p>Most ML practitioners are not equipped with domain knowledge. <font color="blue">All of us admitted that our academic background does not match to the domain that we work in.</font> Even though close collaboration between domain experts and ML practitioners is always emphasized, in practice the authors find that domain experts are often detached from the larger impact of the applications. The authors explain two specific types of problems:</p>
<p><strong>Subjectivity in ground truth:</strong> Areas such as insurance claim approval or medical imaging for cancer detection involve highly specialized and often subjective decision-making. To build a reliable and robust ML system, it is necessary to standardize the decision-making criteria and find consensus. However, ML practitioners are asked to rush through the development process, and thus do not have time to address it.</p>
<p><strong>Poor domain expertise in finding representative data:</strong> ML practitioners often start building ML applications without involving domain experts much because the practitioners simply believe that data are reliable. However, because they lack domain knowledge, practitioners make incomplete assumptions, which results in disparity between data collection and deployment. This often leads to poor and unreliable model performance.</p>
</section>
<section id="conflicting-reward-system" class="level3">
<h3 class="anchored" data-anchor-id="conflicting-reward-system">Conflicting reward system</h3>
<p>Data collection and any data-related work are often considered non-technical and undervalued. The situation gets worse for frontline workers because they are asked to collect and curate field data on top of their existing responsibilities but they are not well compensated.</p>
</section>
<section id="poor-cross-organizational-documentation" class="level3">
<h3 class="anchored" data-anchor-id="poor-cross-organizational-documentation">Poor cross-organizational documentation</h3>
<p>Metadata about data collection, quality, and curation are also often missing. Some good practices the authors suggest involve keeping good documentation on reproducible assets such as data collection plan, data strategy handbooks, design documents, file conventions, field notes, and so on.</p>
</section>
</section>
<section id="broader-context" class="level2">
<h2 class="anchored" data-anchor-id="broader-context">Broader context</h2>
<p>Data cascades discussion can be extended to bigger problems in ML community.</p>
<section id="incentives-and-currency-in-ai" class="level3">
<h3 class="anchored" data-anchor-id="incentives-and-currency-in-ai">Incentives and currency in AI</h3>
<p>Because of the low incentives, data-related work are not rewarded or even tracked. This makes us difficult to get buy-in from stakeholders. The situation is similar in academia as well. Most practitioners and researchers focus on developing algorithms but they rarely mention or work on data. <font color="blue">The title <em>“Everyone wants to do the model work, not the data work”</em> was a verbatim from an interviewee. Unfortunately, we were all able to relate to this quote.</font></p>
</section>
<section id="data-education" class="level3">
<h3 class="anchored" data-anchor-id="data-education">Data education</h3>
<p>Most ML or data science curricula lack any mention of data quality or ethics. They use toy datasets or very clean benchmark datasets. <font color="blue">As experience ML practitioners, we wholeheartedly agreed with this finding. We lamented that these courses do not prepare students with practical knowledge because one never works with clean datasets in real world. Some of us have experienced this pattern firsthand because we have been interviewing candidates for an ML practitioner position and found that the candidates who only worked with clean datasets (or primarily worked on algorithms) often lack basic practical ML knowledge.</font></p>
</section>
<section id="data-bootstrapping" class="level3">
<h3 class="anchored" data-anchor-id="data-bootstrapping">Data bootstrapping</h3>
<p>Data bootstrapping describes ML practitioners’ use of other data sources such as established data services or existing datasets to create their own dataset. <font color="blue">For most of us, it was surprising to learn that many ML practitioners in high-stake domains in countries from Global South had to collect data from scratch. We agreed that challenges in data collection and lack of access to quality data would create inequality between countries.</font></p>
</section>
</section>
<section id="how-to-address-data-cascades" class="level2">
<h2 class="anchored" data-anchor-id="how-to-address-data-cascades">How to address data cascades</h2>
<p>The authors introduce several ways of addressing the problem of data cascades. They introduce the concept of <em>“data excellence”</em>, an effort to <strong>“focus on the practices, politics, and values of humans of the data pipeline to improve the quality and sanctity of data, through the use of processes, standards, infrastructure and incentives”</strong>.</p>
<section id="from-goodness-of-fit-to-goodness-of-data" class="level3">
<h3 class="anchored" data-anchor-id="from-goodness-of-fit-to-goodness-of-data">From goodness-of-fit to goodness-of-data</h3>
<p>The first is to use the right metric to evaluate data quality. Many ML practitioners use model performance metrics such as accuracy and RMSE to evaluate data quality. <font color="blue">Some of us had a similar experience. We had to argue that model metrics shouldn’t be used to make a decision on data-pipeline and data-quality features. We hope that the authors can introduce specific examples of goodness-of-data metrics in the future.</font></p>
</section>
<section id="incentives-for-data-excellence" class="level3">
<h3 class="anchored" data-anchor-id="incentives-for-data-excellence">Incentives for data excellence</h3>
<p>There are several ways to address the low incentives of data work. First, journals and conferences should require dataset documentation, provenance, and ethics as mandatory disclosure. Second, organizations should reward data-related work similar to how good software engineering is rewarded. Finally, partnership between stakeholders can nurture data excellence by sharing the reward on data-related work such as data collection, anomaly identification, and model verification.</p>
</section>
<section id="education-and-visibility" class="level3">
<h3 class="anchored" data-anchor-id="education-and-visibility">Education and visibility</h3>
<p>The authors argue for real-world data literacy in AI education, which includes training on data collection, infrastructure building, data documentation, data sense-making, and data ethics and responsible AI in general. Increasing the data visibility in ML lifecycle is important as well; implementing good monitoring system is one of the most important ML Ops practices anyway.</p>
</section>
</section>
<section id="journal-club-discussion" class="level2">
<h2 class="anchored" data-anchor-id="journal-club-discussion">Journal club discussion</h2>
<p>Some of us found this paper vindicating because we have been advocating for data quality at work and had to fight for the attention it deserves. The paper helped us share our own practices at work that address data-related issues especially data collection, curation, and post-deployment data problems. Even though we generally agreed with authors’ suggestions, some of us wanted something more specific, like a case study. Overall, we found the paper interesting and insightful. We thought it would be beneficial to read the paper with our colleagues at work to start a discussion for data excellence.</p>


</section>

 ]]></description>
  <category>paper</category>
  <category>data</category>
  <category>responsible AI</category>
  <guid>https://hongsupshin.github.io/posts/2022-10-27/</guid>
  <pubDate>Thu, 27 Oct 2022 05:00:00 GMT</pubDate>
  <media:content url="https://hongsupshin.github.io/posts/2022-10-27/Data cascades in high-stakes AI.png" medium="image" type="image/png" height="70" width="144"/>
</item>
</channel>
</rss>
