{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6465af35-32d6-49fd-aa2b-3243c73a981c",
   "metadata": {},
   "source": [
    "# Pretraining on unlabeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d219f05-620c-4aea-81d4-4c910617997c",
   "metadata": {},
   "source": [
    "## Evaluating generative text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93e39a-ddb9-4166-9c49-d78bf2e76c3f",
   "metadata": {},
   "source": [
    "128-138"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44971905-a61c-4d1f-b748-42aa624c3a45",
   "metadata": {},
   "source": [
    "### 1. Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aefdff-3d2a-4ecc-bde2-6f974e637be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../../../LLMs-from-scratch/ch05/01_main-chapter-code/\")\n",
    "from previous_chapters import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d670cc-429f-4a08-9536-66af2ee05b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a821c418-d444-4c77-a8a1-19df2865823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d97c4",
   "metadata": {},
   "source": [
    "text generation process\n",
    "1. text -> token ID\n",
    "2. model generates logits\n",
    "3. logits -> token ID -> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ffe916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8765b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # to add the batch dim\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove the batch dim\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a355f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88b027",
   "metadata": {},
   "source": [
    "### 2. Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55935184",
   "metadata": {},
   "source": [
    "1. Convert logits (model outputs) to probas\n",
    "2. Select the target probability using the target index\n",
    "3. Calculate the average log probability\n",
    "4. Negative log probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac93516",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100], [40, 1107, 588]])\n",
    "targets = torch.tensor([[3626, 6100, 345], [1107, 588, 11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1ddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # disable gradient tracking since not training\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6d941",
   "metadata": {},
   "source": [
    "- 2: batch size (number of examples)\n",
    "- 3: num tokens per example\n",
    "- 50257: embedding dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be0290cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147e3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\" f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27219f15",
   "metadata": {},
   "source": [
    "[0, 1, 2] -> three tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d223c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 1: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6ad54",
   "metadata": {},
   "source": [
    "137-147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "348ec0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6327a221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f700af96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "151402a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75d9e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c16a1d",
   "metadata": {},
   "source": [
    "Essentially the same as using the cross entropy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe009084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466fb0b",
   "metadata": {},
   "source": [
    "Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f33052d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bad82a",
   "metadata": {},
   "source": [
    "### 3. Calculating the training and validation set losses    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7645a7d",
   "metadata": {},
   "source": [
    "141-151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349732d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.exists(\"the-verdict.txt\"):\n",
    "    url = (\n",
    "        \"https://raw.githubusercontent.com/rasbt/\"\n",
    "        \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "        \"the-verdict.txt\"\n",
    "    )\n",
    "    file_path = \"the-verdict.txt\"\n",
    "    urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0c7ec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3fbf2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01ffa860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,  # last incomplete one\n",
    "    shuffle=True,  # reshuffled at every epoch\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5482b88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4b918",
   "metadata": {},
   "source": [
    "9 training set batches, 1 validation set batch\n",
    "- total tokens: about 5k\n",
    "- 256 tokens per training and validation data\n",
    "- stride size of 256 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec82395",
   "metadata": {},
   "source": [
    "144-154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0cae57a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 50257])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "400a82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdaebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ff7bbf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987582948472765\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeeb136",
   "metadata": {},
   "source": [
    "## Training an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27ff80",
   "metadata": {},
   "source": [
    "1. Iterate over epochs\n",
    "2. Iterate over batches in each epoch\n",
    "3. Reset loss gradients from the previous batch\n",
    "4. Calculate loss on current batch\n",
    "5. Backprop to calculate loss gradients\n",
    "6. Update the weights using the gradients\n",
    "7. (Optional) Print train and val losses\n",
    "8. (Optional) Generate sample text for visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d090d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(\n",
    "                    f\"Ep {epoch + 1} (Step {global_step:06d}): \"\n",
    "                    f\"Train loss {train_loss:.3f}, \"\n",
    "                    f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  # dropout is disabled for stable reproducible results\n",
    "    with torch.no_grad():  # disable gradient tracking; reduce computational overhead\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24849909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b921efe",
   "metadata": {},
   "source": [
    "AdamW\n",
    "- A variant of Adam that improves weight decay\n",
    "- Minimize model complexity and prevent overfitting by penalizing larger weights\n",
    "- More efficient regularization and better generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669df79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.817, Val loss 9.924\n",
      "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.332\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.619, Val loss 7.042\n",
      "Ep 2 (Step 000015): Train loss 6.046, Val loss 6.596\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,, and,, the,, the, and,, and,,, the, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.524, Val loss 6.508\n",
      "Ep 3 (Step 000025): Train loss 5.369, Val loss 6.378\n",
      "Every effort moves you, and to the of the of the picture. Gis.                                     \n",
      "Ep 4 (Step 000030): Train loss 4.830, Val loss 6.263\n",
      "Ep 4 (Step 000035): Train loss 4.586, Val loss 6.285\n",
      "Every effort moves you of the \"I the picture.                    \"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.879, Val loss 6.130\n",
      "Every effort moves you know he had been his pictures, and I felt it's by his last word.                   \"Oh, and he had been the end, and he had been\n",
      "Ep 6 (Step 000045): Train loss 3.530, Val loss 6.183\n",
      "Ep 6 (Step 000050): Train loss 2.960, Val loss 6.123\n",
      "Every effort moves you know it was his pictures--I glanced after him, I had the last word.        \"Oh, and I was his pictures--I looked.   \"I looked. \"I looked. \n",
      "Ep 7 (Step 000055): Train loss 2.832, Val loss 6.150\n",
      "Ep 7 (Step 000060): Train loss 2.104, Val loss 6.133\n",
      "Every effort moves you know the picture to me--I glanced after him, and Mrs.  \"I was no great, the fact, the fact that, the moment--as Jack himself, as his pictures--as of the picture--because he was a little\n",
      "Ep 8 (Step 000065): Train loss 1.691, Val loss 6.186\n",
      "Ep 8 (Step 000070): Train loss 1.391, Val loss 6.230\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.059, Val loss 6.251\n",
      "Ep 9 (Step 000080): Train loss 0.800, Val loss 6.278\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, and down the room, and now\n",
      "Ep 10 (Step 000085): Train loss 0.569, Val loss 6.373\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=0.0004, weight_decay=0.1  # pass all trainable weights\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e80f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Valida\")\n",
    "    ax1.set(xlabel=\"Epochs\", ylabel=\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()  # creates a second x axis that shares the same y axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f227ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e1853611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17cdff",
   "metadata": {},
   "source": [
    "## Decoding strategies to control randomness\n",
    "151-161"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb3ced",
   "metadata": {},
   "source": [
    "Transfer the model from GPU to CPU since inference doesn't require heavy compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "05da0e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ca216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7637c14",
   "metadata": {},
   "source": [
    "### 1. Temperature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f6d2b",
   "metadata": {},
   "source": [
    "Not greedy decoding (replace `argmax` with a function that samples from a prob. dist.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c7ad5a",
   "metadata": {},
   "source": [
    "Example of prob. sampling with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2f1c1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e66ee78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "be86b44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c627fc4",
   "metadata": {},
   "source": [
    "Multinomial but still \"forward\" is the most likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b19994ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "425c7a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "\n",
    "print(print_sampled_tokens(probas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36325787",
   "metadata": {},
   "source": [
    "Temperature scaling\n",
    "- T > 1: more uniformly distributed probas\n",
    "- T < 1: more confident (sharper) proba dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "36ecae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf736d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f\"T={T}\")\n",
    "ax.set(ylabel=\"Prob.\", xticks=x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b5fa1",
   "metadata": {},
   "source": [
    "### 2. Top-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caef0c7",
   "metadata": {},
   "source": [
    "- Just using temperature scaling can have a downside: sometimes this leads to nonsensical outputs\n",
    "- Top-k sampling can restrict the sampled tokens to the top-k most likely tokens and exclude others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bae53fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ae427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],  # find the logits < min of top-3\n",
    "    input=torch.tensor(float(\"-inf\")),  # if condition is met, assign -inf\n",
    "    other=next_token_logits,  # retain the original otherwise\n",
    ")\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "486c7669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c444e",
   "metadata": {},
   "source": [
    "### 3. Modifying the text generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3cff0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(\n",
    "    model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None\n",
    "):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits /= temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            # probablistic sampling\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            # greedy decoding\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            # stop generating early if end of sequence token is found\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0cb09523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand,\" she down.\" For Mrs. Gisburn! The women had\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feda65e3",
   "metadata": {},
   "source": [
    "## Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3205d2",
   "metadata": {},
   "source": [
    "159-169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c086de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fe8ef9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bt/p1m1p8ls6rs68x_qsjzsz7qr0000gn/T/ipykernel_1899/936198766.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba46338",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "11748dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bt/p1m1p8ls6rs68x_qsjzsz7qr0000gn/T/ipykernel_1899/2328250181.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef73318e",
   "metadata": {},
   "source": [
    "## Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c96d86c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x14e53d0d0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3c725713",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<00:00, 51.7kiB/s]\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:00<00:00, 3.10MiB/s]\n",
      "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.0/90.0 [00:00<00:00, 68.7kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498M/498M [00:16<00:00, 29.3MiB/s] \n",
      "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.21k/5.21k [00:00<00:00, 3.49MiB/s]\n",
      "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471k/471k [00:00<00:00, 1.90MiB/s]\n",
      "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 1.97MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "808b3eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f4b378df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "85300e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cdb4f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd8590",
   "metadata": {},
   "source": [
    "qkv bias is not used in LLM any more but GPT-2 has it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8da02b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c508833",
   "metadata": {},
   "source": [
    "Overwrite the random weights with the loaded weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90dc94c",
   "metadata": {},
   "source": [
    "Function to check whether the two tensors have the same dim/shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "08ce17a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                         f\"Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "aaa6231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T\n",
    "        )\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T,\n",
    "        )\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"],\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T,\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T,\n",
    "        )\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"],\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"]\n",
    "        )\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"]\n",
    "        )\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7629545a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "512f6e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward more efficient and efficient processes, like in the car's oil and gas operation,\" the study said. To see if that\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5,\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02990fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
